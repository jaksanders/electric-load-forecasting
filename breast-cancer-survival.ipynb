{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-29T17:53:36.886104Z","iopub.execute_input":"2023-09-29T17:53:36.886551Z","iopub.status.idle":"2023-09-29T17:53:36.909164Z","shell.execute_reply.started":"2023-09-29T17:53:36.886518Z","shell.execute_reply":"2023-09-29T17:53:36.907987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:36.921949Z","iopub.execute_input":"2023-09-29T17:53:36.922646Z","iopub.status.idle":"2023-09-29T17:53:36.926690Z","shell.execute_reply.started":"2023-09-29T17:53:36.922612Z","shell.execute_reply":"2023-09-29T17:53:36.926006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"markdown","source":"TCGA breast invasive carcinoma (BRCA) gene expression by RNAseq (polyA+ IlluminaHiSeq percentile)\n\n\nGoldman, M.J., Craft, B., Hastie, M. et al. Visualizing and interpreting cancer genomics data via the Xena platform. Nat Biotechnol (2020). https://doi.org/10.1038/s41587-020-0546-8","metadata":{}},{"cell_type":"code","source":"# load data\n# load gene expression data\ngeneExpressionData = pd.read_csv('/kaggle/input/breast-cancer/TCGA.BRCA.sampleMap_HiSeqV2_percentile/HiSeqV2_percentile', sep='\\t')\ngeneExpressionData","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:37.164182Z","iopub.execute_input":"2023-09-29T17:53:37.164536Z","iopub.status.idle":"2023-09-29T17:53:41.692365Z","shell.execute_reply.started":"2023-09-29T17:53:37.164502Z","shell.execute_reply":"2023-09-29T17:53:41.690892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Curated survival data from the Pan-cancer Atlas paper titled \"An Integrated TCGA Pan-Cancer Clinical Data Resource (TCGA-CDR) to drive high quality survival outcome analytics\". The paper highlights four types of carefully curated survival endpoints, and recommends the use of the endpoints of OS, PFI, DFI, and DSS for each TCGA cancer type.\n\n\nOS: overall survial\n\nPFI: progression-free interval\n\nDSS: disease-specific survival\n\nDFI: disease-free interval","metadata":{}},{"cell_type":"code","source":"# load survival data\nsurvivalData = pd.read_csv('/kaggle/input/breast-cancer/tcga-xena-hub.s3.us-east-1.amazonaws.com_download_survival2FBRCA_survival.txt', sep='\\t')\nsurvivalData","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:41.694544Z","iopub.execute_input":"2023-09-29T17:53:41.694882Z","iopub.status.idle":"2023-09-29T17:53:41.727742Z","shell.execute_reply.started":"2023-09-29T17:53:41.694853Z","shell.execute_reply":"2023-09-29T17:53:41.726368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BRCA_clinicalMatrix","metadata":{}},{"cell_type":"code","source":"clinicalData = pd.read_csv('/kaggle/input/breast-cancer/TCGA.BRCA.sampleMap_BRCA_clinicalMatrix', sep='\\t')\nclinicalData","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:41.729222Z","iopub.execute_input":"2023-09-29T17:53:41.729545Z","iopub.status.idle":"2023-09-29T17:53:41.811667Z","shell.execute_reply.started":"2023-09-29T17:53:41.729509Z","shell.execute_reply":"2023-09-29T17:53:41.810271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"geneExpressionData","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:41.814552Z","iopub.execute_input":"2023-09-29T17:53:41.814941Z","iopub.status.idle":"2023-09-29T17:53:41.852296Z","shell.execute_reply.started":"2023-09-29T17:53:41.814911Z","shell.execute_reply":"2023-09-29T17:53:41.850876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"geneExpressionData.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:41.853906Z","iopub.execute_input":"2023-09-29T17:53:41.854246Z","iopub.status.idle":"2023-09-29T17:53:41.909706Z","shell.execute_reply.started":"2023-09-29T17:53:41.854218Z","shell.execute_reply":"2023-09-29T17:53:41.908132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(survivalData)\nprofile.to_file('survivalData profile_report.html')\n# profile","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:41.911365Z","iopub.execute_input":"2023-09-29T17:53:41.911925Z","iopub.status.idle":"2023-09-29T17:53:54.450566Z","shell.execute_reply.started":"2023-09-29T17:53:41.911892Z","shell.execute_reply":"2023-09-29T17:53:54.449039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\n# pandas gags on this dataset - too big\n# profile = ProfileReport(geneExpressionData)\n# profile.to_file('geneExpressionData profile_report.html')\n# profile","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:54.452229Z","iopub.execute_input":"2023-09-29T17:53:54.453214Z","iopub.status.idle":"2023-09-29T17:53:54.458011Z","shell.execute_reply.started":"2023-09-29T17:53:54.453179Z","shell.execute_reply":"2023-09-29T17:53:54.456695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-processing","metadata":{}},{"cell_type":"code","source":"# join datasets together\n# print(geneExpressionData)\ngene_samples = geneExpressionData['sample'].unique()\ngene_samples.sort()\nprint('gene_samples\\n', gene_samples)\nprint(gene_samples.shape)\npd.DataFrame(gene_samples).to_csv(\"gene_samples.csv\")\n\nsurvival_samples = survivalData['sample'].unique()\nprint('survival_samples\\n', survival_samples)\n\nclinical_samples = clinicalData['sampleID'].unique()\nprint('clinical_samples\\n', clinical_samples)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:54.459536Z","iopub.execute_input":"2023-09-29T17:53:54.460717Z","iopub.status.idle":"2023-09-29T17:53:54.545998Z","shell.execute_reply.started":"2023-09-29T17:53:54.460678Z","shell.execute_reply":"2023-09-29T17:53:54.544911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observation: in the gene expression dataset, the sample IDs are in the column names, and gene IDs are in the 'sample' column, so...\n\nWe'll need to transpose the gene dataset in order to combine it with survival and clinical data","metadata":{}},{"cell_type":"code","source":"# transpose the gene dataset...\ngeneTranspose = geneExpressionData.set_index('sample')\ngeneTranspose = geneTranspose.transpose()\ngeneTranspose.reset_index(names='sampleID', inplace=True)\nprint(geneTranspose.info())\ngeneTranspose\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:54.547940Z","iopub.execute_input":"2023-09-29T17:53:54.548668Z","iopub.status.idle":"2023-09-29T17:53:57.074601Z","shell.execute_reply.started":"2023-09-29T17:53:54.548621Z","shell.execute_reply":"2023-09-29T17:53:57.073108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"geneColNames = list(geneTranspose.columns)\ngeneColNames.remove('sampleID')\ngeneColNames","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:57.079110Z","iopub.execute_input":"2023-09-29T17:53:57.080379Z","iopub.status.idle":"2023-09-29T17:53:57.102232Z","shell.execute_reply.started":"2023-09-29T17:53:57.080313Z","shell.execute_reply":"2023-09-29T17:53:57.100617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looks like the clinial and survival datasets have an easy join\n# the join columns need to have the same name to use the merge function...\n# so will copy the 'sample' column in survival data to a new 'sampleID' column\nmergeSurvival = survivalData.copy()\nmergeSurvival['sampleID'] = mergeSurvival['sample']\nmergeSurvival.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:57.103488Z","iopub.execute_input":"2023-09-29T17:53:57.103857Z","iopub.status.idle":"2023-09-29T17:53:57.130344Z","shell.execute_reply.started":"2023-09-29T17:53:57.103827Z","shell.execute_reply":"2023-09-29T17:53:57.128604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now that clinial and survival datasets both have a sampleID column, we can merge...\nmergeSurvivalClinical = pd.merge(clinicalData, mergeSurvival, on='sampleID')\nprint(mergeSurvivalClinical.info())\nmergeSurvivalClinical","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:57.132003Z","iopub.execute_input":"2023-09-29T17:53:57.132368Z","iopub.status.idle":"2023-09-29T17:53:57.191812Z","shell.execute_reply.started":"2023-09-29T17:53:57.132338Z","shell.execute_reply":"2023-09-29T17:53:57.189915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge the Survival+Clinical dataset with the gene expression dataset\nmergeSurvivalClinicalGene = pd.merge(mergeSurvivalClinical, geneTranspose, on='sampleID')\nprint(mergeSurvivalClinicalGene.info())\nmergeSurvivalClinicalGene","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:57.193241Z","iopub.execute_input":"2023-09-29T17:53:57.193591Z","iopub.status.idle":"2023-09-29T17:53:58.514840Z","shell.execute_reply.started":"2023-09-29T17:53:57.193561Z","shell.execute_reply":"2023-09-29T17:53:58.513557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"# heatmap of gene expression data\n# Python program to generate heatmap which \n# represents panda dataframe in color-coding schemes\n# along with values mentioned in each cell\n  \n# import required libraries\nimport pandas as pd\nimport seaborn as sns\n  \n# Defining figure size  \n# for the output plot \nfig, ax = plt.subplots(figsize = (12, 7))\n  \nsns.heatmap(geneTranspose.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:53:58.515945Z","iopub.execute_input":"2023-09-29T17:53:58.516252Z","iopub.status.idle":"2023-09-29T17:54:39.428809Z","shell.execute_reply.started":"2023-09-29T17:53:58.516224Z","shell.execute_reply":"2023-09-29T17:54:39.427620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gene expression heatmap, genes sorted by average expression percentile\ngeneAvgExpression = geneTranspose.iloc[:, 1:].mean(axis=0)\ngeneAvgExpression.sort_values()\n\ngeneByAvgExp = geneTranspose.reindex(geneTranspose.iloc[:, 1:].mean().sort_values().index, axis=1)\nprint(geneByAvgExp)\n\n# Defining figure size  \n# for the output plot \nfig, ax = plt.subplots(figsize = (12, 7))\n\nax.set_title('Gene Expression by Breast Cancer Sample')\nsns.color_palette(\"mako\", as_cmap=True)\nsns.heatmap(geneByAvgExp, cmap=\"mako\")\n\nplt.ylabel('Sample ID')\nplt.xlabel('Gene')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:54:39.431042Z","iopub.execute_input":"2023-09-29T17:54:39.431485Z","iopub.status.idle":"2023-09-29T17:55:19.724026Z","shell.execute_reply.started":"2023-09-29T17:54:39.431451Z","shell.execute_reply":"2023-09-29T17:55:19.722554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find and handle blanks / NaNs\nmergeSurvivalClinicalGene.isna().sum().sort_values(ascending=False)[lambda x : x > 0]","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:55:19.726395Z","iopub.execute_input":"2023-09-29T17:55:19.726954Z","iopub.status.idle":"2023-09-29T17:55:19.843329Z","shell.execute_reply.started":"2023-09-29T17:55:19.726910Z","shell.execute_reply":"2023-09-29T17:55:19.842101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import preprocessing\n!pip install fast-ml\nfrom fast_ml.model_development import train_valid_test_split","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:55:19.844901Z","iopub.execute_input":"2023-09-29T17:55:19.845601Z","iopub.status.idle":"2023-09-29T17:55:40.784485Z","shell.execute_reply.started":"2023-09-29T17:55:19.845566Z","shell.execute_reply":"2023-09-29T17:55:40.782887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Split\nX_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(mergeSurvivalClinicalGene, target = 'OS', train_size=0.7, valid_size=0.2, test_size=0.1)\n\nprint(X_train.shape), print(y_train.shape)\nprint(X_valid.shape), print(y_valid.shape)\nprint(X_test.shape), print(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:11:33.709213Z","iopub.execute_input":"2023-09-29T18:11:33.709627Z","iopub.status.idle":"2023-09-29T18:11:34.238105Z","shell.execute_reply.started":"2023-09-29T18:11:33.709596Z","shell.execute_reply":"2023-09-29T18:11:34.236866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train['OS.time'])","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:11:43.878757Z","iopub.execute_input":"2023-09-29T18:11:43.879193Z","iopub.status.idle":"2023-09-29T18:11:43.891801Z","shell.execute_reply.started":"2023-09-29T18:11:43.879160Z","shell.execute_reply":"2023-09-29T18:11:43.891012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding Clinical dataset categorical features\n# start with select ordinal features... ER_Status_nature2012\n# work with a copy of the dataset...\nordFeatures_train = pd.DataFrame(X_train.AJCC_Stage_nature2012).copy() # start with a couple...\nordFeatures_valid = pd.DataFrame(X_valid.AJCC_Stage_nature2012).copy() # start with a couple...\n\nordFeatures_train.replace(np.nan, 'Unknown', inplace=True)\nordFeatures_valid.replace(np.nan, 'Unknown', inplace=True)\n\nprint('ordFeatures_train:\\n', ordFeatures_train)\n\n# get unique values from training set\nAJCC_Stage_nature2012_LOV = ordFeatures_train.AJCC_Stage_nature2012.unique()\nprint('AJCC_Stage_nature2012_LOV:\\n', AJCC_Stage_nature2012_LOV)\n\n# set the ordinal sequence\nordinal_encoder = OrdinalEncoder(categories=[[\n    'Stage I','Stage IA','Stage IB', 'Stage II','Stage IIA','Stage IIB','Stage III','Stage IIIA','Stage IIIB','Stage IIIC','Stage IV','Stage X','Unknown']])\n\n# fit the encoder to the training data\nordinal_encoder.fit(ordFeatures_train)\n\n# transform the data\nordFeatures_train = pd.DataFrame(ordinal_encoder.transform(ordFeatures_train), index=X_train.index)\nordFeatures_valid = pd.DataFrame(ordinal_encoder.transform(ordFeatures_valid), index=X_valid.index)\n\n# set the column name for the transformed data\nordFeatures_train.columns = ordinal_encoder.get_feature_names_out()\nordFeatures_valid.columns = ordinal_encoder.get_feature_names_out()\n\n# take a look at the data\nprint('ordFeatures_train:\\n', ordFeatures_train)\nprint('ordFeatures_train:\\n', ordFeatures_train.describe())\nprint('ordFeatures_valid:\\n', ordFeatures_valid)\nprint('ordFeatures_valid:\\n', ordFeatures_valid.describe())","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:11:48.277700Z","iopub.execute_input":"2023-09-29T18:11:48.278155Z","iopub.status.idle":"2023-09-29T18:11:48.314116Z","shell.execute_reply.started":"2023-09-29T18:11:48.278123Z","shell.execute_reply":"2023-09-29T18:11:48.313217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding nominal features...,\nnomFeatureColNames = ['ER_Status_nature2012', 'HER2_Final_Status_nature2012','Metastasis_nature2012','Node_nature2012','Tumor_nature2012']\n\n# work with a copy of the dataset...\nnominalFeatures_train = X_train[nomFeatureColNames].copy()\nnominalFeatures_valid = X_valid[nomFeatureColNames].copy() \nprint('\\nnominalFeatures_train:\\n', nominalFeatures_train)\n# print(nominalFeatures.describe())\n\n# replace all NaN values with 'Unknown'\nnominalFeatures_train = nominalFeatures_train.replace(np.nan, 'Unknown')\nnominalFeatures_valid = nominalFeatures_valid.replace(np.nan, 'Unknown')\n# print(nominalFeatures)\n\n# create one hot encoder\nnominal_encoder = OneHotEncoder(drop='first', sparse_output=True)\n\n# apply the one hot encoder \nnominalFeaturesOHE_train = pd.DataFrame(nominal_encoder.fit_transform(nominalFeatures_train).toarray(), index=X_train.index)\nnominalFeaturesOHE_train.columns = nominal_encoder.get_feature_names_out()\nnominalFeaturesOHE_valid = pd.DataFrame(nominal_encoder.transform(nominalFeatures_valid).toarray(), index=X_valid.index)\nnominalFeaturesOHE_valid.columns = nominal_encoder.get_feature_names_out()\n\n# print(nominalFeaturesOHE.columns)\n# print(nominalFeaturesOHE.info())\n\n# take a look at the one hot encoded features...\nprint('\\nnominalFeaturesOHE_train:\\n', nominalFeaturesOHE_train)\nprint('\\nnominalFeaturesOHE_train:\\n', nominalFeaturesOHE_train.describe())\nprint('\\nnominalFeaturesOHE_valid:\\n', nominalFeaturesOHE_valid)\nprint('\\nnominalFeaturesOHE_valid:\\n', nominalFeaturesOHE_valid.describe())","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:11:59.592127Z","iopub.execute_input":"2023-09-29T18:11:59.592608Z","iopub.status.idle":"2023-09-29T18:11:59.742501Z","shell.execute_reply.started":"2023-09-29T18:11:59.592572Z","shell.execute_reply":"2023-09-29T18:11:59.741015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale numerical features\nlistOfNumericalColNames = ['Age_at_Initial_Pathologic_Diagnosis_nature2012', 'Days_to_Date_of_Last_Contact_nature2012','Days_to_date_of_Death_nature2012','Integrated_Clusters_no_exp__nature2012','Integrated_Clusters_unsup_exp__nature2012','Integrated_Clusters_with_PAM50__nature2012','OS_Time_nature2012','SigClust_Intrinsic_mRNA_nature2012','SigClust_Unsupervised_mRNA_nature2012','age_at_initial_pathologic_diagnosis','days_to_birth','days_to_collection','days_to_death','days_to_initial_pathologic_diagnosis','days_to_last_followup','days_to_last_known_alive','days_to_new_tumor_event_additional_surgery_procedure','initial_weight','lymph_node_examined_count','methylation_Clusters_nature2012','miRNA_Clusters_nature2012','number_of_lymphnodes_positive_by_he','number_of_lymphnodes_positive_by_ihc','year_of_initial_pathologic_diagnosis']\nlistOfNumericalColNames += ['OS.time', 'DSS.time', 'DFI.time', 'PFI.time']\nlistOfNumericalColNames += geneColNames\nprint(X_train['OS.time'])\nnumericalFeatures_train = X_train[listOfNumericalColNames].copy()\n# print(numericalFeatures_train)\n\nmin_max_scaler = preprocessing.MinMaxScaler()\nnumericalFeaturesMinMax_train = pd.DataFrame(min_max_scaler.fit_transform(numericalFeatures_train), columns = numericalFeatures_train.columns, index=X_train.index)\n\nprint(numericalFeaturesMinMax_train)\n\nnumericalFeatures_valid = X_valid[listOfNumericalColNames].copy()\nnumericalFeaturesMinMax_valid = pd.DataFrame(min_max_scaler.transform(numericalFeatures_valid), columns = numericalFeatures_valid.columns, index=X_valid.index)\nprint(numericalFeaturesMinMax_valid)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:12:10.406235Z","iopub.execute_input":"2023-09-29T18:12:10.406688Z","iopub.status.idle":"2023-09-29T18:12:11.479563Z","shell.execute_reply.started":"2023-09-29T18:12:10.406656Z","shell.execute_reply":"2023-09-29T18:12:11.477978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# more features that are already ready to go and don't need scaling (binary 0 or 1)\nlistOfReadyColNames = ['DSS', 'DFI', 'PFI']\nreadyFeatures_train = X_train[listOfReadyColNames].copy()\nreadyFeatures_valid = X_valid[listOfReadyColNames].copy()\n\nprint('\\nreadyFeatures_train:\\n', readyFeatures_train)\nprint('\\nreadyFeatures_valid:\\n', readyFeatures_valid)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:12:19.971508Z","iopub.execute_input":"2023-09-29T18:12:19.971911Z","iopub.status.idle":"2023-09-29T18:12:19.987976Z","shell.execute_reply.started":"2023-09-29T18:12:19.971877Z","shell.execute_reply":"2023-09-29T18:12:19.986701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(survivalData)\nprofile.to_file('survivalData profile_report.html')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:56:35.882976Z","iopub.execute_input":"2023-09-29T17:56:35.883376Z","iopub.status.idle":"2023-09-29T17:56:52.560238Z","shell.execute_reply.started":"2023-09-29T17:56:35.883344Z","shell.execute_reply":"2023-09-29T17:56:52.555019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(clinicalData)\nprofile.to_file('clinicalData profile_report.html')\n# profile","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:56:52.561345Z","iopub.status.idle":"2023-09-29T17:56:52.562137Z","shell.execute_reply.started":"2023-09-29T17:56:52.561939Z","shell.execute_reply":"2023-09-29T17:56:52.561960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(mergeSurvivalClinical)\nprofile.to_file('mergeSurvivalClinical profile_report.html')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:56:52.564398Z","iopub.status.idle":"2023-09-29T17:56:52.565325Z","shell.execute_reply.started":"2023-09-29T17:56:52.565058Z","shell.execute_reply":"2023-09-29T17:56:52.565085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# put training set together\nprint('\\nordFeatures_train:\\n', ordFeatures_train.info())\nprint('\\nnominalFeaturesOHE_train:\\n', nominalFeaturesOHE_train.info())\nprint('\\nnumericalFeaturesMinMax_train:\\n', numericalFeaturesMinMax_train.info())\nprint('\\nreadyFeatures_train:\\n', readyFeatures_train.info())\n\nX_train = pd.DataFrame(pd.concat([ordFeatures_train, nominalFeaturesOHE_train, numericalFeaturesMinMax_train, readyFeatures_train], axis=1))\nX_train.drop_duplicates(inplace=True)\n\nprint('\\nX_train:\\n', X_train.info())\nprint('\\nX_train:\\n', X_train)\nX_valid = pd.DataFrame(pd.concat([ordFeatures_valid, nominalFeaturesOHE_valid, numericalFeaturesMinMax_valid, readyFeatures_valid], axis=1))\n\nprint('\\ny_train:\\n', y_train)\n\nprint('\\nX_valid:\\n', X_valid)\nprint('\\ny_valid:\\n', y_valid)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:12:36.421009Z","iopub.execute_input":"2023-09-29T18:12:36.421483Z","iopub.status.idle":"2023-09-29T18:13:42.134954Z","shell.execute_reply.started":"2023-09-29T18:12:36.421447Z","shell.execute_reply":"2023-09-29T18:13:42.133490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\\nX_train:\\n', X_train.shape)\nprint('\\ny_train:\\n', y_train.shape)\nprint('\\nX_valid:\\n', X_valid.shape)\nprint('\\ny_valid:\\n', y_valid.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:13:54.552443Z","iopub.execute_input":"2023-09-29T18:13:54.552924Z","iopub.status.idle":"2023-09-29T18:13:54.559249Z","shell.execute_reply.started":"2023-09-29T18:13:54.552891Z","shell.execute_reply":"2023-09-29T18:13:54.558413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find and handle blanks / NaNs\nX_train.isna().sum().sort_values(ascending=False)[lambda x : x > 0]","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:14:02.554241Z","iopub.execute_input":"2023-09-29T18:14:02.554698Z","iopub.status.idle":"2023-09-29T18:14:02.613633Z","shell.execute_reply.started":"2023-09-29T18:14:02.554663Z","shell.execute_reply":"2023-09-29T18:14:02.612342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find and handle blanks / NaNs\nX_valid.isna().sum().sort_values(ascending=False)[lambda x : x > 0]","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:17:47.511342Z","iopub.execute_input":"2023-09-29T18:17:47.511819Z","iopub.status.idle":"2023-09-29T18:17:47.543411Z","shell.execute_reply.started":"2023-09-29T18:17:47.511767Z","shell.execute_reply":"2023-09-29T18:17:47.542613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's elimiate the 1 sample that has no data for PFI.time, DSS.time, OS.time\nbadSample = X_valid.loc[X_valid['PFI.time'].isna()]\n\n# badSample = X_train['PFI.time'][lambda x : x.isna()]\nbadSample\nprint(badSample.index.tolist())\n\nX_valid.drop(index=badSample.index.tolist(), inplace=True)\ny_valid.drop(index=badSample.index.tolist(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:20:45.036376Z","iopub.execute_input":"2023-09-29T18:20:45.036896Z","iopub.status.idle":"2023-09-29T18:20:45.079361Z","shell.execute_reply.started":"2023-09-29T18:20:45.036857Z","shell.execute_reply":"2023-09-29T18:20:45.078102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's elimiate the 1 sample that has no data for PFI.time, DSS.time, OS.time\nbadSample = X_train.loc[X_train['PFI.time'].isna()]\n\n# badSample = X_train['PFI.time'][lambda x : x.isna()]\nbadSample\nprint(badSample.index.tolist())\n\nX_train.drop(index=badSample.index.tolist(), inplace=True)\ny_train.drop(index=badSample.index.tolist(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:14:18.025369Z","iopub.execute_input":"2023-09-29T18:14:18.026010Z","iopub.status.idle":"2023-09-29T18:14:18.137672Z","shell.execute_reply.started":"2023-09-29T18:14:18.025961Z","shell.execute_reply":"2023-09-29T18:14:18.136151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:14:23.600423Z","iopub.execute_input":"2023-09-29T18:14:23.600944Z","iopub.status.idle":"2023-09-29T18:14:23.635739Z","shell.execute_reply.started":"2023-09-29T18:14:23.600907Z","shell.execute_reply":"2023-09-29T18:14:23.634861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find and handle blanks / NaNs\nNaNCols = pd.DataFrame(X_train.isna().sum().sort_values(ascending=False)[lambda x : x > 0])\nprint(NaNCols.index)\n\nX_train.drop(columns=NaNCols.index, inplace=True)\nX_valid.drop(columns=NaNCols.index, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:14:37.542881Z","iopub.execute_input":"2023-09-29T18:14:37.543360Z","iopub.status.idle":"2023-09-29T18:14:37.719819Z","shell.execute_reply.started":"2023-09-29T18:14:37.543320Z","shell.execute_reply":"2023-09-29T18:14:37.718225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find and handle blanks / NaNs\nNaNCols = pd.DataFrame(X_valid.isna().sum().sort_values(ascending=False)[lambda x : x > 0])\nprint(NaNCols.index)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:16:51.235425Z","iopub.execute_input":"2023-09-29T18:16:51.235894Z","iopub.status.idle":"2023-09-29T18:16:51.273836Z","shell.execute_reply.started":"2023-09-29T18:16:51.235859Z","shell.execute_reply":"2023-09-29T18:16:51.272149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is too big to attemp\n# profile = ProfileReport(mergeSurvivalClinicalGene, correlations={\"auto\": {\"calculate\": False}})\n# profile.to_file('mergeSurvivalClinicalGene profile_report.html')\n# profile","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:57:10.539947Z","iopub.execute_input":"2023-09-29T17:57:10.540322Z","iopub.status.idle":"2023-09-29T17:57:10.545248Z","shell.execute_reply.started":"2023-09-29T17:57:10.540293Z","shell.execute_reply":"2023-09-29T17:57:10.544210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_train.shape[1])\nX_train","metadata":{"execution":{"iopub.status.busy":"2023-09-29T18:14:46.605529Z","iopub.execute_input":"2023-09-29T18:14:46.605979Z","iopub.status.idle":"2023-09-29T18:14:46.651558Z","shell.execute_reply.started":"2023-09-29T18:14:46.605944Z","shell.execute_reply":"2023-09-29T18:14:46.650337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.tensorflow.org/tutorials/structured_data/time_series#linear_model\nMAX_EPOCHS = 50\n\ndef compile_and_fit(model, X_train, y_train, X_valid, y_valid, patience=2):\n  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    patience=patience,\n                                                    mode='min')\n\n  model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[tf.keras.metrics.BinaryAccuracy()])\n\n  history = model.fit(X_train, y_train, epochs=MAX_EPOCHS,\n                      validation_data=(X_valid, y_valid),\n                      callbacks=[early_stopping])\n  return history","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:46:12.599339Z","iopub.execute_input":"2023-09-29T19:46:12.600864Z","iopub.status.idle":"2023-09-29T19:46:12.608930Z","shell.execute_reply.started":"2023-09-29T19:46:12.600782Z","shell.execute_reply":"2023-09-29T19:46:12.607275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\ndef plot_training_loss_accuracy(history):\n    print(history.history.keys())\n    # summarize history for accuracy\n    plt.plot(history.history['binary_accuracy'])\n    plt.plot(history.history['val_binary_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'valid'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'valid'], loc='upper left')\n    plt.show()\n    return","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:34:03.761225Z","iopub.execute_input":"2023-09-29T19:34:03.761719Z","iopub.status.idle":"2023-09-29T19:34:03.770693Z","shell.execute_reply.started":"2023-09-29T19:34:03.761686Z","shell.execute_reply":"2023-09-29T19:34:03.769068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_model = keras.models.Sequential([\n    keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])\n\nhistory = compile_and_fit(dense_model, X_train, y_train, X_valid, y_valid)\ndense_model.save('dense_model.keras')\n\n# IPython.display.clear_output()\n# multi_val_performance['Dense'] = dense_model.evaluate(X_valid, y_valid)\n# multi_performance['Dense'] = dense_model.evaluate(multi_window.test, verbose=0)\n\nplot_training_loss_accuracy(history)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:49:08.526971Z","iopub.execute_input":"2023-09-29T19:49:08.527409Z","iopub.status.idle":"2023-09-29T19:49:17.184324Z","shell.execute_reply.started":"2023-09-29T19:49:08.527376Z","shell.execute_reply":"2023-09-29T19:49:17.182840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\neval_model=dense_model.evaluate(X_train, y_train)\neval_model","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:49:27.960358Z","iopub.execute_input":"2023-09-29T19:49:27.960710Z","iopub.status.idle":"2023-09-29T19:49:28.640233Z","shell.execute_reply.started":"2023-09-29T19:49:27.960682Z","shell.execute_reply":"2023-09-29T19:49:28.638998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict\ny_pred=dense_model.predict(X_valid)\nprint(y_pred)\ny_pred = (y_pred>0.5)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:49:39.081586Z","iopub.execute_input":"2023-09-29T19:49:39.082886Z","iopub.status.idle":"2023-09-29T19:49:39.384404Z","shell.execute_reply.started":"2023-09-29T19:49:39.082826Z","shell.execute_reply":"2023-09-29T19:49:39.383260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ntn, fp, fn, tp = confusion_matrix(y_valid, y_pred).ravel()\n(tn, fp, fn, tp)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:49:49.348536Z","iopub.execute_input":"2023-09-29T19:49:49.349880Z","iopub.status.idle":"2023-09-29T19:49:49.363469Z","shell.execute_reply.started":"2023-09-29T19:49:49.349827Z","shell.execute_reply":"2023-09-29T19:49:49.362319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare the clinical data for machine learning...\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:57:15.475747Z","iopub.status.idle":"2023-09-29T17:57:15.476187Z","shell.execute_reply.started":"2023-09-29T17:57:15.476007Z","shell.execute_reply":"2023-09-29T17:57:15.476026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# heatmap of gene expression data\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:57:15.477762Z","iopub.status.idle":"2023-09-29T17:57:15.478214Z","shell.execute_reply.started":"2023-09-29T17:57:15.478032Z","shell.execute_reply":"2023-09-29T17:57:15.478052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clustering which group genes and/or samples together based on the similarity of their gene expression pattern","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:57:15.479433Z","iopub.status.idle":"2023-09-29T17:57:15.479873Z","shell.execute_reply.started":"2023-09-29T17:57:15.479625Z","shell.execute_reply":"2023-09-29T17:57:15.479646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# join data","metadata":{"execution":{"iopub.status.busy":"2023-09-29T17:57:15.483422Z","iopub.status.idle":"2023-09-29T17:57:15.483872Z","shell.execute_reply.started":"2023-09-29T17:57:15.483638Z","shell.execute_reply":"2023-09-29T17:57:15.483655Z"},"trusted":true},"execution_count":null,"outputs":[]}]}