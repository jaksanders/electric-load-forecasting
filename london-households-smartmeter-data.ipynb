{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Short-term residential load forecasting with Deep Learning\n\nLondon Households SmartMeter Data","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-26T13:22:54.611331Z","iopub.execute_input":"2023-09-26T13:22:54.611742Z","iopub.status.idle":"2023-09-26T13:22:54.903903Z","shell.execute_reply.started":"2023-09-26T13:22:54.611711Z","shell.execute_reply":"2023-09-26T13:22:54.902693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nimport IPython\nimport IPython.display\nimport glob\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nrandomState = 42 # tip of the cap to Douglas Adams\n#!pip install -U pip\n#!pip install -U setuptools wheel\n\n#!pip install autogluon\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:23:05.024352Z","iopub.execute_input":"2023-09-26T13:23:05.025378Z","iopub.status.idle":"2023-09-26T13:23:05.033157Z","shell.execute_reply.started":"2023-09-26T13:23:05.025341Z","shell.execute_reply":"2023-09-26T13:23:05.032208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creat two load forecasts...\n1) half-hourly load forecast for next 24 hours\n2) peak half-hour in the next 24 hours\n\nValue...\n* For electric network operator, minimize the amount of spinning reserve\n\nData...\n* residential smart meter usage data\n* weather data\n* weather forecast data","metadata":{}},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"markdown","source":"## Load half-hourly electric usage data\n...for ~5k smart meters in London\n[SmartMeter Energy Consumption Data in London Households](https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households)","metadata":{}},{"cell_type":"code","source":"import time\n# load half-hourly electric usage data\n# takes about four minutes, need to find somerthing faster like Dask?\n# https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households\nd = pd.read_csv('/kaggle/input/small-lcl-data/LCL-June2015v2_99.csv', parse_dates=[\"DateTime\"])\n\n# Get CSV files list from a folder\npath = '/kaggle/input/smart-meters-in-london/halfhourly_dataset/halfhourly_dataset'\ncsv_files = glob.glob(path + \"/*.csv\")\n\n# Read each CSV file into DataFrame\n# This creates a list of dataframes\nstart_time = time.time()\ndf_list = (pd.read_csv(file, parse_dates=[\"tstp\"]) for file in csv_files)\nprint('%s seconds' % (time.time() - start_time))\n\n# Concatenate all DataFrames\nstart_time = time.time()\nd = pd.concat(df_list, ignore_index=True)\nprint('%s seconds' % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:32:03.390665Z","iopub.execute_input":"2023-09-25T16:32:03.391445Z","iopub.status.idle":"2023-09-25T16:36:59.883095Z","shell.execute_reply.started":"2023-09-25T16:32:03.391413Z","shell.execute_reply":"2023-09-25T16:36:59.881694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:36:59.884831Z","iopub.execute_input":"2023-09-25T16:36:59.885554Z","iopub.status.idle":"2023-09-25T16:38:47.607166Z","shell.execute_reply.started":"2023-09-25T16:36:59.885500Z","shell.execute_reply":"2023-09-25T16:38:47.606048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load hourly weather data","metadata":{}},{"cell_type":"code","source":"# load hourly weather data\n# https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households\nweatherData = pd.read_csv('/kaggle/input/smart-meters-in-london/weather_hourly_darksky.csv', parse_dates=[\"time\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:38:47.611892Z","iopub.execute_input":"2023-09-25T16:38:47.612263Z","iopub.status.idle":"2023-09-25T16:38:47.705985Z","shell.execute_reply.started":"2023-09-25T16:38:47.612234Z","shell.execute_reply":"2023-09-25T16:38:47.704423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weatherData.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:38:47.707500Z","iopub.execute_input":"2023-09-25T16:38:47.707866Z","iopub.status.idle":"2023-09-25T16:38:47.764069Z","shell.execute_reply.started":"2023-09-25T16:38:47.707834Z","shell.execute_reply":"2023-09-25T16:38:47.762822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weatherData.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:38:47.765612Z","iopub.execute_input":"2023-09-25T16:38:47.765957Z","iopub.status.idle":"2023-09-25T16:38:47.816603Z","shell.execute_reply.started":"2023-09-25T16:38:47.765928Z","shell.execute_reply":"2023-09-25T16:38:47.815779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data pre-processing and cleaning","metadata":{}},{"cell_type":"markdown","source":"## Weather data: convert text attributes to string datatype","metadata":{}},{"cell_type":"code","source":"weatherData = weatherData.astype({'precipType':'string', 'icon':'string', 'summary':'string'})\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:38:47.817913Z","iopub.execute_input":"2023-09-25T16:38:47.819074Z","iopub.status.idle":"2023-09-25T16:38:47.832631Z","shell.execute_reply.started":"2023-09-25T16:38:47.819031Z","shell.execute_reply":"2023-09-25T16:38:47.831522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\n\nprofile = ProfileReport(weatherData, tsmode=True, sortby=\"time\")\nprofile.to_file('weatherData profile_report.html')\n# profile\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:38:47.834118Z","iopub.execute_input":"2023-09-25T16:38:47.834524Z","iopub.status.idle":"2023-09-25T16:40:03.023830Z","shell.execute_reply.started":"2023-09-25T16:38:47.834488Z","shell.execute_reply":"2023-09-25T16:40:03.022609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Identify and remove weather records not exactly on the hour","metadata":{}},{"cell_type":"code","source":"# inspect and remove records not exactly on the hour\noffRecs = weatherData.query(\"time.dt.minute != 0 or time.dt.second != 0\")\nprint('Records not exactly on the half-hour:\\n ', offRecs)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:03.025398Z","iopub.execute_input":"2023-09-25T16:40:03.025850Z","iopub.status.idle":"2023-09-25T16:40:03.096693Z","shell.execute_reply.started":"2023-09-25T16:40:03.025807Z","shell.execute_reply":"2023-09-25T16:40:03.095438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Upsample weather data to match half-houly sampling rate of load data","metadata":{}},{"cell_type":"code","source":"# select weather data features of interest\nweatherUpsample = weatherData[['time','temperature', 'dewPoint', 'pressure', 'humidity']].copy()\nweatherUpsample = weatherUpsample.sort_values(by=['time'])\nprint(weatherUpsample.info())\nprint(weatherUpsample.describe())\nprint(weatherUpsample)\n\nweatherUpsample = weatherUpsample.set_index('time')\nweatherUpsample.index.rename('time', inplace=True)\n\nstart_time = time.time()\n\nweatherUpsample = weatherUpsample.resample('30Min').mean()\n\n# upsample \nweatherUpsample['temperature'] = weatherUpsample['temperature'].interpolate()\nweatherUpsample['dewPoint'] = weatherUpsample['dewPoint'].interpolate()\nweatherUpsample['pressure'] = weatherUpsample['pressure'].interpolate()\nweatherUpsample['humidity'] = weatherUpsample['humidity'].interpolate()\n\nprint('%s seconds' % (time.time() - start_time))\n\nweatherUpsample = weatherUpsample.reset_index(names='DateTime')\nprint(weatherUpsample.info())\nprint(weatherUpsample.describe())\nprint(weatherUpsample)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:03.098230Z","iopub.execute_input":"2023-09-25T16:40:03.098627Z","iopub.status.idle":"2023-09-25T16:40:03.235244Z","shell.execute_reply.started":"2023-09-25T16:40:03.098596Z","shell.execute_reply":"2023-09-25T16:40:03.233826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weatherUpsample.to_csv('/kaggle/working/WeatherDataFinal.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:03.237541Z","iopub.execute_input":"2023-09-25T16:40:03.238597Z","iopub.status.idle":"2023-09-25T16:40:03.655378Z","shell.execute_reply.started":"2023-09-25T16:40:03.238551Z","shell.execute_reply":"2023-09-25T16:40:03.651471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:03.657607Z","iopub.execute_input":"2023-09-25T16:40:03.658311Z","iopub.status.idle":"2023-09-25T16:40:03.671631Z","shell.execute_reply.started":"2023-09-25T16:40:03.658269Z","shell.execute_reply":"2023-09-25T16:40:03.670198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# utility function to nicely format variable names and memory they are consuming\nimport sys\ndef sizeof_fmt(num, suffix='B'):\n    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n        if abs(num) < 1024.0:\n            return \"%3.1f %s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f %s%s\" % (num, 'Yi', suffix)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:03.679137Z","iopub.execute_input":"2023-09-25T16:40:03.679553Z","iopub.status.idle":"2023-09-25T16:40:03.687320Z","shell.execute_reply.started":"2023-09-25T16:40:03.679518Z","shell.execute_reply":"2023-09-25T16:40:03.685916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert smart meter usage datatype to float","metadata":{}},{"cell_type":"code","source":"# ~1 minute\nstart_time = time.time()\nd.iloc[:, 2] = pd.to_numeric(d.iloc[:, 2], errors='coerce')\nprint('%s seconds' % (time.time() - start_time))\n\n# rename usage column for easier reference\nd.rename(columns={d.columns[2]: 'KWHperHH'}, inplace=True)\nd.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:03.689297Z","iopub.execute_input":"2023-09-25T16:40:03.690115Z","iopub.status.idle":"2023-09-25T16:41:57.259474Z","shell.execute_reply.started":"2023-09-25T16:40:03.690070Z","shell.execute_reply":"2023-09-25T16:41:57.258198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set timestamp as the index\nstart_time = time.time()\nd.set_index('tstp')\nprint('%s seconds' % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:41:57.260979Z","iopub.execute_input":"2023-09-25T16:41:57.261328Z","iopub.status.idle":"2023-09-25T16:42:01.692062Z","shell.execute_reply.started":"2023-09-25T16:41:57.261299Z","shell.execute_reply":"2023-09-25T16:42:01.690758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identify and handle duplicates in the smart meter data","metadata":{}},{"cell_type":"code","source":"# about 1.5 minutes\nstart_time = time.time()\ndupes = d[d.duplicated()]\nprint('dupes', dupes)\nprint('dupes.index', dupes.index)\nd.drop(index=dupes.index, inplace=True)\nprint('%s seconds' % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:42:01.696080Z","iopub.execute_input":"2023-09-25T16:42:01.696502Z","iopub.status.idle":"2023-09-25T16:43:51.411504Z","shell.execute_reply.started":"2023-09-25T16:42:01.696469Z","shell.execute_reply":"2023-09-25T16:43:51.410203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set index for the usage data to the timestamp column.  Is this necessary?  Can't remember why\nstart_time = time.time()\nd.set_index('tstp')\nd.info()\nprint('%s seconds' % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:43:51.413179Z","iopub.execute_input":"2023-09-25T16:43:51.414237Z","iopub.status.idle":"2023-09-25T16:43:56.654136Z","shell.execute_reply.started":"2023-09-25T16:43:51.414203Z","shell.execute_reply":"2023-09-25T16:43:56.652819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check what is gobbling RAM\nfor name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n                          locals().items())), key= lambda x: -x[1])[:10]:\n    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:43:56.656535Z","iopub.execute_input":"2023-09-25T16:43:56.658458Z","iopub.status.idle":"2023-09-25T16:44:37.419760Z","shell.execute_reply.started":"2023-09-25T16:43:56.658420Z","shell.execute_reply":"2023-09-25T16:44:37.418753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize smart meter dataset to analyze for quality, completenes and othe insights","metadata":{}},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:44:37.421187Z","iopub.execute_input":"2023-09-25T16:44:37.421552Z","iopub.status.idle":"2023-09-25T16:44:37.427274Z","shell.execute_reply.started":"2023-09-25T16:44:37.421522Z","shell.execute_reply":"2023-09-25T16:44:37.426135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## grab a random sample of 2% of meters for visualization and analysis","metadata":{}},{"cell_type":"code","source":"rng = np.random.default_rng(randomState)\n# random_state = np.random.RandomState(randomState)\nsampleMeters = rng.choice(d.LCLid.unique(), size=int(len(d.LCLid.unique())*0.02), replace=False)\n# sampleMeters = np.random.choice(d.LCLid.unique(), size=int(len(d.LCLid.unique())*0.02), replace=False, random_state=random_state)\nprint('sampleMeters:\\n', sampleMeters)\nsample = d[d['LCLid'].isin(sampleMeters)]\nprint('sample:\\n', sample)\nprint(sample.describe())\n# print(sample.info())","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:44:37.429178Z","iopub.execute_input":"2023-09-25T16:44:37.430178Z","iopub.status.idle":"2023-09-25T16:45:17.953515Z","shell.execute_reply.started":"2023-09-25T16:44:37.430146Z","shell.execute_reply":"2023-09-25T16:45:17.952287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Heatmap to visualize meter read coverage and completeness","metadata":{}},{"cell_type":"code","source":"# visualize meter read coverage and completeness\n# using a random sample of 2% of meters\nplt.subplots(figsize=(20,15))\npivot_table = pd.pivot_table(sample, columns='tstp', index='LCLid', values='KWHperHH')\nsns.heatmap(pivot_table)\nplt.savefig('meter data heatmap.png', format='png')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:45:17.954883Z","iopub.execute_input":"2023-09-25T16:45:17.955572Z","iopub.status.idle":"2023-09-25T16:45:39.185243Z","shell.execute_reply.started":"2023-09-25T16:45:17.955541Z","shell.execute_reply":"2023-09-25T16:45:39.183586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations from Heatmap...\n* several houses start producing load part-way through the period\n    - eg MAC004221, MAC004248\n    \n    \n* several houses stop producing part-way through the period\n    - eg MAC004226, MAC004257\n    \n\n* most houses have at least one \"gap\" in their data (visible as white lines)\n\n\n* several houses stand out as having significantly higher average load than others\n    - eg MAC004225, MAC004249","metadata":{}},{"cell_type":"markdown","source":"## identify and remove smart meter readings not exactly on the half-hour","metadata":{}},{"cell_type":"code","source":"# identify and remove records not exactly on the half-hour\n\nstart_time = time.time()\n\noffRecs = d.query(\"tstp.dt.minute not in (0,30) or tstp.dt.second != 0\")\n# aggLoad[\"DateTime\"].dt.hour > 30\nprint('Records not exactly on the half-hour:\\n ', offRecs)\nprint(offRecs.info())\n\n# delete records not exactly on the half-hour\nd.drop(offRecs.index, inplace=True)\n\nprint('%s seconds' % (time.time() - start_time))\n\noffRecs = d.query(\"tstp.dt.minute not in (0,30) or tstp.dt.second != 0\")\nprint('Records not exactly on the half-hour: ', offRecs)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:45:39.187159Z","iopub.execute_input":"2023-09-25T16:45:39.187573Z","iopub.status.idle":"2023-09-25T16:46:58.201771Z","shell.execute_reply.started":"2023-09-25T16:45:39.187538Z","shell.execute_reply":"2023-09-25T16:46:58.200712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:46:58.203195Z","iopub.execute_input":"2023-09-25T16:46:58.203822Z","iopub.status.idle":"2023-09-25T16:46:58.213939Z","shell.execute_reply.started":"2023-09-25T16:46:58.203789Z","shell.execute_reply":"2023-09-25T16:46:58.213106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check what is gobbling RAM\nfor name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n                          locals().items())), key= lambda x: -x[1])[:10]:\n    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:46:58.215328Z","iopub.execute_input":"2023-09-25T16:46:58.216000Z","iopub.status.idle":"2023-09-25T16:47:44.979577Z","shell.execute_reply.started":"2023-09-25T16:46:58.215968Z","shell.execute_reply":"2023-09-25T16:47:44.978122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fill gaps in the smart meter data using interpolation\n\nOur heatmap above shows lots of gaps (small white vertical lines), and we'll fill those gaps using interpolation","metadata":{}},{"cell_type":"markdown","source":"### First step of filling these gaps is to create NaN records where records are missing\n\nThen we can fill these gas with interpolation","metadata":{}},{"cell_type":"code","source":"# First step of interpolation is to create NaN records where records are missing\n# about 2 minutes\nd.sort_values(by=['tstp'], inplace=True)\nd.set_index('tstp', inplace=True)\nd.index.rename('tstp', inplace=True)\n\nstart_time = time.time()\n# resample to create NaN records where records are missing\nd = d.groupby('LCLid')\\\n                .resample('30Min')\\\n                .mean()\n\n# fill the gaps with interpolation\nd['KWHperHH'] = d['KWHperHH'].interpolate()\nd.reset_index(inplace=True)\n\nprint('%s seconds' % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:47:44.981197Z","iopub.execute_input":"2023-09-25T16:47:44.981556Z","iopub.status.idle":"2023-09-25T16:50:58.215262Z","shell.execute_reply.started":"2023-09-25T16:47:44.981526Z","shell.execute_reply":"2023-09-25T16:50:58.213775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check the meter data heatmap to see if gaps have been filled","metadata":{}},{"cell_type":"code","source":"# visualize after interpolating missing values\nd.info()\nsample = d[d['LCLid'].isin(sampleMeters)]\npivot_table = pd.pivot_table(sample, columns='tstp', index='LCLid', values='KWHperHH')\nplt.subplots(figsize=(20,15))\n\nsns.heatmap(pivot_table)\nplt.savefig('meter data heatmap gaps filled.png', format='png')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:50:58.217098Z","iopub.execute_input":"2023-09-25T16:50:58.217602Z","iopub.status.idle":"2023-09-25T16:51:29.495977Z","shell.execute_reply.started":"2023-09-25T16:50:58.217555Z","shell.execute_reply":"2023-09-25T16:51:29.494456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize zeros in the dataset using heatmap\n\nI'm always curious to understand zeros in a dataset, and whether they are legitimate zero values, or indicate a data quality problem.","metadata":{}},{"cell_type":"code","source":"# visualize zeros in the dataset\nstart_time = time.time()\nsample = d[d['LCLid'].isin(sampleMeters)]\nsample['ZeroKWHperHH'] = sample['KWHperHH'] == 0\npivot_table = pd.pivot_table(sample, columns='tstp', index='LCLid', values='ZeroKWHperHH')\nprint('%s seconds' % (time.time() - start_time))\nplt.subplots(figsize=(20,15))\n\nsns.heatmap(pivot_table)\nplt.savefig('meter data heatmap zeros.png', format='png')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:51:29.497596Z","iopub.execute_input":"2023-09-25T16:51:29.497974Z","iopub.status.idle":"2023-09-25T16:52:00.706741Z","shell.execute_reply.started":"2023-09-25T16:51:29.497943Z","shell.execute_reply":"2023-09-25T16:52:00.705308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take a snapshot of data\nstart_time = time.time()\nd.to_csv('/kaggle/working/MeterDataFinal.csv',index=False)\nprint('%s seconds' % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:52:00.709005Z","iopub.execute_input":"2023-09-25T16:52:00.709551Z","iopub.status.idle":"2023-09-25T17:11:01.579031Z","shell.execute_reply.started":"2023-09-25T16:52:00.709499Z","shell.execute_reply":"2023-09-25T17:11:01.577533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Obervation\n\nThere are a handful of households that account all the zero value meter reads: MAC004233, MAC004226, MAC004267","metadata":{}},{"cell_type":"code","source":"# investigate the meters with zero reads\nMAC005127 = sample.query(\"LCLid == 'MAC005127'\")\n\nfig, ax = plt.subplots(4,figsize=(20,9))\n\n# plot whole ~2 years\nax[0].plot(MAC005127.tstp, MAC005127.KWHperHH)\nax[0].plot(MAC005127.tstp, MAC005127.ZeroKWHperHH)\nax[0].set(ylabel='KWH/hh',\n       title='Load from one Household MAC004233 with lots of zero values')\nplt.tick_params(rotation=45)\nax[0].grid()\n\n# zoom in\nax[1].plot(MAC005127.tstp[11000:15000], MAC005127.KWHperHH[11000:15000])\nax[1].plot(MAC005127.tstp[11000:15000], MAC005127.ZeroKWHperHH[11000:15000])\nax[1].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[1].grid()\n\n# zoom in more...\nax[2].plot(MAC005127.tstp[13000:13500], MAC005127.KWHperHH[13000:13500])\nax[2].plot(MAC005127.tstp[13000:13500], MAC005127.ZeroKWHperHH[13000:13500])\nax[2].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[2].grid()\n\n# zoom in to a different part of the series...\nax[3].plot(MAC005127.tstp[25000:25500], MAC005127.KWHperHH[25000:25500])\nax[3].plot(MAC005127.tstp[25000:25500], MAC005127.ZeroKWHperHH[25000:25500])\nax[3].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[3].grid()\n\nfig.savefig(\"MAC005127.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:11:01.581375Z","iopub.execute_input":"2023-09-25T17:11:01.581776Z","iopub.status.idle":"2023-09-25T17:11:03.206587Z","shell.execute_reply.started":"2023-09-25T17:11:01.581743Z","shell.execute_reply":"2023-09-25T17:11:03.205423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:\nThe zeros for MAC004233 seem legit - leaving them in","metadata":{}},{"cell_type":"code","source":"# investigate the meters with zero reads\nMAC002304 = sample.query(\"LCLid == 'MAC002304'\")\nfig, ax = plt.subplots(4,figsize=(20,9))\n\n# plot whole ~2 years\nax[0].plot(MAC002304.tstp, MAC002304.KWHperHH)\nax[0].plot(MAC002304.tstp, MAC002304.ZeroKWHperHH)\nax[0].set(ylabel='KWH/hh',\n       title='Load from one Household MAC002304 with lots of zero values')\nplt.tick_params(rotation=45)\nax[0].grid()\n\n# zoom in\nax[1].plot(MAC002304.tstp[17000:21000], MAC002304.KWHperHH[17000:21000])\nax[1].plot(MAC002304.tstp[17000:21000], MAC002304.ZeroKWHperHH[17000:21000])\nax[1].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[1].grid()\n\n# zoom in more...\nax[2].plot(MAC002304.tstp[19300:19800], MAC002304.KWHperHH[19300:19800])\nax[2].plot(MAC002304.tstp[19300:19800], MAC002304.ZeroKWHperHH[19300:19800])\nax[2].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[2].grid()\n\n# zoom in to a different part of the series...\nax[3].plot(MAC002304.tstp[25000:25500], MAC002304.KWHperHH[25000:25500])\nax[3].plot(MAC002304.tstp[25000:25500], MAC002304.ZeroKWHperHH[25000:25500])\nax[3].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[3].grid()\n\nfig.savefig(\"MAC002304.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:11:03.208316Z","iopub.execute_input":"2023-09-25T17:11:03.209426Z","iopub.status.idle":"2023-09-25T17:11:04.794129Z","shell.execute_reply.started":"2023-09-25T17:11:03.209389Z","shell.execute_reply":"2023-09-25T17:11:04.793085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation\n\nThe zeros for MAC004233 seem legit - leaving them in\n","metadata":{}},{"cell_type":"code","source":"# visualize and handle outliers\n\n# minumum and maximum timestamp for each house\nprint(d.groupby('LCLid').max().sort_values('tstp'))\nprint(d.groupby('LCLid').min().sort_values('tstp'))\nprint(d.groupby('LCLid').count().sort_values('tstp'))\n\nprint(d.groupby('LCLid').agg(['min', 'max', 'count']))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:11:04.795391Z","iopub.execute_input":"2023-09-25T17:11:04.796457Z","iopub.status.idle":"2023-09-25T17:12:34.731173Z","shell.execute_reply.started":"2023-09-25T17:11:04.796421Z","shell.execute_reply":"2023-09-25T17:12:34.729701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# which house has the highest peak load?\n\n# which house has the highest total aggregate load?\n\n# how variable / predictable is the timing of the peak load\n\n# how accurate is the next 24 hours forecast profile overall?\n\n# how accurate is the peak load forecast in next 24 hours?\n\n# normalize and standardize\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:12:34.733051Z","iopub.execute_input":"2023-09-25T17:12:34.733516Z","iopub.status.idle":"2023-09-25T17:12:34.739884Z","shell.execute_reply.started":"2023-09-25T17:12:34.733458Z","shell.execute_reply":"2023-09-25T17:12:34.738653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract one smartmeter for plotting\nsample = d.query(\"LCLid == 'MAC004233'\")\nsample","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:12:34.741425Z","iopub.execute_input":"2023-09-25T17:12:34.742864Z","iopub.status.idle":"2023-09-25T17:12:42.687196Z","shell.execute_reply.started":"2023-09-25T17:12:34.742823Z","shell.execute_reply":"2023-09-25T17:12:42.685824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize load profile for one household meter\nfig, ax = plt.subplots()\nax.plot(sample.iloc[100:4500,1], sample.iloc[100:4500,2])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Load from one Household, June-September 2012')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Load from one Household, June-September 2012.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:12:42.688823Z","iopub.execute_input":"2023-09-25T17:12:42.689296Z","iopub.status.idle":"2023-09-25T17:12:43.241882Z","shell.execute_reply.started":"2023-09-25T17:12:42.689265Z","shell.execute_reply":"2023-09-25T17:12:43.240581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set index for the sample\nsample.set_index('tstp')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:12:43.243384Z","iopub.execute_input":"2023-09-25T17:12:43.243823Z","iopub.status.idle":"2023-09-25T17:12:43.261454Z","shell.execute_reply.started":"2023-09-25T17:12:43.243787Z","shell.execute_reply":"2023-09-25T17:12:43.260202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA: Visualize daily average load for each meter and all meters...","metadata":{}},{"cell_type":"code","source":"# calculate average daily load profile for all meters...\n# abut 1.5 minutes\n\nstart_time = time.time()\navgLoadProfile = pd.DataFrame(d.groupby([d['tstp'].dt.hour, d['tstp'].dt.minute]).KWHperHH.mean())\navgLoadProfile = avgLoadProfile.reset_index(names=['hour', 'minute'])\navgLoadProfile['labels'] = pd.to_datetime(avgLoadProfile['hour'].astype(str) + ':' + avgLoadProfile['minute'].astype(str), format='%H:%M').dt.time\nprint('%s seconds' % (time.time() - start_time))\n\n# print(avgLoadProfile.info())\n# print(avgLoadProfile)\n\nfig, ax = plt.subplots(figsize=(10,7))\n\nax.set_xticks(avgLoadProfile.index, avgLoadProfile.labels)\n\nax.set(xlabel='time (HH:MI)', ylabel='KWH/hh',\n       title='Average Household 24 hour load profile')\n\n# calculate average daily load for each meter...\nstart_time = time.time()\navgLoadProfileEachMeter = pd.DataFrame(d.groupby(['LCLid', d['tstp'].dt.hour, d['tstp'].dt.minute]).agg({'KWHperHH': 'mean'}))\navgLoadProfileEachMeter = avgLoadProfileEachMeter.reset_index(names=['LCLid', 'hour', 'minute'])\nprint('%s seconds' % (time.time() - start_time))\n# print(avgLoadProfileEachMeter.info())\n# print(avgLoadProfileEachMeter)\n\n# plot every sample meter\nfor meter in sampleMeters:\n    # print(meter)\n    ax.plot(avgLoadProfileEachMeter.loc[avgLoadProfileEachMeter['LCLid'] == meter].index % 48, \n            avgLoadProfileEachMeter.loc[avgLoadProfileEachMeter['LCLid'] == meter].KWHperHH,\n           color='grey')\n\n# plot the average\nax.plot(avgLoadProfile.index, avgLoadProfile.KWHperHH, linewidth=5)\n\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Avg 24hr Load Profile every meter.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:12:43.263511Z","iopub.execute_input":"2023-09-25T17:12:43.263993Z","iopub.status.idle":"2023-09-25T17:15:06.098795Z","shell.execute_reply.started":"2023-09-25T17:12:43.263949Z","shell.execute_reply":"2023-09-25T17:15:06.097714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the sum of all loads for each timestamp using `groupby()` and `agg()`\nstart_time = time.time()\n# aggLoad = d.groupby('tstp')['KWHperHH'].agg('sum')\naggLoad = pd.DataFrame(d.groupby('tstp')['KWHperHH'].agg('sum'))\naggLoad.reset_index(inplace=True)\naggLoad.columns = ['tstp', 'AggregateLoad']\nprint('%s seconds' % (time.time() - start_time))\n\nprint(aggLoad)\nprint(aggLoad.describe())\nprint(aggLoad.info())","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:06.100692Z","iopub.execute_input":"2023-09-25T17:15:06.101402Z","iopub.status.idle":"2023-09-25T17:15:12.164141Z","shell.execute_reply.started":"2023-09-25T17:15:06.101365Z","shell.execute_reply":"2023-09-25T17:15:12.162717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad.sort_values(by=['tstp'], inplace=True)\naggLoad.set_index('tstp', inplace=True)\naggLoad.index.rename('DateTimeIndex', inplace=True)\naggLoad.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:12.165656Z","iopub.execute_input":"2023-09-25T17:15:12.165998Z","iopub.status.idle":"2023-09-25T17:15:12.184249Z","shell.execute_reply.started":"2023-09-25T17:15:12.165969Z","shell.execute_reply":"2023-09-25T17:15:12.182708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad['DateTime'] = aggLoad.index\naggLoad.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:12.185824Z","iopub.execute_input":"2023-09-25T17:15:12.186210Z","iopub.status.idle":"2023-09-25T17:15:12.209868Z","shell.execute_reply.started":"2023-09-25T17:15:12.186178Z","shell.execute_reply":"2023-09-25T17:15:12.208409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inspect and fix records with zero load\n# start with the aggregated records with zero load\nAggZeros = aggLoad.query(\"AggregateLoad == 0\")\nAggZeros\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:12.225147Z","iopub.execute_input":"2023-09-25T17:15:12.225569Z","iopub.status.idle":"2023-09-25T17:15:12.243499Z","shell.execute_reply.started":"2023-09-25T17:15:12.225537Z","shell.execute_reply":"2023-09-25T17:15:12.242048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observation: Some of the timestamps are not exactly on the half-hour\nQuestion: How many of the timestamps are not exactly on the half-hour?","metadata":{}},{"cell_type":"code","source":"# inspect and fix records not exactly on the half-hour\noffRecs = aggLoad.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\n# aggLoad[\"DateTime\"].dt.hour > 30\nprint('Records not exactly on the half-hour: ', offRecs)\nprint(offRecs.info())\n\n# delete records not exactly on the half-hour\naggLoad = aggLoad.drop(offRecs.index)\n\noffRecs = aggLoad.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\nprint('Records not exactly on the half-hour: ', offRecs)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:12.245446Z","iopub.execute_input":"2023-09-25T17:15:12.245932Z","iopub.status.idle":"2023-09-25T17:15:12.296299Z","shell.execute_reply.started":"2023-09-25T17:15:12.245878Z","shell.execute_reply":"2023-09-25T17:15:12.294883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the regularity of the observations (time between observations)\n# print(pd.infer_freq(train_data.DateTime))\naggLoad.index.to_series().diff().value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:12.298444Z","iopub.execute_input":"2023-09-25T17:15:12.299141Z","iopub.status.idle":"2023-09-25T17:15:12.314142Z","shell.execute_reply.started":"2023-09-25T17:15:12.299105Z","shell.execute_reply":"2023-09-25T17:15:12.313037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate moving average and stddev\nwindow_size = int(len(aggLoad.AggregateLoad) / 10)\nprint(window_size)\n\naggLoadMovingStdev = aggLoad.AggregateLoad.rolling(window_size).std()\naggLoadMovingStdev.columns = ['MovingStdev']\n# aggLoadMovingStdev.columns.values[0] = 'MovingStdev'\n\naggLoadMovingAvg = aggLoad.AggregateLoad.rolling(window_size).mean()\naggLoadMovingAvg.columns = ['MovingAvg']\n\nprint('aggLoadMovingStdev:\\n', aggLoadMovingStdev)\nprint(aggLoadMovingStdev.info())\nprint('aggLoadMovingAvg:\\n', aggLoadMovingAvg)\nprint(aggLoadMovingAvg.info())\n\n# aggLoad['MovingStdev'] = aggLoad.AggregateLoad.rolling(window_size).std()\n# aggLoad['MovingAvg'] = aggLoad.AggregateLoad.rolling(window_size).mean()\n\n# print('aggLoad.MovingStdev:\\n', aggLoad.MovingStdev)\n# print('aggLoad.MovingAvg:\\n', aggLoad.MovingAvg)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:12.315782Z","iopub.execute_input":"2023-09-25T17:15:12.316480Z","iopub.status.idle":"2023-09-25T17:15:12.348712Z","shell.execute_reply.started":"2023-09-25T17:15:12.316437Z","shell.execute_reply":"2023-09-25T17:15:12.347648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(aggLoad)\n\nfig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime, aggLoad.AggregateLoad)\n# ax.plot(aggLoad.DateTime, aggLoad.MovingAvg, linewidth=3)\n# ax.plot(aggLoad.DateTime, aggLoad.MovingStdev, linewidth=3)\nax.plot(aggLoad.DateTime, aggLoadMovingAvg, linewidth=3)\nax.plot(aggLoad.DateTime, aggLoadMovingStdev, linewidth=3)\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load 2012-2014')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Aggregate Household load 2012-2014.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:12.350629Z","iopub.execute_input":"2023-09-25T17:15:12.351037Z","iopub.status.idle":"2023-09-25T17:15:13.266877Z","shell.execute_reply.started":"2023-09-25T17:15:12.351004Z","shell.execute_reply":"2023-09-25T17:15:13.265461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:13.269008Z","iopub.execute_input":"2023-09-25T17:15:13.269420Z","iopub.status.idle":"2023-09-25T17:15:13.284200Z","shell.execute_reply.started":"2023-09-25T17:15:13.269386Z","shell.execute_reply":"2023-09-25T17:15:13.282364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime[10000:15000], aggLoad.AggregateLoad[10000:15000])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load June-August 2012')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Aggregate Household load June-August 2012.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:13.286280Z","iopub.execute_input":"2023-09-25T17:15:13.286814Z","iopub.status.idle":"2023-09-25T17:15:14.140602Z","shell.execute_reply.started":"2023-09-25T17:15:13.286752Z","shell.execute_reply":"2023-09-25T17:15:14.139315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime[12000:13000], aggLoad.AggregateLoad[12000:13000])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Aggregate Household load one month.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:14.142559Z","iopub.execute_input":"2023-09-25T17:15:14.143538Z","iopub.status.idle":"2023-09-25T17:15:14.815824Z","shell.execute_reply.started":"2023-09-25T17:15:14.143490Z","shell.execute_reply":"2023-09-25T17:15:14.814420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime[12500:12600], aggLoad.AggregateLoad[12500:12600])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load ~two days')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Aggregate Household load two days.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:14.817530Z","iopub.execute_input":"2023-09-25T17:15:14.817969Z","iopub.status.idle":"2023-09-25T17:15:15.480174Z","shell.execute_reply.started":"2023-09-25T17:15:14.817929Z","shell.execute_reply":"2023-09-25T17:15:15.478628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(aggLoad.DateTime[12500:12550], aggLoad.AggregateLoad[12500:12550])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load (one day)')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Aggregate Household load (one day).png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:15.481803Z","iopub.execute_input":"2023-09-25T17:15:15.482200Z","iopub.status.idle":"2023-09-25T17:15:15.976662Z","shell.execute_reply.started":"2023-09-25T17:15:15.482166Z","shell.execute_reply":"2023-09-25T17:15:15.975206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad.to_csv('/kaggle/working/aggLoadDataFinal.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:15.978311Z","iopub.execute_input":"2023-09-25T17:15:15.978833Z","iopub.status.idle":"2023-09-25T17:15:16.302035Z","shell.execute_reply.started":"2023-09-25T17:15:15.978797Z","shell.execute_reply":"2023-09-25T17:15:16.301025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Join load data and weather data\nmergeData = pd.merge(aggLoad, weatherUpsample, on='DateTime', copy=False)\nprint(mergeData.info())\nmergeData\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:16.303242Z","iopub.execute_input":"2023-09-25T17:15:16.303622Z","iopub.status.idle":"2023-09-25T17:15:16.357884Z","shell.execute_reply.started":"2023-09-25T17:15:16.303589Z","shell.execute_reply":"2023-09-25T17:15:16.356285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move first column to the Last\n# df = pd.DataFrame(mergeData)\ndf = mergeData\ntemp_cols=df.columns.tolist()\nnew_cols=temp_cols[1:] + temp_cols[0:1]\nmergeData=df[new_cols]\nprint(mergeData)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:16.359541Z","iopub.execute_input":"2023-09-25T17:15:16.359926Z","iopub.status.idle":"2023-09-25T17:15:16.376995Z","shell.execute_reply.started":"2023-09-25T17:15:16.359894Z","shell.execute_reply":"2023-09-25T17:15:16.375512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\n\nprofile = ProfileReport(mergeData, tsmode=True, sortby=\"DateTime\")\nprofile.to_file('mergeData profile_report.html')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:15:16.378763Z","iopub.execute_input":"2023-09-25T17:15:16.379641Z","iopub.status.idle":"2023-09-25T17:16:11.930183Z","shell.execute_reply.started":"2023-09-25T17:15:16.379589Z","shell.execute_reply":"2023-09-25T17:16:11.928814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the dateTime feature from the dataset\nautoData = mergeData.copy() # keep a copy for the autogluon AutoML\nmergeData = mergeData.drop(columns=['DateTime'])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:16:11.932063Z","iopub.execute_input":"2023-09-25T17:16:11.932574Z","iopub.status.idle":"2023-09-25T17:16:11.941325Z","shell.execute_reply.started":"2023-09-25T17:16:11.932536Z","shell.execute_reply":"2023-09-25T17:16:11.939877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoData.to_csv('/kaggle/working/autoDataFinal.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:16:11.943503Z","iopub.execute_input":"2023-09-25T17:16:11.943997Z","iopub.status.idle":"2023-09-25T17:16:12.415938Z","shell.execute_reply.started":"2023-09-25T17:16:11.943960Z","shell.execute_reply":"2023-09-25T17:16:12.414677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergeData.to_csv('/kaggle/working/mergeDataFinal.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:16:12.417607Z","iopub.execute_input":"2023-09-25T17:16:12.417987Z","iopub.status.idle":"2023-09-25T17:16:12.750810Z","shell.execute_reply.started":"2023-09-25T17:16:12.417954Z","shell.execute_reply":"2023-09-25T17:16:12.749180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergeData = pd.read_csv('/kaggle/working/mergeDataFinal.csv')\nmergeData","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:23:38.038825Z","iopub.execute_input":"2023-09-26T13:23:38.039692Z","iopub.status.idle":"2023-09-26T13:23:38.181115Z","shell.execute_reply.started":"2023-09-26T13:23:38.039625Z","shell.execute_reply":"2023-09-26T13:23:38.179607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergeData.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:23:42.120400Z","iopub.execute_input":"2023-09-26T13:23:42.120794Z","iopub.status.idle":"2023-09-26T13:23:42.154267Z","shell.execute_reply.started":"2023-09-26T13:23:42.120765Z","shell.execute_reply":"2023-09-26T13:23:42.153207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the time series data into train, test, and validation datasets\ntrain_size = int(len(mergeData) * 0.7)  # 70% for training\nval_size = int(len(mergeData) * 0.2)   # 20% for validation\ntest_size = len(mergeData) - val_size - train_size  # Remaining for testing\n\ntrain_data = mergeData[:train_size].copy()\nval_data = mergeData[train_size:train_size+val_size].copy()\ntest_data = mergeData[train_size+val_size:].copy()\n\nprint('train_data.head()', train_data.head())\nprint('val_data.head()', val_data.head())\nprint('test_data.head()', test_data.head())\nprint(train_data.info())\n\nnum_features = mergeData.shape[1]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:23:45.886608Z","iopub.execute_input":"2023-09-26T13:23:45.887014Z","iopub.status.idle":"2023-09-26T13:23:45.919409Z","shell.execute_reply.started":"2023-09-26T13:23:45.886981Z","shell.execute_reply":"2023-09-26T13:23:45.918253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_plot(testY, test_predict):\n      len_prediction=[x for x in range(len(testY))]\n      plt.figure(figsize=(20,5))\n      plt.plot(len_prediction, testY, marker='.', label=\"actual\")\n      plt.plot(len_prediction, test_predict, 'r', label=\"prediction\")\n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:23:50.766119Z","iopub.execute_input":"2023-09-26T13:23:50.766528Z","iopub.status.idle":"2023-09-26T13:23:50.775363Z","shell.execute_reply.started":"2023-09-26T13:23:50.766498Z","shell.execute_reply":"2023-09-26T13:23:50.774182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalize the data\ntrain_mean = train_data.mean()\ntrain_std = train_data.std()\n\ntrain_data = (train_data - train_mean) / train_std\nval_data = (val_data - train_mean) / train_std\ntest_data = (test_data - train_mean) / train_std\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:23:53.769392Z","iopub.execute_input":"2023-09-26T13:23:53.770059Z","iopub.status.idle":"2023-09-26T13:23:53.789375Z","shell.execute_reply.started":"2023-09-26T13:23:53.770024Z","shell.execute_reply":"2023-09-26T13:23:53.788515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize distribution of the features\ndf_std = (mergeData - train_mean) / train_std\ndf_std = df_std.melt(var_name='Column', value_name='Normalized')\nplt.figure(figsize=(12, 6))\nax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n_ = ax.set_xticklabels(mergeData.keys(), rotation=90)\nplt.savefig('violin_plot.png', format='png')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:23:56.821512Z","iopub.execute_input":"2023-09-26T13:23:56.822488Z","iopub.status.idle":"2023-09-26T13:23:58.346298Z","shell.execute_reply.started":"2023-09-26T13:23:56.822452Z","shell.execute_reply":"2023-09-26T13:23:58.345388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WindowGenerator():\n    # https://www.tensorflow.org/tutorials/structured_data/time_series#1_indexes_and_offsets\n  def __init__(self, input_width, label_width, shift,\n               train_df=train_data, val_df=val_data, test_df=test_data,\n               label_columns=None):\n    # Store the raw data.\n    self.train_df = train_df\n    self.val_df = val_df\n    self.test_df = test_df\n\n    # Work out the label column indices.\n    self.label_columns = label_columns\n    if label_columns is not None:\n      self.label_columns_indices = {name: i for i, name in\n                                    enumerate(label_columns)}\n    self.column_indices = {name: i for i, name in\n                           enumerate(train_df.columns)}\n\n    # Work out the window parameters.\n    self.input_width = input_width\n    self.label_width = label_width\n    self.shift = shift\n\n    self.total_window_size = input_width + shift\n\n    self.input_slice = slice(0, input_width)\n    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n    self.label_start = self.total_window_size - self.label_width\n    self.labels_slice = slice(self.label_start, None)\n    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n  def __repr__(self):\n    return '\\n'.join([\n        f'Total window size: {self.total_window_size}',\n        f'Input indices: {self.input_indices}',\n        f'Label indices: {self.label_indices}',\n        f'Label column name(s): {self.label_columns}'])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:24:13.636303Z","iopub.execute_input":"2023-09-26T13:24:13.636753Z","iopub.status.idle":"2023-09-26T13:24:13.649604Z","shell.execute_reply.started":"2023-09-26T13:24:13.636717Z","shell.execute_reply":"2023-09-26T13:24:13.648150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_window(self, features):\n    # https://www.tensorflow.org/tutorials/structured_data/time_series#2_split\n  inputs = features[:, self.input_slice, :]\n  labels = features[:, self.labels_slice, :]\n  if self.label_columns is not None:\n    labels = tf.stack(\n        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n        axis=-1)\n\n  # Slicing doesn't preserve static shape information, so set the shapes\n  # manually. This way the `tf.data.Datasets` are easier to inspect.\n  inputs.set_shape([None, self.input_width, None])\n  labels.set_shape([None, self.label_width, None])\n\n  return inputs, labels\n\nWindowGenerator.split_window = split_window\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:24:19.014234Z","iopub.execute_input":"2023-09-26T13:24:19.016154Z","iopub.status.idle":"2023-09-26T13:24:19.026917Z","shell.execute_reply.started":"2023-09-26T13:24:19.016110Z","shell.execute_reply":"2023-09-26T13:24:19.025050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot(self, model=None, plot_col='AggregateLoad', max_subplots=3):\n    # https://www.tensorflow.org/tutorials/structured_data/time_series#3_plot\n  inputs, labels = self.example\n  plt.figure(figsize=(12, 8))\n  plot_col_index = self.column_indices[plot_col]\n  max_n = min(max_subplots, len(inputs))\n  for n in range(max_n):\n    plt.subplot(max_n, 1, n+1)\n    plt.ylabel(f'{plot_col} [normed]')\n    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n             label='Inputs', marker='.', zorder=-10)\n\n    if self.label_columns:\n      label_col_index = self.label_columns_indices.get(plot_col, None)\n    else:\n      label_col_index = plot_col_index\n\n    if label_col_index is None:\n      continue\n\n    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n    if model is not None:\n      predictions = model(inputs)\n      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n                  marker='X', edgecolors='k', label='Predictions',\n                  c='#ff7f0e', s=64)\n\n    if n == 0:\n      plt.legend()\n\n  plt.xlabel('Time [h]')\n\nWindowGenerator.plot = plot","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:24:53.684234Z","iopub.execute_input":"2023-09-26T13:24:53.684636Z","iopub.status.idle":"2023-09-26T13:24:53.696190Z","shell.execute_reply.started":"2023-09-26T13:24:53.684606Z","shell.execute_reply":"2023-09-26T13:24:53.694966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataset(self, data):\n    # https://www.tensorflow.org/tutorials/structured_data/time_series#4_create_tfdatadatasets\n  data = np.array(data, dtype=np.float32)\n  ds = tf.keras.utils.timeseries_dataset_from_array(\n      data=data,\n      targets=None,\n      sequence_length=self.total_window_size,\n      sequence_stride=1,\n      shuffle=True,\n      seed=randomState,\n      batch_size=32,)\n\n  ds = ds.map(self.split_window)\n\n  return ds\n\nWindowGenerator.make_dataset = make_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:24:58.050878Z","iopub.execute_input":"2023-09-26T13:24:58.051309Z","iopub.status.idle":"2023-09-26T13:24:58.058509Z","shell.execute_reply.started":"2023-09-26T13:24:58.051273Z","shell.execute_reply":"2023-09-26T13:24:58.057616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.tensorflow.org/tutorials/structured_data/time_series#4_create_tfdatadatasets\n@property\ndef train(self):\n  return self.make_dataset(self.train_df)\n\n@property\ndef val(self):\n  return self.make_dataset(self.val_df)\n\n@property\ndef test(self):\n  return self.make_dataset(self.test_df)\n\n@property\ndef example(self):\n  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n  result = getattr(self, '_example', None)\n  if result is None:\n    # No example batch was found, so get one from the `.train` dataset\n    result = next(iter(self.train))\n    # And cache it for next time\n    self._example = result\n  return result\n\nWindowGenerator.train = train\nWindowGenerator.val = val\nWindowGenerator.test = test\nWindowGenerator.example = example","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:25:00.752724Z","iopub.execute_input":"2023-09-26T13:25:00.753626Z","iopub.status.idle":"2023-09-26T13:25:00.762754Z","shell.execute_reply.started":"2023-09-26T13:25:00.753582Z","shell.execute_reply":"2023-09-26T13:25:00.761279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare data for one-shot multi-step\nOUT_STEPS = 48 # 24 hour forecast\nIN_STEPS = 336 # look back 1 week\nmulti_window = WindowGenerator(input_width=IN_STEPS,\n                               label_width=OUT_STEPS,\n                               shift=OUT_STEPS)\n\nmulti_window.plot()\nmulti_window","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:25:04.896761Z","iopub.execute_input":"2023-09-26T13:25:04.897180Z","iopub.status.idle":"2023-09-26T13:25:06.258240Z","shell.execute_reply.started":"2023-09-26T13:25:04.897144Z","shell.execute_reply":"2023-09-26T13:25:06.257245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use a naive persistence model as baseline to compare more sophisticated models\nUse a 1 week persistence\n\nGeorgios Tziolis, Chrysovalantis Spanias, Maria Theodoride, Spyros Theocharides, Javier Lopez-Lorente, Andreas Livera, George Makrides, George E. Georghiou,\n\nShort-term electric net load forecasting for solar-integrated distribution systems based on Bayesian neural networks and statistical post-processing,\n\nEnergy,\nVolume 271,\n2023,\n127018,\nISSN 0360-5442,\n\nhttps://doi.org/10.1016/j.energy.2023.127018.","metadata":{}},{"cell_type":"code","source":"# capture performnce of models\nmulti_val_performance = {}\nmulti_performance = {}","metadata":{"execution":{"iopub.status.busy":"2023-09-26T15:15:40.450631Z","iopub.execute_input":"2023-09-26T15:15:40.452836Z","iopub.status.idle":"2023-09-26T15:15:40.460946Z","shell.execute_reply.started":"2023-09-26T15:15:40.452772Z","shell.execute_reply":"2023-09-26T15:15:40.459759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.tensorflow.org/tutorials/structured_data/time_series#linear_model\nMAX_EPOCHS = 50\n\ndef compile_and_fit(model, window, patience=2):\n  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    patience=patience,\n                                                    mode='min')\n\n  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n\n  history = model.fit(window.train, epochs=MAX_EPOCHS,\n                      validation_data=window.val,\n                      callbacks=[early_stopping])\n  return history\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:25:17.368764Z","iopub.execute_input":"2023-09-26T13:25:17.369167Z","iopub.status.idle":"2023-09-26T13:25:17.377444Z","shell.execute_reply.started":"2023-09-26T13:25:17.369134Z","shell.execute_reply":"2023-09-26T13:25:17.376189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Naive 1 week persistence model\nNaiveForecast = mergeData.AggregateLoad.copy()\n\nOneWeekNPeriods = 48 * 7\n\nNaiveForecast[:OneWeekNPeriods] = np.nan\n\nfor i in range(OneWeekNPeriods, len(mergeData.AggregateLoad)):\n    NaiveForecast[i] = mergeData.AggregateLoad[i - OneWeekNPeriods]\n\nprint(NaiveForecast.info())\nprint(NaiveForecast.describe())","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:25:20.693269Z","iopub.execute_input":"2023-09-26T13:25:20.694330Z","iopub.status.idle":"2023-09-26T13:25:21.980260Z","shell.execute_reply.started":"2023-09-26T13:25:20.694280Z","shell.execute_reply":"2023-09-26T13:25:21.979027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize naive forecast\nprediction_plot(mergeData.AggregateLoad, NaiveForecast)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:25:28.169783Z","iopub.execute_input":"2023-09-26T13:25:28.170241Z","iopub.status.idle":"2023-09-26T13:25:28.898112Z","shell.execute_reply.started":"2023-09-26T13:25:28.170188Z","shell.execute_reply":"2023-09-26T13:25:28.897264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize naive forecast and actuals for first day of the test dataset\nprediction_plot(mergeData.AggregateLoad[train_size+test_size:train_size+test_size+OUT_STEPS], NaiveForecast[train_size+test_size:train_size+test_size+OUT_STEPS])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T21:04:47.808980Z","iopub.execute_input":"2023-09-25T21:04:47.809404Z","iopub.status.idle":"2023-09-25T21:04:48.081430Z","shell.execute_reply.started":"2023-09-25T21:04:47.809374Z","shell.execute_reply":"2023-09-25T21:04:48.080589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The average offer price for balancing actions  to align supply and demand  between the start of September and early January was 287 a MWh. Data from Elexon, which oversees the market, shows Rye House submitted the 20 highest winter bids  between 5,000 and 6,000 a MWh  for varying volumes of power on 12 December, setting new records\nhttps://www.theguardian.com/business/2023/jan/29/gas-fired-plants-uk-lights-on-cost-profits-energy-crisis","metadata":{}},{"cell_type":"code","source":"# Area Under Curve\nfrom scipy.integrate import simpson\nfrom numpy import trapz\n\n\n# The y values.  A numpy array is used here,\n# but a python list could also be used.\n# y = np.array([5, 20, 4, 18, 19, 18, 7, 4])\nyhat = NaiveForecast[train_size+test_size:train_size+test_size+OUT_STEPS]\n\n# Compute the area using the composite trapezoidal rule.\nyhatArea = trapz(yhat, dx=5)\nprint(\"yhat area =\", yhatArea)\n\n# Compute the area using the composite Simpson's rule.\nyhatArea = simpson(yhat, dx=5)\nprint(\"yhat area =\", yhatArea)\n\nyActual = mergeData.AggregateLoad[train_size+test_size:train_size+test_size+OUT_STEPS]\n\n# Compute the area using the composite trapezoidal rule.\nyActualArea = trapz(yActual, dx=5)\nprint(\"yActualArea =\", yActualArea)\n\n# Compute the area using the composite Simpson's rule.\nyActualArea = simpson(yActual, dx=5)\nprint(\"yActualArea =\", yActualArea)\n\n# Calculate the area difference between the two curves...\nAreaDifference = yhatArea - yActualArea\nprint(\"AreaDifference =\", AreaDifference)\n\n# calculate price at 287 a MWh\ncost = (AreaDifference / 1000) * 287\nprint(\"cost for 1 day for 5k homes =\", cost)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:25:38.796075Z","iopub.execute_input":"2023-09-26T13:25:38.796541Z","iopub.status.idle":"2023-09-26T13:25:38.808017Z","shell.execute_reply.started":"2023-09-26T13:25:38.796503Z","shell.execute_reply":"2023-09-26T13:25:38.806716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The population of England was 56,489,800 in 2021\n24.9 million dwellings in England\n\n","metadata":{}},{"cell_type":"code","source":"# Scale up costs\ncost = cost * (56000000/5000)\nprint(\"cost for 1 day for 5k homes =\", cost)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:25:47.048828Z","iopub.execute_input":"2023-09-26T13:25:47.049273Z","iopub.status.idle":"2023-09-26T13:25:47.055785Z","shell.execute_reply.started":"2023-09-26T13:25:47.049234Z","shell.execute_reply":"2023-09-26T13:25:47.054498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# normalize the naive \n# (NaiveForecast - train_mean) / train_std\nNaiveForecastNormed = NaiveForecast.transform(lambda x: (x - train_mean) / train_std)\nNaiveForecastNormed.describe()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:25:49.600162Z","iopub.execute_input":"2023-09-26T13:25:49.600844Z","iopub.status.idle":"2023-09-26T13:25:59.753508Z","shell.execute_reply.started":"2023-09-26T13:25:49.600808Z","shell.execute_reply":"2023-09-26T13:25:59.752394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize naive forecast and actuals for first day of the test dataset\nmergeDataNormed = (mergeData - train_mean) / train_std\nprediction_plot(mergeDataNormed.AggregateLoad[train_size+test_size:train_size+test_size+OUT_STEPS], NaiveForecastNormed.AggregateLoad[train_size+test_size:train_size+test_size+OUT_STEPS])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:33:56.436603Z","iopub.execute_input":"2023-09-26T13:33:56.437045Z","iopub.status.idle":"2023-09-26T13:33:56.853550Z","shell.execute_reply.started":"2023-09-26T13:33:56.437010Z","shell.execute_reply":"2023-09-26T13:33:56.852058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mergeDataNormed.AggregateLoad[train_size:train_size+val_size])\nprint(NaiveForecastNormed.AggregateLoad[train_size:train_size+val_size])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:36:32.609610Z","iopub.execute_input":"2023-09-26T13:36:32.610284Z","iopub.status.idle":"2023-09-26T13:36:32.620361Z","shell.execute_reply.started":"2023-09-26T13:36:32.610240Z","shell.execute_reply":"2023-09-26T13:36:32.619186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate error for naive model (Normed)\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n\n# calculate error for naive model on validation set\nvalNaiveMAE = mean_absolute_error(mergeDataNormed.AggregateLoad[train_size:train_size+val_size], NaiveForecastNormed.AggregateLoad[train_size:train_size+val_size])\n\n# calculate error for naive model on test set\ntestNaiveMAE = mean_absolute_error(mergeDataNormed.AggregateLoad[train_size+val_size:], NaiveForecastNormed.AggregateLoad[train_size+val_size:])\n\nprint('valNaiveMAE: ', valNaiveMAE)\nprint('testNaiveMAE: ', testNaiveMAE)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:42:17.979359Z","iopub.execute_input":"2023-09-26T13:42:17.979824Z","iopub.status.idle":"2023-09-26T13:42:17.993094Z","shell.execute_reply.started":"2023-09-26T13:42:17.979791Z","shell.execute_reply":"2023-09-26T13:42:17.991261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate error for naive model (not normed)\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\nprint('Naive Root Mean Squared Error(RMSE): %.2f; Naive Mean Absolute Error(MAE) : %.2f; Naive Mean Absolute Percantage Error(MAPE) : %.2f '\n      % (np.sqrt(mean_squared_error(mergeData.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])),\n         mean_absolute_error(mergeData.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:]),\n         mean_absolute_percentage_error(mergeData.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])))\n\n# calculate error for naive model on validation set\nvalNaiveMAE = mean_absolute_error(mergeData.AggregateLoad[train_size:train_size+val_size], NaiveForecast[train_size:train_size+val_size])\n\n# calculate error for naive model on test set\ntestNaiveMAE = mean_absolute_error(mergeData.AggregateLoad[train_size+val_size:], NaiveForecast[train_size+val_size:])\n\nprint('valNaiveMAE: ', valNaiveMAE)\nprint('testNaiveMAE: ', testNaiveMAE)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T13:26:23.961268Z","iopub.execute_input":"2023-09-26T13:26:23.961686Z","iopub.status.idle":"2023-09-26T13:26:24.255323Z","shell.execute_reply.started":"2023-09-26T13:26:23.961652Z","shell.execute_reply":"2023-09-26T13:26:24.254036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RepeatBaseline(tf.keras.Model):\n  def call(self, inputs):\n    return inputs\n\nrepeat_baseline = RepeatBaseline()\nrepeat_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n                        metrics=[tf.keras.metrics.MeanAbsoluteError()])\n\nmulti_val_performance['Naive'] = repeat_baseline.evaluate(mergeDataNormed.AggregateLoad[train_size:train_size+val_size], NaiveForecastNormed.AggregateLoad[train_size:train_size+val_size])\nmulti_performance['Naive'] = repeat_baseline.evaluate(mergeDataNormed.AggregateLoad[train_size+val_size:], NaiveForecastNormed.AggregateLoad[train_size+val_size:], verbose=0)\n\n# multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n# multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n# multi_window.plot(repeat_baseline)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T15:16:14.840049Z","iopub.execute_input":"2023-09-26T15:16:14.840582Z","iopub.status.idle":"2023-09-26T15:16:15.872477Z","shell.execute_reply.started":"2023-09-26T15:16:14.840540Z","shell.execute_reply":"2023-09-26T15:16:15.871160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_dense_model = tf.keras.Sequential([\n    # Take the last time step.\n    # Shape [batch, time, features] => [batch, 1, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n    # Shape => [batch, 1, dense_units]\n    tf.keras.layers.Dense(512, activation='relu'),\n    # Shape => [batch, out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_dense_model, multi_window)\nmulti_dense_model.save('multi_dense_model.keras')\n\n# IPython.display.clear_output()\nmulti_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\nmulti_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(multi_dense_model)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:08:46.124573Z","iopub.execute_input":"2023-09-26T16:08:46.125372Z","iopub.status.idle":"2023-09-26T16:09:13.504210Z","shell.execute_reply.started":"2023-09-26T16:08:46.125334Z","shell.execute_reply":"2023-09-26T16:09:13.503022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONV_WIDTH = 10\nmulti_conv_model = tf.keras.Sequential([\n    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n    # Shape => [batch, 1, conv_units]\n    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n    # Shape => [batch, 1,  out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_conv_model, multi_window)\nmulti_conv_model.save('multi_conv_model.keras')\n# IPython.display.clear_output()\n\nmulti_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\nmulti_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(multi_conv_model)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T15:18:15.884265Z","iopub.execute_input":"2023-09-26T15:18:15.885523Z","iopub.status.idle":"2023-09-26T15:18:59.694107Z","shell.execute_reply.started":"2023-09-26T15:18:15.885468Z","shell.execute_reply":"2023-09-26T15:18:59.693236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_rnn_model = tf.keras.Sequential([\n    # Shape [batch, time, features] => [batch, lstm_units].\n    # Adding more `lstm_units` just overfits more quickly.\n    tf.keras.layers.SimpleRNN(32, return_sequences=False),\n    # Shape => [batch, out_steps*features].\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features].\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_rnn_model, multi_window)\nmulti_rnn_model.save('multi_rnn_model.keras')\n# IPython.display.clear_output()\n\nmulti_val_performance['RNN'] = multi_rnn_model.evaluate(multi_window.val)\nmulti_performance['RNN'] = multi_rnn_model.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(multi_rnn_model)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T15:18:59.695625Z","iopub.execute_input":"2023-09-26T15:18:59.696215Z","iopub.status.idle":"2023-09-26T15:25:39.655695Z","shell.execute_reply.started":"2023-09-26T15:18:59.696166Z","shell.execute_reply":"2023-09-26T15:25:39.654381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_lstm_model = tf.keras.Sequential([\n    # Shape [batch, time, features] => [batch, lstm_units].\n    # Adding more `lstm_units` just overfits more quickly.\n    tf.keras.layers.LSTM(32, return_sequences=False),\n    # Shape => [batch, out_steps*features].\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features].\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_lstm_model, multi_window)\nmulti_lstm_model.save('multi_lstm_model.keras')\n# IPython.display.clear_output()\n\nmulti_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\nmulti_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(multi_lstm_model)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T15:25:39.658257Z","iopub.execute_input":"2023-09-26T15:25:39.658618Z","iopub.status.idle":"2023-09-26T15:35:28.695792Z","shell.execute_reply.started":"2023-09-26T15:25:39.658587Z","shell.execute_reply":"2023-09-26T15:35:28.694703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.arange(len(multi_performance))\nwidth = 0.3\n\nmetric_name = 'mean_absolute_error'\nmetric_index = multi_lstm_model.metrics_names.index('mean_absolute_error')\nval_mae = [v[metric_index] for v in multi_val_performance.values()]\ntest_mae = [v[metric_index] for v in multi_performance.values()]\n\nplt.bar(x - 0.17, val_mae, width, label='Validation')\nplt.bar(x + 0.17, test_mae, width, label='Test')\nplt.xticks(ticks=x, labels=multi_performance.keys(),\n           rotation=45)\nplt.ylabel(f'MAE (average over all times and outputs)')\n_ = plt.legend()\nplt.savefig('model performance.png', format='png')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:22:59.821524Z","iopub.execute_input":"2023-09-26T16:22:59.822000Z","iopub.status.idle":"2023-09-26T16:23:00.249312Z","shell.execute_reply.started":"2023-09-26T16:22:59.821966Z","shell.execute_reply":"2023-09-26T16:23:00.248119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build a single record dataset from start of the test dataset\nprint(mergeDataNormed)\nprint(train_size+test_size-IN_STEPS)\nprint(mergeDataNormed.iloc[train_size+test_size-IN_STEPS:train_size+test_size])\n\nds = tf.keras.utils.timeseries_dataset_from_array(\n      data=test_data[:IN_STEPS],\n      targets=None,\n      sequence_length=IN_STEPS,\n      sequence_stride=1,\n      shuffle=False,\n      batch_size=32,)\n\ntestYhatNormed = multi_lstm_model.predict(ds)\n\n#     data=test_data[:IN_STEPS],\n# data=mergeDataNormed[train_size+test_size-IN_STEPS:train_size+test_size],","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:49:34.441306Z","iopub.execute_input":"2023-09-26T20:49:34.441816Z","iopub.status.idle":"2023-09-26T20:49:34.761410Z","shell.execute_reply.started":"2023-09-26T20:49:34.441782Z","shell.execute_reply":"2023-09-26T20:49:34.759702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(testYhatNormed)\nprint(testYhatNormed[0,:,-1])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:49:50.715906Z","iopub.execute_input":"2023-09-26T20:49:50.716778Z","iopub.status.idle":"2023-09-26T20:49:50.732679Z","shell.execute_reply.started":"2023-09-26T20:49:50.716729Z","shell.execute_reply":"2023-09-26T20:49:50.730936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Invert stabdardization\ntestYhat = (np.array(testYhatNormed) * np.array(train_std)) + np.array(train_mean)\n\nprint(testYhat)\nprint(testYhat[0,:,-1])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:09:22.877923Z","iopub.execute_input":"2023-09-26T21:09:22.879171Z","iopub.status.idle":"2023-09-26T21:09:22.897955Z","shell.execute_reply.started":"2023-09-26T21:09:22.879088Z","shell.execute_reply":"2023-09-26T21:09:22.896606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for plotting the train and test loss curves\ndef model_loss(history):\n    plt.figure(figsize=(8,4))\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Test Loss')\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epochs')\n    plt.legend(loc='upper right')\n    plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-26T15:35:29.974096Z","iopub.execute_input":"2023-09-26T15:35:29.974498Z","iopub.status.idle":"2023-09-26T15:35:29.984658Z","shell.execute_reply.started":"2023-09-26T15:35:29.974459Z","shell.execute_reply":"2023-09-26T15:35:29.983462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN-LSTM","metadata":{"execution":{"iopub.status.busy":"2023-09-26T15:35:29.986222Z","iopub.execute_input":"2023-09-26T15:35:29.986565Z","iopub.status.idle":"2023-09-26T15:35:29.996285Z","shell.execute_reply.started":"2023-09-26T15:35:29.986536Z","shell.execute_reply":"2023-09-26T15:35:29.995308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot of naive, LSTM and actuals","metadata":{}},{"cell_type":"code","source":"      len_prediction=[x for x in range(len(testYhat[0,:,-1]))]\n      plt.figure(figsize=(10,5))\n      # plt.plot(len_prediction, test_data[:OUT_STEPS].AggregateLoad, marker='.', label=\"actual\")\n      plt.plot(len_prediction, mergeDataNormed.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS], marker='.', label=\"actual\")\n      plt.plot(len_prediction, testYhatNormed[0,:,-1], 'r', label=\"LSTM prediction\")\n      plt.plot(len_prediction, NaiveForecastNormed[train_size+val_size:train_size+val_size+OUT_STEPS].AggregateLoad, 'g', label=\"Naive prediction\")\n        \n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour (Normed)', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show();\n      plt.savefig('Test First Day Normed.png', format='png')\n\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:11:30.751619Z","iopub.execute_input":"2023-09-26T21:11:30.752303Z","iopub.status.idle":"2023-09-26T21:11:31.334122Z","shell.execute_reply.started":"2023-09-26T21:11:30.752259Z","shell.execute_reply":"2023-09-26T21:11:31.332136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"      len_prediction=[x for x in range(len(testYhat[0,:,-1]))]\n      plt.figure(figsize=(10,5))\n      # plt.plot(len_prediction, test_data[:OUT_STEPS].AggregateLoad, marker='.', label=\"actual\")\n      plt.plot(len_prediction, mergeData.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS], marker='.', label=\"actual\")\n      plt.plot(len_prediction, testYhat[0,:,-1], 'r', label=\"LSTM prediction\")\n      plt.plot(len_prediction, NaiveForecast[train_size+val_size:train_size+val_size+OUT_STEPS], 'g', label=\"Naive prediction\")\n        \n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show()\n      plt.savefig('Test First Day.png', format='png')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:14:23.393705Z","iopub.execute_input":"2023-09-26T21:14:23.395015Z","iopub.status.idle":"2023-09-26T21:14:23.870714Z","shell.execute_reply.started":"2023-09-26T21:14:23.394943Z","shell.execute_reply":"2023-09-26T21:14:23.869238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Estimate financial impact of improved forecast","metadata":{}},{"cell_type":"code","source":"# Area Under Curve\nfrom scipy.integrate import simpson\nfrom numpy import trapz\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T15:35:30.387175Z","iopub.execute_input":"2023-09-26T15:35:30.387938Z","iopub.status.idle":"2023-09-26T15:35:30.393502Z","shell.execute_reply.started":"2023-09-26T15:35:30.387897Z","shell.execute_reply":"2023-09-26T15:35:30.392169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# install AutoGluon AutoML\n!pip install autogluon\nfrom autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor","metadata":{"execution":{"iopub.status.busy":"2023-09-26T15:35:30.394876Z","iopub.execute_input":"2023-09-26T15:35:30.395459Z","iopub.status.idle":"2023-09-26T15:39:06.757617Z","shell.execute_reply.started":"2023-09-26T15:35:30.395403Z","shell.execute_reply":"2023-09-26T15:39:06.756481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoData = pd.read_csv('/kaggle/working/autoDataFinal.csv')\nautoData","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:07:47.755408Z","iopub.execute_input":"2023-09-26T16:07:47.756548Z","iopub.status.idle":"2023-09-26T16:07:47.905363Z","shell.execute_reply.started":"2023-09-26T16:07:47.756508Z","shell.execute_reply":"2023-09-26T16:07:47.903996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AutoGluon specific data preparation\n# Split the time series data into train, test, and validation datasets\ntrain_size = int(len(autoData) * 0.7)  # 70% for training\nval_size = int(len(autoData) * 0.2)   # 20% for validation\ntest_size = len(autoData) - val_size - test_size  # Remaining for testing\n\nag_train_data = autoData[:train_size]\nag_val_data = autoData[train_size:train_size+val_size]\nag_test_data = autoData[train_size+val_size:]\n\nprint('ag_train_data:\\n', ag_train_data)\nprint('ag_val_data:\\n', ag_val_data)\nprint('ag_test_data\\n', ag_test_data)\n# print(ag_train_data.info())\n\n# AutoGluon requires an ItemID Column, so adding one...\nag_train_data['item_id'] = 'LoadSum'\nag_train_data = ag_train_data.astype({\"item_id\": str})\nag_val_data['item_id'] = 'LoadSum'\nag_val_data = ag_val_data.astype({\"item_id\": str})\nag_test_data['item_id'] = 'LoadSum'\nag_test_data = ag_test_data.astype({\"item_id\": str})\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:58:13.138045Z","iopub.execute_input":"2023-09-26T16:58:13.139090Z","iopub.status.idle":"2023-09-26T16:58:13.181470Z","shell.execute_reply.started":"2023-09-26T16:58:13.139047Z","shell.execute_reply":"2023-09-26T16:58:13.180231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take a quick look at the split datasets\nprint('ag_train_data\\n', ag_train_data)\nprint('ag_val_data\\n', ag_val_data)\nprint('ag_test_data\\n', ag_test_data)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:58:13.183476Z","iopub.execute_input":"2023-09-26T16:58:13.183801Z","iopub.status.idle":"2023-09-26T16:58:13.211460Z","shell.execute_reply.started":"2023-09-26T16:58:13.183772Z","shell.execute_reply":"2023-09-26T16:58:13.210348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load training data in to required AutoGluon proprietary data frame\n# print(ag_train_data.info())\nag_train_data_tsdf = TimeSeriesDataFrame.from_data_frame(\n    ag_train_data,\n    id_column=\"item_id\",\n    timestamp_column=\"DateTime\"\n)\nag_train_data_tsdf","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:58:13.212970Z","iopub.execute_input":"2023-09-26T16:58:13.213309Z","iopub.status.idle":"2023-09-26T16:58:13.326721Z","shell.execute_reply.started":"2023-09-26T16:58:13.213280Z","shell.execute_reply":"2023-09-26T16:58:13.325583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load validation data in to required AutoGluon proprietary data frame, \"_tsdf\" suffix = time series data frame\nag_val_data_tsdf = TimeSeriesDataFrame.from_data_frame(\n    ag_val_data,\n    id_column=\"item_id\",\n    timestamp_column=\"DateTime\"\n)\nag_val_data_tsdf","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:58:13.329892Z","iopub.execute_input":"2023-09-26T16:58:13.330448Z","iopub.status.idle":"2023-09-26T16:58:13.378596Z","shell.execute_reply.started":"2023-09-26T16:58:13.330406Z","shell.execute_reply":"2023-09-26T16:58:13.377526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load test data in to required AutoGluon proprietary data frame\n# print(ag_test_data.info())\nag_test_data_tsdf = TimeSeriesDataFrame.from_data_frame(\n    ag_test_data,\n    id_column=\"item_id\",\n    timestamp_column=\"DateTime\"\n)\nag_test_data_tsdf","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:58:13.379917Z","iopub.execute_input":"2023-09-26T16:58:13.380265Z","iopub.status.idle":"2023-09-26T16:58:13.418262Z","shell.execute_reply.started":"2023-09-26T16:58:13.380236Z","shell.execute_reply":"2023-09-26T16:58:13.417259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# at \"high_quality\" level, training takes about 45 minutes...\n# training takes about 15 minutes for DeepAR\n# training takes about 21 minutes for TemporalFusionTransformer\n# training takes about 4 minutes for PatchTST\n# training takes about 4 minutes for PatchTST","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:58:13.420078Z","iopub.execute_input":"2023-09-26T16:58:13.420554Z","iopub.status.idle":"2023-09-26T16:58:13.425829Z","shell.execute_reply.started":"2023-09-26T16:58:13.420513Z","shell.execute_reply":"2023-09-26T16:58:13.424710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ag_predictor = TimeSeriesPredictor(\n    prediction_length=48,\n    path=\"autogluon-london-half-hourly\",\n    target=\"AggregateLoad\",\n    eval_metric=\"MASE\",\n)\n\nag_predictor.fit(\n    ag_train_data_tsdf,\n    presets=\"medium_quality\",\n    time_limit=6000,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T16:58:13.427465Z","iopub.execute_input":"2023-09-26T16:58:13.427880Z","iopub.status.idle":"2023-09-26T17:15:15.459764Z","shell.execute_reply.started":"2023-09-26T16:58:13.427839Z","shell.execute_reply":"2023-09-26T17:15:15.458719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The test score is computed using the last\n# prediction_length=48 timesteps of each time series in test_data\nag_predictor.leaderboard(ag_val_data_tsdf, silent=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:15:15.461838Z","iopub.execute_input":"2023-09-26T17:15:15.462998Z","iopub.status.idle":"2023-09-26T17:16:32.723725Z","shell.execute_reply.started":"2023-09-26T17:15:15.462959Z","shell.execute_reply":"2023-09-26T17:16:32.722563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate predictions\nag_predictions = ag_predictor.predict(ag_val_data_tsdf)\nag_predictions.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:16:32.725403Z","iopub.execute_input":"2023-09-26T17:16:32.725786Z","iopub.status.idle":"2023-09-26T17:17:11.774267Z","shell.execute_reply.started":"2023-09-26T17:16:32.725749Z","shell.execute_reply":"2023-09-26T17:17:11.773425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_mean)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:49:27.811651Z","iopub.execute_input":"2023-09-26T21:49:27.812168Z","iopub.status.idle":"2023-09-26T21:49:27.821263Z","shell.execute_reply.started":"2023-09-26T21:49:27.812129Z","shell.execute_reply":"2023-09-26T21:49:27.819920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# standardize the predictions so we can compare prediction errors with other models\nag_predictionsNormed = (ag_predictions[\"mean\"] - train_mean[\"AggregateLoad\"]) / train_std[\"AggregateLoad\"]\nag_predictionsNormed","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:51:40.836309Z","iopub.execute_input":"2023-09-26T21:51:40.836717Z","iopub.status.idle":"2023-09-26T21:51:40.850224Z","shell.execute_reply.started":"2023-09-26T21:51:40.836685Z","shell.execute_reply":"2023-09-26T21:51:40.848924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot prediction results, history and actual test data values\nplt.figure(figsize=(20, 3))\n\nitem_id = \"LoadSum\"\ny_past = ag_val_data_tsdf.loc[item_id][\"AggregateLoad\"]\ny_pred = ag_predictions.loc[item_id]\ny_val = ag_test_data_tsdf.loc[item_id][\"AggregateLoad\"]\n# y_val = ag_val_data_tsdf.loc[item_id][\"AggregateLoad\"]\n\nplt.plot(y_past[-100:], label=\"Past time series values\")\nplt.plot(y_pred[\"mean\"], label=\"Mean forecast\")\nplt.plot(y_val[:48], label=\"Future time series values\")\n\nplt.fill_between(\n    y_pred.index, y_pred[\"0.1\"], y_pred[\"0.9\"], color=\"red\", alpha=0.1, label=f\"10%-90% confidence interval\"\n)\nplt.legend();\nplt.savefig('AutoML forecast.png', format='png')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:17:11.777529Z","iopub.execute_input":"2023-09-26T17:17:11.778054Z","iopub.status.idle":"2023-09-26T17:17:12.331523Z","shell.execute_reply.started":"2023-09-26T17:17:11.778024Z","shell.execute_reply":"2023-09-26T17:17:12.330345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# load test data in to required AutoGluon proprietary data frame\n# print(ag_test_data.info())\nag_testday1_data_tsdf = TimeSeriesDataFrame.from_data_frame(\n    ag_val_data[-IN_STEPS:],\n    id_column=\"item_id\",\n    timestamp_column=\"DateTime\"\n)\nag_testday1_data_tsdf","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:30:09.433982Z","iopub.execute_input":"2023-09-26T20:30:09.434519Z","iopub.status.idle":"2023-09-26T20:30:09.475392Z","shell.execute_reply.started":"2023-09-26T20:30:09.434483Z","shell.execute_reply":"2023-09-26T20:30:09.474143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate predictions\nagTestDay1_predictions = ag_predictor.predict(ag_testday1_data_tsdf)\nagTestDay1_predictions.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:30:17.939653Z","iopub.execute_input":"2023-09-26T20:30:17.940448Z","iopub.status.idle":"2023-09-26T20:31:11.905821Z","shell.execute_reply.started":"2023-09-26T20:30:17.940407Z","shell.execute_reply":"2023-09-26T20:31:11.904325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agTestDay1_predictions","metadata":{"execution":{"iopub.status.busy":"2023-09-26T20:32:13.398938Z","iopub.execute_input":"2023-09-26T20:32:13.399478Z","iopub.status.idle":"2023-09-26T20:32:13.444696Z","shell.execute_reply.started":"2023-09-26T20:32:13.399433Z","shell.execute_reply":"2023-09-26T20:32:13.443406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"      len_prediction=[x for x in range(len(testYhat[0,:,-1]))]\n      plt.figure(figsize=(10,5))\n      # plt.plot(len_prediction, test_data[:OUT_STEPS].AggregateLoad, marker='.', label=\"actual\")\n      plt.plot(len_prediction, mergeData.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS], marker='.', label=\"actual\")\n      plt.plot(len_prediction, testYhat[0,:,-1], 'r', label=\"LSTM prediction\")\n      plt.plot(len_prediction, NaiveForecast[train_size+val_size:train_size+val_size+OUT_STEPS], 'g', label=\"Naive prediction\")\n      plt.plot(len_prediction, agTestDay1_predictions[\"mean\"], 'y', label=\"AutoML prediction\")\n        \n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show()\n      plt.savefig('Test First Day.png', format='png')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T21:23:52.910928Z","iopub.execute_input":"2023-09-26T21:23:52.911480Z","iopub.status.idle":"2023-09-26T21:23:53.334643Z","shell.execute_reply.started":"2023-09-26T21:23:52.911441Z","shell.execute_reply":"2023-09-26T21:23:53.333393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate error for naive model on validation set\n# valAutoMLMAE = mean_absolute_error(mergeDataNormed.AggregateLoad[train_size:train_size+val_size], ag_predictionsNormed[train_size:train_size+val_size])\n\n# calculate error for naive model on test set\ntestAutoMLMAE = mean_absolute_error(mergeDataNormed.AggregateLoad[train_size+val_size:], ag_predictionsNormed)\n\n# print('valAutoMLMAE: ', valAutoMLMAE)\nprint('testAutoMLMAE: ', testAutoMLMAE)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T22:16:45.347502Z","iopub.execute_input":"2023-09-26T22:16:45.348044Z","iopub.status.idle":"2023-09-26T22:16:46.514568Z","shell.execute_reply.started":"2023-09-26T22:16:45.348005Z","shell.execute_reply":"2023-09-26T22:16:46.512769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import dill\n# save\ndill.dump_session('notebook_env.db')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:17:12.333491Z","iopub.execute_input":"2023-09-26T17:17:12.334153Z","iopub.status.idle":"2023-09-26T17:17:24.175604Z","shell.execute_reply.started":"2023-09-26T17:17:12.334118Z","shell.execute_reply":"2023-09-26T17:17:24.174288Z"},"trusted":true},"execution_count":null,"outputs":[]}]}