{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Short-term residential load forecasting with Deep Learning\n\nLondon Households SmartMeter Data","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-12T22:45:57.997699Z","iopub.execute_input":"2023-09-12T22:45:57.998229Z","iopub.status.idle":"2023-09-12T22:45:58.208179Z","shell.execute_reply.started":"2023-09-12T22:45:57.998184Z","shell.execute_reply":"2023-09-12T22:45:58.207258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#!pip install -U pip\n#!pip install -U setuptools wheel\n\n#!pip install autogluon\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:58.210227Z","iopub.execute_input":"2023-09-12T22:45:58.210676Z","iopub.status.idle":"2023-09-12T22:45:58.216793Z","shell.execute_reply.started":"2023-09-12T22:45:58.210634Z","shell.execute_reply":"2023-09-12T22:45:58.215582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creat two load forecasts...\n1) half-hourly load forecast for next 24 hours\n2) peak half-hour in the next 24 hours\n\nValue...\n* For electric network operator, minimize the amount of spinning reserve\n\nData...\n* residential smart meter usage data\n* weather data\n* weather forecast data","metadata":{}},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"# load half-hourly electric usage data\n# https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households\nd = pd.read_csv('/kaggle/input/small-lcl-data/LCL-June2015v2_99.csv', parse_dates=[\"DateTime\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:58.218509Z","iopub.execute_input":"2023-09-12T22:45:58.219629Z","iopub.status.idle":"2023-09-12T22:45:59.938762Z","shell.execute_reply.started":"2023-09-12T22:45:58.219590Z","shell.execute_reply":"2023-09-12T22:45:59.937235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:59.941976Z","iopub.execute_input":"2023-09-12T22:45:59.942897Z","iopub.status.idle":"2023-09-12T22:46:00.424268Z","shell.execute_reply.started":"2023-09-12T22:45:59.942842Z","shell.execute_reply":"2023-09-12T22:46:00.422746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert usage to floats\n# print(d.iloc[3])\nd.iloc[:, 3] = pd.to_numeric(d.iloc[:, 3], errors='coerce')\n# print(d.dtypes)\n# rename usage column for easier reference\n#d.rename(columns={\"KWH/hh (per half hour)\": \"KWHperHH\"}, inplace=True)\nd.rename(columns={d.columns[3]: 'KWHperHH'}, inplace=True)\n# d.rename_col_by_index(3, 'KWHperHH')\nd.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:00.425839Z","iopub.execute_input":"2023-09-12T22:46:00.426316Z","iopub.status.idle":"2023-09-12T22:46:01.095713Z","shell.execute_reply.started":"2023-09-12T22:46:00.426271Z","shell.execute_reply":"2023-09-12T22:46:01.093441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set timestamp as the index\nd.set_index('DateTime')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:01.097635Z","iopub.execute_input":"2023-09-12T22:46:01.098137Z","iopub.status.idle":"2023-09-12T22:46:01.152534Z","shell.execute_reply.started":"2023-09-12T22:46:01.098088Z","shell.execute_reply":"2023-09-12T22:46:01.148782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\n\nprofile = ProfileReport(d, tsmode=True, sortby=\"DateTime\")\nprofile.to_file('profile_report.html')\nprofile","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:01.154216Z","iopub.execute_input":"2023-09-12T22:46:01.154689Z","iopub.status.idle":"2023-09-12T22:46:23.677024Z","shell.execute_reply.started":"2023-09-12T22:46:01.154645Z","shell.execute_reply":"2023-09-12T22:46:23.675714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize and handle duplicates\n# d = d.drop_duplicates()\nprint(d.groupby(d.columns.tolist(),as_index=False).size())\ndupes = d[d.duplicated()]\nprint('dupes', dupes)\nprint('dupes.index', dupes.index)\nd = d.drop(index=dupes.index)\n\nd.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:23.678906Z","iopub.execute_input":"2023-09-12T22:46:23.680031Z","iopub.status.idle":"2023-09-12T22:46:24.999525Z","shell.execute_reply.started":"2023-09-12T22:46:23.679982Z","shell.execute_reply":"2023-09-12T22:46:24.998609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d.set_index('DateTime')\nd.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:25.000680Z","iopub.execute_input":"2023-09-12T22:46:25.001557Z","iopub.status.idle":"2023-09-12T22:46:25.837568Z","shell.execute_reply.started":"2023-09-12T22:46:25.001517Z","shell.execute_reply":"2023-09-12T22:46:25.836211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize smart meter dataset to anayze for quality, completenes and othe insights","metadata":{}},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:25.840816Z","iopub.execute_input":"2023-09-12T22:46:25.841190Z","iopub.status.idle":"2023-09-12T22:46:25.846580Z","shell.execute_reply.started":"2023-09-12T22:46:25.841158Z","shell.execute_reply":"2023-09-12T22:46:25.845124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize meter read coverage and completeness\npivot_table = pd.pivot_table(d, columns='DateTime', index='LCLid', values='KWHperHH')\n# print(pivot_table)\nplt.subplots(figsize=(20,15))\nsns.heatmap(pivot_table)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:25.848299Z","iopub.execute_input":"2023-09-12T22:46:25.848756Z","iopub.status.idle":"2023-09-12T22:46:35.235397Z","shell.execute_reply.started":"2023-09-12T22:46:25.848710Z","shell.execute_reply":"2023-09-12T22:46:35.234176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations from Heatmap...\n* several houses start producing load part-way through the period\n    - eg MAC004221, MAC004248\n    \n    \n* several houses stop producing part-way through the period\n    - eg MAC004226, MAC004257\n    \n\n* most houses have at least one \"gap\" in their data (visible as white lines)\n\n\n* several houses stand out as having significantly higher average load than others\n    - eg MAC004225, MAC004249","metadata":{}},{"cell_type":"code","source":"# inspect and remove records not exactly on the half-hour\noffRecs = d.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\n# aggLoad[\"DateTime\"].dt.hour > 30\nprint('Records not exactly on the half-hour:\\n ', offRecs)\nprint(offRecs.info())\n\n# delete records not exactly on the half-hour\nd = d.drop(offRecs.index)\n\noffRecs = d.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\nprint('Records not exactly on the half-hour: ', offRecs)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:35.236931Z","iopub.execute_input":"2023-09-12T22:46:35.238010Z","iopub.status.idle":"2023-09-12T22:46:35.751103Z","shell.execute_reply.started":"2023-09-12T22:46:35.237957Z","shell.execute_reply":"2023-09-12T22:46:35.750079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:35.752359Z","iopub.execute_input":"2023-09-12T22:46:35.752684Z","iopub.status.idle":"2023-09-12T22:46:36.061000Z","shell.execute_reply.started":"2023-09-12T22:46:35.752654Z","shell.execute_reply":"2023-09-12T22:46:36.059817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First step of interpolation is to create NaN records where records are missing\ndf = d.copy()\ndf.info()\ndf = df.sort_values(by=['DateTime'])\ndf = df.set_index('DateTime')\ndf.index.rename('DateTime', inplace=True)\ndf.info()\n\n# df['datetime'] = pd.to_datetime(df['datetime'])\n# df.index = df['datetime']\n# del df['datetime']\n\ndf_interpol = df.groupby('LCLid')\\\n                .resample('30Min')\\\n                .mean()\ndf_interpol['KWHperHH'] = df_interpol['KWHperHH'].interpolate()\ndf_interpol.info()\ndf_interpol = df_interpol.reset_index()\n\n# df_interpol['LCLid'], df_interpol['DateTime'] = df_interpol.index\ndf_interpol.head(4)\ndf_interpol.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:36.062792Z","iopub.execute_input":"2023-09-12T22:46:36.063257Z","iopub.status.idle":"2023-09-12T22:46:37.578504Z","shell.execute_reply.started":"2023-09-12T22:46:36.063214Z","shell.execute_reply":"2023-09-12T22:46:37.576898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize after interpolating missing values\ndf_interpol.info()\npivot_table = pd.pivot_table(df_interpol, columns='DateTime', index='LCLid', values='KWHperHH')\nplt.subplots(figsize=(20,15))\n\nsns.heatmap(pivot_table)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:37.579999Z","iopub.execute_input":"2023-09-12T22:46:37.580516Z","iopub.status.idle":"2023-09-12T22:46:46.825328Z","shell.execute_reply.started":"2023-09-12T22:46:37.580466Z","shell.execute_reply":"2023-09-12T22:46:46.824195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize zeros in the dataset\ndf_interpol.info()\ndf_interpol['ZeroKWHperHH'] = df_interpol['KWHperHH'] == 0\npivot_table = pd.pivot_table(df_interpol, columns='DateTime', index='LCLid', values='ZeroKWHperHH')\nplt.subplots(figsize=(20,15))\n\nsns.heatmap(pivot_table)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:46.826907Z","iopub.execute_input":"2023-09-12T22:46:46.827699Z","iopub.status.idle":"2023-09-12T22:46:56.169373Z","shell.execute_reply.started":"2023-09-12T22:46:46.827652Z","shell.execute_reply":"2023-09-12T22:46:56.168189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obervation: there are a handful of households that account all the zero value meter reads: MAC004233, MAC004226, MAC004267","metadata":{}},{"cell_type":"code","source":"# investigate the meters with zero reads\nMAC004233 = df_interpol.query(\"LCLid == 'MAC004233'\")\n\nfig, ax = plt.subplots(4,figsize=(20,9))\n\n# plot whole ~2 years\nax[0].plot(MAC004233.DateTime, MAC004233.KWHperHH)\nax[0].plot(MAC004233.DateTime, MAC004233.ZeroKWHperHH)\nax[0].set(ylabel='KWH/hh',\n       title='Load from one Household MAC004233 with lots of zero values')\nplt.tick_params(rotation=45)\nax[0].grid()\n\n# zoom in\nax[1].plot(MAC004233.DateTime[11000:15000], MAC004233.KWHperHH[11000:15000])\nax[1].plot(MAC004233.DateTime[11000:15000], MAC004233.ZeroKWHperHH[11000:15000])\nax[1].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[1].grid()\n\n# zoom in more...\nax[2].plot(MAC004233.DateTime[13000:13500], MAC004233.KWHperHH[13000:13500])\nax[2].plot(MAC004233.DateTime[13000:13500], MAC004233.ZeroKWHperHH[13000:13500])\nax[2].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[2].grid()\n\n# zoom in to a different part of the series...\nax[3].plot(MAC004233.DateTime[25000:25500], MAC004233.KWHperHH[25000:25500])\nax[3].plot(MAC004233.DateTime[25000:25500], MAC004233.ZeroKWHperHH[25000:25500])\nax[3].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[3].grid()\n\nfig.savefig(\"MAC004233.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:56.170846Z","iopub.execute_input":"2023-09-12T22:46:56.171302Z","iopub.status.idle":"2023-09-12T22:46:57.816073Z","shell.execute_reply.started":"2023-09-12T22:46:56.171268Z","shell.execute_reply":"2023-09-12T22:46:57.814798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n\nThe zeros for MAC004233 seem legit - leaving them in","metadata":{}},{"cell_type":"code","source":"# investigate the meters with zero reads\nMAC004267 = df_interpol.query(\"LCLid == 'MAC004267'\")\nfig, ax = plt.subplots(4,figsize=(20,9))\n\n# plot whole ~2 years\nax[0].plot(MAC004267.DateTime, MAC004267.KWHperHH)\nax[0].plot(MAC004267.DateTime, MAC004267.ZeroKWHperHH)\nax[0].set(ylabel='KWH/hh',\n       title='Load from one Household MAC004233 with lots of zero values')\nplt.tick_params(rotation=45)\nax[0].grid()\n\n# zoom in\nax[1].plot(MAC004267.DateTime[17000:21000], MAC004267.KWHperHH[17000:21000])\nax[1].plot(MAC004267.DateTime[17000:21000], MAC004267.ZeroKWHperHH[17000:21000])\nax[1].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[1].grid()\n\n# zoom in more...\nax[2].plot(MAC004267.DateTime[19300:19800], MAC004267.KWHperHH[19300:19800])\nax[2].plot(MAC004267.DateTime[19300:19800], MAC004267.ZeroKWHperHH[19300:19800])\nax[2].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[2].grid()\n\n# zoom in to a different part of the series...\nax[3].plot(MAC004267.DateTime[25000:25500], MAC004267.KWHperHH[25000:25500])\nax[3].plot(MAC004267.DateTime[25000:25500], MAC004267.ZeroKWHperHH[25000:25500])\nax[3].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[3].grid()\n\nfig.savefig(\"MAC004233.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:57.817439Z","iopub.execute_input":"2023-09-12T22:46:57.817758Z","iopub.status.idle":"2023-09-12T22:46:59.270372Z","shell.execute_reply.started":"2023-09-12T22:46:57.817729Z","shell.execute_reply":"2023-09-12T22:46:59.269121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation\n\nThe zeros for MAC004233 seem legit - leaving them in\n","metadata":{}},{"cell_type":"code","source":"# visualize and handle outliers\nd = df_interpol.copy()\n\n# minumum and maximum timestamp for each house\nprint(d.groupby('LCLid').max().sort_values('DateTime'))\nprint(d.groupby('LCLid').min().sort_values('DateTime'))\nprint(d.groupby('LCLid').count().sort_values('DateTime'))\n\nprint(d.groupby('LCLid').agg(['min', 'max', 'count']))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:59.272378Z","iopub.execute_input":"2023-09-12T22:46:59.272809Z","iopub.status.idle":"2023-09-12T22:46:59.776698Z","shell.execute_reply.started":"2023-09-12T22:46:59.272769Z","shell.execute_reply":"2023-09-12T22:46:59.775524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# which house has the highest peak load?\n\n# which house has the highest total aggregate load?\n\n# how variable / predictable is the timing of the peak load\n\n# how accurate is the next 24 hours forecast profile overall?\n\n# how accurate is the peak load forecast in next 24 hours?\n\n# normalize and standardize\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:59.778429Z","iopub.execute_input":"2023-09-12T22:46:59.778887Z","iopub.status.idle":"2023-09-12T22:46:59.786072Z","shell.execute_reply.started":"2023-09-12T22:46:59.778841Z","shell.execute_reply":"2023-09-12T22:46:59.784694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract one smartmeter for plotting\nsample = d.query(\"LCLid == 'MAC004233'\")\nsample","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:59.787464Z","iopub.execute_input":"2023-09-12T22:46:59.787859Z","iopub.status.idle":"2023-09-12T22:46:59.839561Z","shell.execute_reply.started":"2023-09-12T22:46:59.787824Z","shell.execute_reply":"2023-09-12T22:46:59.838370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize load profile for one household meter\nfig, ax = plt.subplots()\nax.plot(sample.iloc[100:4500,1], sample.iloc[100:4500,2])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Load from one Household, June-September 2012')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:46:59.841067Z","iopub.execute_input":"2023-09-12T22:46:59.841439Z","iopub.status.idle":"2023-09-12T22:47:00.327562Z","shell.execute_reply.started":"2023-09-12T22:46:59.841404Z","shell.execute_reply":"2023-09-12T22:47:00.326367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:47:00.329325Z","iopub.execute_input":"2023-09-12T22:47:00.331384Z","iopub.status.idle":"2023-09-12T22:47:00.344923Z","shell.execute_reply.started":"2023-09-12T22:47:00.331334Z","shell.execute_reply":"2023-09-12T22:47:00.343574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.DateTime.dtype\nsample.set_index('DateTime')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:47:00.346839Z","iopub.execute_input":"2023-09-12T22:47:00.347305Z","iopub.status.idle":"2023-09-12T22:47:00.368441Z","shell.execute_reply.started":"2023-09-12T22:47:00.347263Z","shell.execute_reply":"2023-09-12T22:47:00.367220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA: Visualize daily average load for each meter and all meters...","metadata":{}},{"cell_type":"code","source":"# calculate avearge daily load for each meter...\n# work with a copy of dataset...\nMeterData = df_interpol.copy()\n\navgLoadProfile = pd.DataFrame(MeterData.groupby([MeterData['DateTime'].dt.hour, MeterData['DateTime'].dt.minute]).KWHperHH.mean())\navgLoadProfile = avgLoadProfile.reset_index(names=['hour', 'minute'])\navgLoadProfile['labels'] = pd.to_datetime(avgLoadProfile['hour'].astype(str) + ':' + avgLoadProfile['minute'].astype(str), format='%H:%M').dt.time\n\nprint(avgLoadProfile.info())\nprint(avgLoadProfile)\n\navgLoadProfileEachMeter = MeterData.groupby(['LCLid', MeterData['DateTime'].dt.hour, MeterData['DateTime'].dt.minute]).agg({'KWHperHH': 'mean'})\nprint(avgLoadProfileEachMeter.info())\nprint(avgLoadProfileEachMeter)\n\nfig, ax = plt.subplots(figsize=(20,7))\nax.plot(avgLoadProfile.index, avgLoadProfile.KWHperHH)\n\nax.set_xticks(avgLoadProfile.index, avgLoadProfile.labels)\n\nax.set(xlabel='time (HH:MI)', ylabel='KWH/hh',\n       title='Average Household 24 hour load profile')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Avg 24hr Load Profile all meters.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:15:02.243496Z","iopub.execute_input":"2023-09-13T02:15:02.243953Z","iopub.status.idle":"2023-09-13T02:15:03.793825Z","shell.execute_reply.started":"2023-09-13T02:15:02.243919Z","shell.execute_reply":"2023-09-13T02:15:03.792640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate sum of all loads\naggLoad = pd.DataFrame(columns=['DateTime', 'AggregateLoad'])\nlimit = 100\ncounter = 1\nreportFreq = 1000\nnUniqueTstamps = d.DateTime.unique().size\nfor tstamp in d.DateTime.unique():\n    # print('tstamp: ', tstamp)\n    tstampSum = d.loc[d['DateTime'] == tstamp].iloc[:,2].sum()\n    row = {\n    \"DateTime\": tstamp,\n    \"AggregateLoad\": tstampSum\n    }\n    # print(row)\n    # aggLoad = aggLoad.append(row, ignore_index=True)\n    # Create an index for the DataFrame\n    # index = pd.Index([1])\n    index = pd.Index([1])\n    \n    # Create the DataFrame\n    row_df = pd.DataFrame(row, index=index)\n\n    # Concatenate `row_df` to `aggLoad`\n    aggLoad = pd.concat([aggLoad, row_df], ignore_index=True)\n    \n    counter += 1\n    \n    if counter % reportFreq == 0:\n        print('Progress: ', (counter / nUniqueTstamps)*100)\n    \naggLoad","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:04:55.294547Z","iopub.execute_input":"2023-09-05T14:04:55.295240Z","iopub.status.idle":"2023-09-05T14:07:22.182189Z","shell.execute_reply.started":"2023-09-05T14:04:55.295202Z","shell.execute_reply":"2023-09-05T14:07:22.181011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad = aggLoad.sort_values(by=['DateTime'])\naggLoad = aggLoad.set_index('DateTime')\naggLoad.index.rename('DateTimeIndex', inplace=True)\naggLoad.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:22.185117Z","iopub.execute_input":"2023-09-05T14:07:22.185509Z","iopub.status.idle":"2023-09-05T14:07:22.201988Z","shell.execute_reply.started":"2023-09-05T14:07:22.185476Z","shell.execute_reply":"2023-09-05T14:07:22.200813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad['DateTime'] = aggLoad.index\naggLoad.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:22.203241Z","iopub.execute_input":"2023-09-05T14:07:22.203750Z","iopub.status.idle":"2023-09-05T14:07:22.219932Z","shell.execute_reply.started":"2023-09-05T14:07:22.203715Z","shell.execute_reply":"2023-09-05T14:07:22.218746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inspect and fix records with zero load\n# start with the aggregated records with zero load\nAggZeros = aggLoad.query(\"AggregateLoad == 0\")\nAggZeros\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:22.228236Z","iopub.execute_input":"2023-09-05T14:07:22.229355Z","iopub.status.idle":"2023-09-05T14:07:22.242566Z","shell.execute_reply.started":"2023-09-05T14:07:22.229309Z","shell.execute_reply":"2023-09-05T14:07:22.241466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observation: Some of the timestamps are not exactly on the half-hour\nQuestion: How many of the timestamps are not exactly on the half-hour?","metadata":{}},{"cell_type":"code","source":"# inspect and fix records with zero load\n# look at the raw records with zero load\n# RawZeros = d.query(\"'KWH/hh (per half hour)' == 0\")\n# RawZeros","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:22.243900Z","iopub.execute_input":"2023-09-05T14:07:22.244327Z","iopub.status.idle":"2023-09-05T14:07:22.249781Z","shell.execute_reply.started":"2023-09-05T14:07:22.244256Z","shell.execute_reply":"2023-09-05T14:07:22.248596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inspect and fix records not exactly on the half-hour\noffRecs = aggLoad.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\n# aggLoad[\"DateTime\"].dt.hour > 30\nprint('Records not exactly on the half-hour: ', offRecs)\nprint(offRecs.info())\n\n# delete records not exactly on the half-hour\naggLoad = aggLoad.drop(offRecs.index)\n\noffRecs = aggLoad.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\nprint('Records not exactly on the half-hour: ', offRecs)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:22.251186Z","iopub.execute_input":"2023-09-05T14:07:22.251905Z","iopub.status.idle":"2023-09-05T14:07:22.298259Z","shell.execute_reply.started":"2023-09-05T14:07:22.251861Z","shell.execute_reply":"2023-09-05T14:07:22.297029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for missing records in the aggregate load time series\n# create reference time series\nminTimestamp = aggLoad.index.min()\nmaxTimestamp = aggLoad.index.max()\n\nprint('minTimestamp: ', minTimestamp)\nprint('maxTimestamp: ', maxTimestamp)\n\ndate_range = pd.date_range(minTimestamp, maxTimestamp, freq='30Min')\nreference_df = pd.DataFrame(np.random.randint(1, 20, (date_range.shape[0], 1)))\nreference_df.index = date_range  # set index\n\nprint('reference index length: ', reference_df.shape)\nprint('aggLoad index length: ', aggLoad.shape)\n\nprint('reference_df: ', reference_df)\nprint('aggLoad: ', aggLoad)\n\nprint('reference index: ', reference_df.index)\nprint('aggLoad index: ', aggLoad.index)\n\n# check for missing datetimeindex values based on reference index (with all values)\nmissing_dates = reference_df.index[~reference_df.index.isin(aggLoad.index)]\n\nprint('missing_dates: ', missing_dates)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:22.300005Z","iopub.execute_input":"2023-09-05T14:07:22.300801Z","iopub.status.idle":"2023-09-05T14:07:22.324329Z","shell.execute_reply.started":"2023-09-05T14:07:22.300755Z","shell.execute_reply":"2023-09-05T14:07:22.323154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the regularity of the observations (time between observations)\n# print(pd.infer_freq(train_data.DateTime))\naggLoad.index.to_series().diff().value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:22.326188Z","iopub.execute_input":"2023-09-05T14:07:22.327396Z","iopub.status.idle":"2023-09-05T14:07:22.337395Z","shell.execute_reply.started":"2023-09-05T14:07:22.327351Z","shell.execute_reply":"2023-09-05T14:07:22.336227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(aggLoad)\n\nfig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime, aggLoad.AggregateLoad)\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load 2012-2014')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:22.338860Z","iopub.execute_input":"2023-09-05T14:07:22.339419Z","iopub.status.idle":"2023-09-05T14:07:23.246139Z","shell.execute_reply.started":"2023-09-05T14:07:22.339379Z","shell.execute_reply":"2023-09-05T14:07:23.244933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:23.247491Z","iopub.execute_input":"2023-09-05T14:07:23.247837Z","iopub.status.idle":"2023-09-05T14:07:23.258945Z","shell.execute_reply.started":"2023-09-05T14:07:23.247806Z","shell.execute_reply":"2023-09-05T14:07:23.258052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime[10000:15000], aggLoad.AggregateLoad[10000:15000])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load June-August 2012')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Aggregate Household load June-August 2012.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:23.260180Z","iopub.execute_input":"2023-09-05T14:07:23.260784Z","iopub.status.idle":"2023-09-05T14:07:24.107710Z","shell.execute_reply.started":"2023-09-05T14:07:23.260750Z","shell.execute_reply":"2023-09-05T14:07:24.106349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime[12000:13000], aggLoad.AggregateLoad[12000:13000])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:24.109203Z","iopub.execute_input":"2023-09-05T14:07:24.110506Z","iopub.status.idle":"2023-09-05T14:07:24.743422Z","shell.execute_reply.started":"2023-09-05T14:07:24.110462Z","shell.execute_reply":"2023-09-05T14:07:24.742295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime[12500:12600], aggLoad.AggregateLoad[12500:12600])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load ~two days')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:24.744899Z","iopub.execute_input":"2023-09-05T14:07:24.745966Z","iopub.status.idle":"2023-09-05T14:07:25.360517Z","shell.execute_reply.started":"2023-09-05T14:07:24.745858Z","shell.execute_reply":"2023-09-05T14:07:25.359322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(aggLoad.DateTime[12500:12550], aggLoad.AggregateLoad[12500:12550])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load (one day)')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:25.362253Z","iopub.execute_input":"2023-09-05T14:07:25.362640Z","iopub.status.idle":"2023-09-05T14:07:25.790433Z","shell.execute_reply.started":"2023-09-05T14:07:25.362608Z","shell.execute_reply":"2023-09-05T14:07:25.789204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_plot(testY, test_predict):\n      len_prediction=[x for x in range(len(testY))]\n      plt.figure(figsize=(20,5))\n      plt.plot(len_prediction, testY, marker='.', label=\"actual\")\n      plt.plot(len_prediction, test_predict, 'r', label=\"prediction\")\n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:25.791905Z","iopub.execute_input":"2023-09-05T14:07:25.792626Z","iopub.status.idle":"2023-09-05T14:07:25.801226Z","shell.execute_reply.started":"2023-09-05T14:07:25.792592Z","shell.execute_reply":"2023-09-05T14:07:25.800117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use a naive persistence model as baseline to compare more sophisticated models\nUse a 1 week persistence\n\nGeorgios Tziolis, Chrysovalantis Spanias, Maria Theodoride, Spyros Theocharides, Javier Lopez-Lorente, Andreas Livera, George Makrides, George E. Georghiou,\n\nShort-term electric net load forecasting for solar-integrated distribution systems based on Bayesian neural networks and statistical post-processing,\n\nEnergy,\nVolume 271,\n2023,\n127018,\nISSN 0360-5442,\n\nhttps://doi.org/10.1016/j.energy.2023.127018.","metadata":{}},{"cell_type":"code","source":"# Naive 1 week persistence model\nNaiveForecast = aggLoad.AggregateLoad.copy()\n\nOneWeekNPeriods = 48 * 7\n\nNaiveForecast[:OneWeekNPeriods] = np.nan\n\nfor i in range(OneWeekNPeriods, len(aggLoad.AggregateLoad)):\n    NaiveForecast[i] = aggLoad.AggregateLoad[i - OneWeekNPeriods]\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:25.802680Z","iopub.execute_input":"2023-09-05T14:07:25.803512Z","iopub.status.idle":"2023-09-05T14:07:27.582711Z","shell.execute_reply.started":"2023-09-05T14:07:25.803478Z","shell.execute_reply":"2023-09-05T14:07:27.581700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize naive forecast\nprediction_plot(aggLoad.AggregateLoad, NaiveForecast)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:27.584115Z","iopub.execute_input":"2023-09-05T14:07:27.584498Z","iopub.status.idle":"2023-09-05T14:07:28.328635Z","shell.execute_reply.started":"2023-09-05T14:07:27.584464Z","shell.execute_reply":"2023-09-05T14:07:28.327424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate error for naive model\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\nprint('Naive Root Mean Squared Error(RMSE): %.2f; Naive Mean Absolute Error(MAE) : %.2f; Naive Mean Absolute Percantage Error(MAPE) : %.2f '\n      % (np.sqrt(mean_squared_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])),\n         mean_absolute_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:]),\n         mean_absolute_percentage_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:28.329938Z","iopub.execute_input":"2023-09-05T14:07:28.330321Z","iopub.status.idle":"2023-09-05T14:07:28.493909Z","shell.execute_reply.started":"2023-09-05T14:07:28.330260Z","shell.execute_reply":"2023-09-05T14:07:28.492797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ADF Test function\nimport statsmodels.tsa.stattools as smt\ndef adf_test(series):\n result = smt.adfuller(series.dropna())\n print('ADF Statistic: %f' % result[0])\n print('p-value: %f' % result[1])\n return result","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:28.495737Z","iopub.execute_input":"2023-09-05T14:07:28.496115Z","iopub.status.idle":"2023-09-05T14:07:28.502210Z","shell.execute_reply.started":"2023-09-05T14:07:28.496082Z","shell.execute_reply":"2023-09-05T14:07:28.500943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adf_test(aggLoad.AggregateLoad)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:28.503706Z","iopub.execute_input":"2023-09-05T14:07:28.504634Z","iopub.status.idle":"2023-09-05T14:07:33.037053Z","shell.execute_reply.started":"2023-09-05T14:07:28.504573Z","shell.execute_reply":"2023-09-05T14:07:33.035572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.tsa.seasonal as sts\n\ncomponents = sts.seasonal_decompose(aggLoad.AggregateLoad, period=48) # 48 = one day\ncomponents.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:33.039089Z","iopub.execute_input":"2023-09-05T14:07:33.040349Z","iopub.status.idle":"2023-09-05T14:07:35.135197Z","shell.execute_reply.started":"2023-09-05T14:07:33.040282Z","shell.execute_reply":"2023-09-05T14:07:35.133537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf\nplot_acf(aggLoad.AggregateLoad, lags = 96) \n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:35.136680Z","iopub.execute_input":"2023-09-05T14:07:35.137033Z","iopub.status.idle":"2023-09-05T14:07:35.982956Z","shell.execute_reply.started":"2023-09-05T14:07:35.137004Z","shell.execute_reply":"2023-09-05T14:07:35.982110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install pmdarima","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:35.984133Z","iopub.execute_input":"2023-09-05T14:07:35.985212Z","iopub.status.idle":"2023-09-05T14:07:51.437649Z","shell.execute_reply.started":"2023-09-05T14:07:35.985176Z","shell.execute_reply":"2023-09-05T14:07:51.436245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"find best parameters for ARIMA\nimport pmdarima as pm\nmodel = pm.auto_arima(aggLoad.AggregateLoad, start_p=1, start_q=1,\n                      test='adf',       \nuse adftest to find optimal 'd'\n                      max_p=3, max_q=3, \nmaximum p=3 and q=3\n                      m=17532,              \nperiodicity of 48 months as the data timeline is in h\n                      d=None,           \nlet the model determine 'd'\n                      seasonal=True,   # Seasonality\n                      start_P=0, \n                      D=1, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=True)\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-09-01T20:45:20.266736Z","iopub.execute_input":"2023-09-01T20:45:20.267337Z"}}},{"cell_type":"code","source":"# print(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:51.440054Z","iopub.execute_input":"2023-09-05T14:07:51.440540Z","iopub.status.idle":"2023-09-05T14:07:51.446814Z","shell.execute_reply.started":"2023-09-05T14:07:51.440490Z","shell.execute_reply":"2023-09-05T14:07:51.445618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the time series data into train, test, and validation datasets\ntrain_size = int(len(aggLoad) * 0.7)  # 70% for training\ntest_size = int(len(aggLoad) * 0.2)   # 20% for testing\nval_size = len(aggLoad) - train_size - test_size  # Remaining for validation\n\ntrain_data = aggLoad[:train_size]\ntest_data = aggLoad[train_size:train_size+test_size]\nval_data = aggLoad[train_size+test_size:]\n\nprint('train_data.head()', train_data.head())\nprint('test_data.head()', test_data.head())\nprint('val_data.head()', val_data.head())\nprint(train_data.info())","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:51.448686Z","iopub.execute_input":"2023-09-05T14:07:51.449118Z","iopub.status.idle":"2023-09-05T14:07:51.482579Z","shell.execute_reply.started":"2023-09-05T14:07:51.449078Z","shell.execute_reply":"2023-09-05T14:07:51.481339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create an ARIMA algorithm baseline to assess other models against ","metadata":{}},{"cell_type":"markdown","source":"# Create a Deep Learning time series forecasting model using Keras","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\ndef convert2matrix(data_arr, look_back):\n   X, Y =[], []\n   for i in range(len(data_arr)-look_back):\n       d=i+look_back  \n       X.append(data_arr[i:d,])\n       Y.append(data_arr[d,])\n   return np.array(X), np.array(Y)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:51.484509Z","iopub.execute_input":"2023-09-05T14:07:51.484958Z","iopub.status.idle":"2023-09-05T14:07:59.934767Z","shell.execute_reply.started":"2023-09-05T14:07:51.484916Z","shell.execute_reply":"2023-09-05T14:07:59.933666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RNN\n# work with a copy of the dataset\ndf1 = aggLoad.copy()\n# print(df1.head())\ndf1 = df1.drop(columns=['DateTime'])\nprint(df1.head())\n\n# prepare the data\ntrain,test = df1.values[0:train_size,:], df1.values[train_size:train_size+test_size,:]\nlook_back = 96 # create window size\ntest = np.append(test,np.repeat(test[-1,], look_back))\ntrain = np.append(train,np.repeat(train[-1,],look_back))\ntrainX,trainY =convert2matrix(train,look_back)\ntestX,testY =convert2matrix(test,look_back)\n# reshape input to be [samples, window size, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n\n\nprint('trainX:\\n', trainX.shape, trainX.dtype)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:07:59.936179Z","iopub.execute_input":"2023-09-05T14:07:59.937166Z","iopub.status.idle":"2023-09-05T14:08:00.004061Z","shell.execute_reply.started":"2023-09-05T14:07:59.937129Z","shell.execute_reply":"2023-09-05T14:08:00.003224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the RNN model architecture\nfrom keras.models import Sequential\nfrom keras.layers import Dense, SimpleRNN\nfrom keras.callbacks import EarlyStopping\ndef model_rnn(look_back):\n  model=Sequential()\n  model.add(SimpleRNN(units=8, input_shape=(1,look_back), activation=\"relu\"))\n  model.add(Dense(4, activation='relu'))\n  model.add(Dense(1))\n  model.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:08:00.005350Z","iopub.execute_input":"2023-09-05T14:08:00.006314Z","iopub.status.idle":"2023-09-05T14:08:00.013903Z","shell.execute_reply.started":"2023-09-05T14:08:00.006249Z","shell.execute_reply":"2023-09-05T14:08:00.012354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the RNN model\nmodel=model_rnn(look_back)\n\nhistory=model.fit(trainX,trainY, epochs=100, batch_size=30, verbose=1, validation_data=(testX,testY),callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:08:00.015309Z","iopub.execute_input":"2023-09-05T14:08:00.015652Z","iopub.status.idle":"2023-09-05T14:08:39.131067Z","shell.execute_reply.started":"2023-09-05T14:08:00.015621Z","shell.execute_reply":"2023-09-05T14:08:39.129909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for plotting the train and test loss curves\ndef model_loss(history):\n    plt.figure(figsize=(8,4))\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Test Loss')\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epochs')\n    plt.legend(loc='upper right')\n    plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:08:39.132625Z","iopub.execute_input":"2023-09-05T14:08:39.132966Z","iopub.status.idle":"2023-09-05T14:08:39.140435Z","shell.execute_reply.started":"2023-09-05T14:08:39.132935Z","shell.execute_reply":"2023-09-05T14:08:39.138812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict on the train and test datasets\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\ntrain_predict = model.predict(trainX)\ntest_predict = model.predict(testX)\nprint('Train Root Mean Squared Error(RMSE): %.2f; Train Mean Absolute Error(MAE) : %.2f '\n      % (np.sqrt(mean_squared_error(trainY, train_predict)), mean_absolute_error(trainY, train_predict[:,0])))\nprint('Test Root Mean Squared Error(RMSE): %.2f; Test Mean Absolute Error(MAE) : %.2f ' \n      % (np.sqrt(mean_squared_error(testY, test_predict[:,0])), mean_absolute_error(testY, test_predict[:,0])))\nmodel_loss(history)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:08:39.142081Z","iopub.execute_input":"2023-09-05T14:08:39.142817Z","iopub.status.idle":"2023-09-05T14:08:45.090443Z","shell.execute_reply.started":"2023-09-05T14:08:39.142772Z","shell.execute_reply":"2023-09-05T14:08:45.089287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot actuals and predictions for the whole test set\n# print('testY:\\n', testY.shape, testY)\n# print('test_predict:\\n', test_predict.shape, test_predict)\nprediction_plot(testY, test_predict)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:08:45.092057Z","iopub.execute_input":"2023-09-05T14:08:45.092446Z","iopub.status.idle":"2023-09-05T14:08:45.716933Z","shell.execute_reply.started":"2023-09-05T14:08:45.092414Z","shell.execute_reply":"2023-09-05T14:08:45.715645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot actuals and RNN predictions for the first day of the test set\nprediction_plot(testY[0:48], test_predict[0:48])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T14:08:45.718275Z","iopub.execute_input":"2023-09-05T14:08:45.718638Z","iopub.status.idle":"2023-09-05T14:08:46.140324Z","shell.execute_reply.started":"2023-09-05T14:08:45.718605Z","shell.execute_reply":"2023-09-05T14:08:46.139159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTM\n# work with a copy of the dataset\ndf1 = aggLoad.copy()\n# print(df1.head())\ndf1 = df1.drop(columns=['DateTime'])\nprint(df1.head())\n\n# prepare the data\ntrain,test = df1.values[0:train_size,:], df1.values[train_size:train_size+test_size,:]\nlook_back = 48 # create window size\ntest = np.append(test,np.repeat(test[-1,], look_back))\ntrain = np.append(train,np.repeat(train[-1,],look_back))\ntrainX,trainY =convert2matrix(train,look_back)\ntestX,testY =convert2matrix(test,look_back)\n# reshape input to be [samples, window size, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n\n\nprint('trainX:\\n', trainX.shape, trainX.dtype)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:06:11.457194Z","iopub.execute_input":"2023-09-05T15:06:11.457609Z","iopub.status.idle":"2023-09-05T15:06:11.522175Z","shell.execute_reply.started":"2023-09-05T15:06:11.457579Z","shell.execute_reply":"2023-09-05T15:06:11.520993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTM\nimport keras\nfrom keras.layers import LSTM\n\n# Create the LSTM layer\nlstm_layer = LSTM(units=128, input_shape=(1,look_back))\n\n# Create the model\nlstm_model = keras.Sequential()\nlstm_model.add(lstm_layer)\nlstm_model.add(keras.layers.Dense(8))\nlstm_model.add(keras.layers.Dropout(0.2))\nlstm_model.add(keras.layers.Dense(1))\n\n# Compile the model\nlstm_model.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:15:29.692642Z","iopub.execute_input":"2023-09-05T15:15:29.693062Z","iopub.status.idle":"2023-09-05T15:15:30.030067Z","shell.execute_reply.started":"2023-09-05T15:15:29.693030Z","shell.execute_reply":"2023-09-05T15:15:30.029112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nprint('Fitting LSTM model...\\n')\nhistory = lstm_model.fit(trainX,trainY, \n               epochs=100, batch_size=30, verbose=1, \n               validation_data=(testX,testY),\n               callbacks=[EarlyStopping(monitor='val_loss', patience=10)],\n               shuffle=False)\n\n# Make a prediction\nprint('Predicting train and test data using LSTM model...\\n')\n\nlstm_train_predict = lstm_model.predict(trainX)\nlstm_test_predict = lstm_model.predict(testX)\nprint('Train Root Mean Squared Error(RMSE): %.2f; Train Mean Absolute Error(MAE) : %.2f '\n      % (np.sqrt(mean_squared_error(trainY, lstm_train_predict)), mean_absolute_error(trainY, lstm_train_predict[:,0])))\nprint('Test Root Mean Squared Error(RMSE): %.2f; Test Mean Absolute Error(MAE) : %.2f ' \n      % (np.sqrt(mean_squared_error(testY, lstm_test_predict[:,0])), mean_absolute_error(testY, lstm_test_predict[:,0])))\n\n# generate loss curves...\nmodel_loss(history)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:15:32.983673Z","iopub.execute_input":"2023-09-05T15:15:32.984076Z","iopub.status.idle":"2023-09-05T15:20:00.198688Z","shell.execute_reply.started":"2023-09-05T15:15:32.984044Z","shell.execute_reply":"2023-09-05T15:20:00.197377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN-LSTM","metadata":{"execution":{"iopub.status.busy":"2023-09-03T23:28:36.532107Z","iopub.execute_input":"2023-09-03T23:28:36.532710Z","iopub.status.idle":"2023-09-03T23:28:36.545743Z","shell.execute_reply.started":"2023-09-03T23:28:36.532648Z","shell.execute_reply":"2023-09-03T23:28:36.544393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary of errors for naive and RNN\n","metadata":{}},{"cell_type":"code","source":"print('Naive Root Mean Squared Error(RMSE): %.2f; Naive Mean Absolute Error(MAE) : %.2f; Naive Mean Absolute Percantage Error(MAPE) : %.2f '\n      % (np.sqrt(mean_squared_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])),\n         mean_absolute_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:]),\n         mean_absolute_percentage_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])))\nprint('RNN Train Root Mean Squared Error(RMSE): %.2f; Train Mean Absolute Error(MAE) : %.2f '\n      % (np.sqrt(mean_squared_error(trainY, train_predict)), mean_absolute_error(trainY, train_predict[:,0])))\nprint('RNN Test Root Mean Squared Error(RMSE): %.2f; Test Mean Absolute Error(MAE) : %.2f ' \n      % (np.sqrt(mean_squared_error(testY, test_predict[:,0])), mean_absolute_error(testY, test_predict[:,0])))\n\n# to-do: create nice graphic for this","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:55:30.155224Z","iopub.execute_input":"2023-09-04T23:55:30.155877Z","iopub.status.idle":"2023-09-04T23:55:30.175418Z","shell.execute_reply.started":"2023-09-04T23:55:30.155828Z","shell.execute_reply":"2023-09-04T23:55:30.173829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot of naive, RNN and actuals","metadata":{}},{"cell_type":"code","source":"      len_prediction=[x for x in range(len(testY))]\n      plt.figure(figsize=(20,5))\n      plt.plot(len_prediction, testY, marker='.', label=\"actual\")\n      plt.plot(len_prediction, test_predict, 'r', label=\"RNN prediction\")\n      plt.plot(len_prediction, NaiveForecast[train_size:train_size+test_size], 'g', label=\"Naive prediction\")\n        \n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:55:38.805613Z","iopub.execute_input":"2023-09-04T23:55:38.806813Z","iopub.status.idle":"2023-09-04T23:55:39.519139Z","shell.execute_reply.started":"2023-09-04T23:55:38.806769Z","shell.execute_reply":"2023-09-04T23:55:39.517504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"      len_prediction=[x for x in range(len(testY[0:48]))]\n      plt.figure(figsize=(20,5))\n      plt.plot(len_prediction, testY[0:48], marker='.', label=\"actual\")\n      plt.plot(len_prediction, test_predict[0:48], 'r', label=\"RNN prediction\")\n      plt.plot(len_prediction, NaiveForecast[train_size:train_size+48], 'g', label=\"Naive prediction\")\n        \n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:55:49.168171Z","iopub.execute_input":"2023-09-04T23:55:49.168657Z","iopub.status.idle":"2023-09-04T23:55:49.606567Z","shell.execute_reply.started":"2023-09-04T23:55:49.168619Z","shell.execute_reply":"2023-09-04T23:55:49.605145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use AutoGluon AutoML with London dataset","metadata":{}},{"cell_type":"code","source":"# install AutoGluon AutoML\n!pip install autogluon\nfrom autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:56:43.600693Z","iopub.execute_input":"2023-09-04T23:56:43.601148Z","iopub.status.idle":"2023-09-05T00:00:46.053764Z","shell.execute_reply.started":"2023-09-04T23:56:43.601111Z","shell.execute_reply":"2023-09-05T00:00:46.052121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AutoGluon specific data preparation\n# work with a copy of the split datasets...\"ag_\" prefix stands for AutoGluon\nag_train_data = train_data.copy()\nag_test_data = test_data.copy()\nag_val_data = val_data.copy()\n\n# AutoGluon requires an ItemID Column, so adding one...\nag_train_data['item_id'] = 'LoadSum'\nag_train_data = ag_train_data.astype({\"item_id\": str})\nag_test_data['item_id'] = 'LoadSum'\nag_test_data = ag_test_data.astype({\"item_id\": str})\nag_val_data['item_id'] = 'LoadSum'\nag_val_data = ag_val_data.astype({\"item_id\": str})","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:02:57.622862Z","iopub.execute_input":"2023-09-05T00:02:57.623378Z","iopub.status.idle":"2023-09-05T00:02:57.642375Z","shell.execute_reply.started":"2023-09-05T00:02:57.623321Z","shell.execute_reply":"2023-09-05T00:02:57.641091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take a quick look at the split datasets\nprint('ag_train_data\\n', ag_train_data)\nprint('ag_test_data\\n', ag_test_data)\nprint('ag_val_data\\n', ag_val_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:02:57.644400Z","iopub.execute_input":"2023-09-05T00:02:57.645483Z","iopub.status.idle":"2023-09-05T00:02:57.666916Z","shell.execute_reply.started":"2023-09-05T00:02:57.645443Z","shell.execute_reply":"2023-09-05T00:02:57.665283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load training data in to required AutoGluon proprietary data frame\nprint(ag_train_data.info())\nag_train_data_tsdf = TimeSeriesDataFrame.from_data_frame(\n    ag_train_data,\n    id_column=\"item_id\",\n    timestamp_column=\"DateTime\"\n)\nag_train_data_tsdf","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:02:57.668613Z","iopub.execute_input":"2023-09-05T00:02:57.669254Z","iopub.status.idle":"2023-09-05T00:02:57.785494Z","shell.execute_reply.started":"2023-09-05T00:02:57.669198Z","shell.execute_reply":"2023-09-05T00:02:57.784083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load test data in to required AutoGluon proprietary data frame, \"_tsdf\" suffix = time series data frame\nag_test_data_tsdf = TimeSeriesDataFrame.from_data_frame(\n    ag_test_data,\n    id_column=\"item_id\",\n    timestamp_column=\"DateTime\"\n)\nag_test_data_tsdf","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:03:35.910694Z","iopub.execute_input":"2023-09-05T00:03:35.911150Z","iopub.status.idle":"2023-09-05T00:03:35.961695Z","shell.execute_reply.started":"2023-09-05T00:03:35.911103Z","shell.execute_reply":"2023-09-05T00:03:35.960368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# at \"high_quality\" level, training takes about 45 minutes...\n# training takes about 15 minutes for DeepAR\n# training takes about 21 minutes for TemporalFusionTransformer\n# training takes about 4 minutes for PatchTST\n# training takes about 4 minutes for PatchTST","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:02:57.897891Z","iopub.status.idle":"2023-09-05T00:02:57.898397Z","shell.execute_reply.started":"2023-09-05T00:02:57.898169Z","shell.execute_reply":"2023-09-05T00:02:57.898191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ag_predictor = TimeSeriesPredictor(\n    prediction_length=48,\n    path=\"autogluon-london-half-hourly\",\n    target=\"AggregateLoad\",\n    eval_metric=\"MASE\",\n)\n\nag_predictor.fit(\n    ag_train_data_tsdf,\n    presets=\"medium_quality\",\n    time_limit=6000,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:04:33.882500Z","iopub.execute_input":"2023-09-05T00:04:33.883042Z","iopub.status.idle":"2023-09-05T00:21:20.865163Z","shell.execute_reply.started":"2023-09-05T00:04:33.883001Z","shell.execute_reply":"2023-09-05T00:21:20.863593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The test score is computed using the last\n# prediction_length=48 timesteps of each time series in test_data\nag_predictor.leaderboard(ag_test_data_tsdf, silent=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:23:04.466659Z","iopub.execute_input":"2023-09-05T00:23:04.467189Z","iopub.status.idle":"2023-09-05T00:24:29.154779Z","shell.execute_reply.started":"2023-09-05T00:23:04.467148Z","shell.execute_reply":"2023-09-05T00:24:29.152877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate predictions\nag_predictions = ag_predictor.predict(ag_train_data_tsdf)\nag_predictions.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:24:49.703473Z","iopub.execute_input":"2023-09-05T00:24:49.704626Z","iopub.status.idle":"2023-09-05T00:24:50.891442Z","shell.execute_reply.started":"2023-09-05T00:24:49.704581Z","shell.execute_reply":"2023-09-05T00:24:50.890089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot prediction results, history and actual test data values\nplt.figure(figsize=(20, 3))\n\nitem_id = \"LoadSum\"\ny_past = ag_train_data_tsdf.loc[item_id][\"AggregateLoad\"]\ny_pred = ag_predictions.loc[item_id]\ny_test = ag_test_data_tsdf.loc[item_id][\"AggregateLoad\"]\n\nplt.plot(y_past[-100:], label=\"Past time series values\")\nplt.plot(y_pred[\"mean\"], label=\"Mean forecast\")\nplt.plot(y_test[:48], label=\"Future time series values\")\n\nplt.fill_between(\n    y_pred.index, y_pred[\"0.1\"], y_pred[\"0.9\"], color=\"red\", alpha=0.1, label=f\"10%-90% confidence interval\"\n)\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:25:02.411138Z","iopub.execute_input":"2023-09-05T00:25:02.411621Z","iopub.status.idle":"2023-09-05T00:25:02.943478Z","shell.execute_reply.started":"2023-09-05T00:25:02.411573Z","shell.execute_reply":"2023-09-05T00:25:02.941935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}