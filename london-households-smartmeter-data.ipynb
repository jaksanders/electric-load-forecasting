{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Short-term residential load forecasting with Deep Learning\n\nLondon Households SmartMeter Data","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T22:03:41.802148Z","iopub.execute_input":"2023-09-13T22:03:41.802596Z","iopub.status.idle":"2023-09-13T22:03:41.837824Z","shell.execute_reply.started":"2023-09-13T22:03:41.802563Z","shell.execute_reply":"2023-09-13T22:03:41.836521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#!pip install -U pip\n#!pip install -U setuptools wheel\n\n#!pip install autogluon\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:41.841002Z","iopub.execute_input":"2023-09-13T22:03:41.841406Z","iopub.status.idle":"2023-09-13T22:03:41.846939Z","shell.execute_reply.started":"2023-09-13T22:03:41.841346Z","shell.execute_reply":"2023-09-13T22:03:41.845642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creat two load forecasts...\n1) half-hourly load forecast for next 24 hours\n2) peak half-hour in the next 24 hours\n\nValue...\n* For electric network operator, minimize the amount of spinning reserve\n\nData...\n* residential smart meter usage data\n* weather data\n* weather forecast data","metadata":{}},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"# load half-hourly electric usage data\n# https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households\nd = pd.read_csv('/kaggle/input/small-lcl-data/LCL-June2015v2_99.csv', parse_dates=[\"DateTime\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:41.848463Z","iopub.execute_input":"2023-09-13T22:03:41.849219Z","iopub.status.idle":"2023-09-13T22:03:43.071269Z","shell.execute_reply.started":"2023-09-13T22:03:41.849172Z","shell.execute_reply":"2023-09-13T22:03:43.070211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load hourly weather data\n# https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households\nweatherData = pd.read_csv('/kaggle/input/smart-meters-in-london/weather_hourly_darksky.csv', parse_dates=[\"time\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weatherData.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:43.073749Z","iopub.execute_input":"2023-09-13T22:03:43.074098Z","iopub.status.idle":"2023-09-13T22:03:43.542398Z","shell.execute_reply.started":"2023-09-13T22:03:43.074069Z","shell.execute_reply":"2023-09-13T22:03:43.541144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert usage to floats\n# print(d.iloc[3])\nd.iloc[:, 3] = pd.to_numeric(d.iloc[:, 3], errors='coerce')\n# print(d.dtypes)\n# rename usage column for easier reference\n#d.rename(columns={\"KWH/hh (per half hour)\": \"KWHperHH\"}, inplace=True)\nd.rename(columns={d.columns[3]: 'KWHperHH'}, inplace=True)\n# d.rename_col_by_index(3, 'KWHperHH')\nd.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:43.543731Z","iopub.execute_input":"2023-09-13T22:03:43.544164Z","iopub.status.idle":"2023-09-13T22:03:44.219761Z","shell.execute_reply.started":"2023-09-13T22:03:43.544119Z","shell.execute_reply":"2023-09-13T22:03:44.218437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set timestamp as the index\nd.set_index('DateTime')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:44.221328Z","iopub.execute_input":"2023-09-13T22:03:44.221698Z","iopub.status.idle":"2023-09-13T22:03:44.268644Z","shell.execute_reply.started":"2023-09-13T22:03:44.221666Z","shell.execute_reply":"2023-09-13T22:03:44.267434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\n\nprofile = ProfileReport(d, tsmode=True, sortby=\"DateTime\")\nprofile.to_file('profile_report.html')\nprofile","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:44.269869Z","iopub.execute_input":"2023-09-13T22:03:44.270648Z","iopub.status.idle":"2023-09-13T22:03:54.084203Z","shell.execute_reply.started":"2023-09-13T22:03:44.270612Z","shell.execute_reply":"2023-09-13T22:03:54.083167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize and handle duplicates\n# d = d.drop_duplicates()\nprint(d.groupby(d.columns.tolist(),as_index=False).size())\ndupes = d[d.duplicated()]\nprint('dupes', dupes)\nprint('dupes.index', dupes.index)\nd = d.drop(index=dupes.index)\n\nd.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:54.085540Z","iopub.execute_input":"2023-09-13T22:03:54.085861Z","iopub.status.idle":"2023-09-13T22:03:55.170573Z","shell.execute_reply.started":"2023-09-13T22:03:54.085834Z","shell.execute_reply":"2023-09-13T22:03:55.169181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d.set_index('DateTime')\nd.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:55.171775Z","iopub.execute_input":"2023-09-13T22:03:55.172207Z","iopub.status.idle":"2023-09-13T22:03:55.496633Z","shell.execute_reply.started":"2023-09-13T22:03:55.172162Z","shell.execute_reply":"2023-09-13T22:03:55.495376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize smart meter dataset to anayze for quality, completenes and othe insights","metadata":{}},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:55.501415Z","iopub.execute_input":"2023-09-13T22:03:55.501775Z","iopub.status.idle":"2023-09-13T22:03:55.506672Z","shell.execute_reply.started":"2023-09-13T22:03:55.501744Z","shell.execute_reply":"2023-09-13T22:03:55.505600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize meter read coverage and completeness\npivot_table = pd.pivot_table(d, columns='DateTime', index='LCLid', values='KWHperHH')\n# print(pivot_table)\nplt.subplots(figsize=(20,15))\nsns.heatmap(pivot_table)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:03:55.508069Z","iopub.execute_input":"2023-09-13T22:03:55.508468Z","iopub.status.idle":"2023-09-13T22:04:04.821515Z","shell.execute_reply.started":"2023-09-13T22:03:55.508436Z","shell.execute_reply":"2023-09-13T22:04:04.820334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations from Heatmap...\n* several houses start producing load part-way through the period\n    - eg MAC004221, MAC004248\n    \n    \n* several houses stop producing part-way through the period\n    - eg MAC004226, MAC004257\n    \n\n* most houses have at least one \"gap\" in their data (visible as white lines)\n\n\n* several houses stand out as having significantly higher average load than others\n    - eg MAC004225, MAC004249","metadata":{}},{"cell_type":"code","source":"# inspect and remove records not exactly on the half-hour\noffRecs = d.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\n# aggLoad[\"DateTime\"].dt.hour > 30\nprint('Records not exactly on the half-hour:\\n ', offRecs)\nprint(offRecs.info())\n\n# delete records not exactly on the half-hour\nd = d.drop(offRecs.index)\n\noffRecs = d.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\nprint('Records not exactly on the half-hour: ', offRecs)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:04.823275Z","iopub.execute_input":"2023-09-13T22:04:04.824297Z","iopub.status.idle":"2023-09-13T22:04:05.339511Z","shell.execute_reply.started":"2023-09-13T22:04:04.824259Z","shell.execute_reply":"2023-09-13T22:04:05.338562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:05.341143Z","iopub.execute_input":"2023-09-13T22:04:05.341712Z","iopub.status.idle":"2023-09-13T22:04:05.654776Z","shell.execute_reply.started":"2023-09-13T22:04:05.341675Z","shell.execute_reply":"2023-09-13T22:04:05.653611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First step of interpolation is to create NaN records where records are missing\ndf = d.copy()\n# df.info()\ndf = df.sort_values(by=['DateTime'])\ndf = df.set_index('DateTime')\ndf.index.rename('DateTime', inplace=True)\n# df.info()\n\n# df['datetime'] = pd.to_datetime(df['datetime'])\n# df.index = df['datetime']\n# del df['datetime']\n\ndf_interpol = df.groupby('LCLid')\\\n                .resample('30Min')\\\n                .mean()\ndf_interpol['KWHperHH'] = df_interpol['KWHperHH'].interpolate()\n# df_interpol.info()\ndf_interpol = df_interpol.reset_index()\n\n# df_interpol['LCLid'], df_interpol['DateTime'] = df_interpol.index\ndf_interpol.head(4)\ndf_interpol.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:05.657301Z","iopub.execute_input":"2023-09-13T22:04:05.657755Z","iopub.status.idle":"2023-09-13T22:04:06.564509Z","shell.execute_reply.started":"2023-09-13T22:04:05.657714Z","shell.execute_reply":"2023-09-13T22:04:06.563204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize after interpolating missing values\ndf_interpol.info()\npivot_table = pd.pivot_table(df_interpol, columns='DateTime', index='LCLid', values='KWHperHH')\nplt.subplots(figsize=(20,15))\n\nsns.heatmap(pivot_table)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:06.566059Z","iopub.execute_input":"2023-09-13T22:04:06.566527Z","iopub.status.idle":"2023-09-13T22:04:16.026572Z","shell.execute_reply.started":"2023-09-13T22:04:06.566482Z","shell.execute_reply":"2023-09-13T22:04:16.025568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize zeros in the dataset\ndf_interpol.info()\ndf_interpol['ZeroKWHperHH'] = df_interpol['KWHperHH'] == 0\npivot_table = pd.pivot_table(df_interpol, columns='DateTime', index='LCLid', values='ZeroKWHperHH')\nplt.subplots(figsize=(20,15))\n\nsns.heatmap(pivot_table)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:16.027709Z","iopub.execute_input":"2023-09-13T22:04:16.028006Z","iopub.status.idle":"2023-09-13T22:04:25.758675Z","shell.execute_reply.started":"2023-09-13T22:04:16.027979Z","shell.execute_reply":"2023-09-13T22:04:25.757477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obervation: there are a handful of households that account all the zero value meter reads: MAC004233, MAC004226, MAC004267","metadata":{}},{"cell_type":"code","source":"# investigate the meters with zero reads\nMAC004233 = df_interpol.query(\"LCLid == 'MAC004233'\")\n\nfig, ax = plt.subplots(4,figsize=(20,9))\n\n# plot whole ~2 years\nax[0].plot(MAC004233.DateTime, MAC004233.KWHperHH)\nax[0].plot(MAC004233.DateTime, MAC004233.ZeroKWHperHH)\nax[0].set(ylabel='KWH/hh',\n       title='Load from one Household MAC004233 with lots of zero values')\nplt.tick_params(rotation=45)\nax[0].grid()\n\n# zoom in\nax[1].plot(MAC004233.DateTime[11000:15000], MAC004233.KWHperHH[11000:15000])\nax[1].plot(MAC004233.DateTime[11000:15000], MAC004233.ZeroKWHperHH[11000:15000])\nax[1].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[1].grid()\n\n# zoom in more...\nax[2].plot(MAC004233.DateTime[13000:13500], MAC004233.KWHperHH[13000:13500])\nax[2].plot(MAC004233.DateTime[13000:13500], MAC004233.ZeroKWHperHH[13000:13500])\nax[2].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[2].grid()\n\n# zoom in to a different part of the series...\nax[3].plot(MAC004233.DateTime[25000:25500], MAC004233.KWHperHH[25000:25500])\nax[3].plot(MAC004233.DateTime[25000:25500], MAC004233.ZeroKWHperHH[25000:25500])\nax[3].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[3].grid()\n\nfig.savefig(\"MAC004233.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:25.760150Z","iopub.execute_input":"2023-09-13T22:04:25.760551Z","iopub.status.idle":"2023-09-13T22:04:27.377520Z","shell.execute_reply.started":"2023-09-13T22:04:25.760515Z","shell.execute_reply":"2023-09-13T22:04:27.376451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n\nThe zeros for MAC004233 seem legit - leaving them in","metadata":{}},{"cell_type":"code","source":"# investigate the meters with zero reads\nMAC004267 = df_interpol.query(\"LCLid == 'MAC004267'\")\nfig, ax = plt.subplots(4,figsize=(20,9))\n\n# plot whole ~2 years\nax[0].plot(MAC004267.DateTime, MAC004267.KWHperHH)\nax[0].plot(MAC004267.DateTime, MAC004267.ZeroKWHperHH)\nax[0].set(ylabel='KWH/hh',\n       title='Load from one Household MAC004233 with lots of zero values')\nplt.tick_params(rotation=45)\nax[0].grid()\n\n# zoom in\nax[1].plot(MAC004267.DateTime[17000:21000], MAC004267.KWHperHH[17000:21000])\nax[1].plot(MAC004267.DateTime[17000:21000], MAC004267.ZeroKWHperHH[17000:21000])\nax[1].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[1].grid()\n\n# zoom in more...\nax[2].plot(MAC004267.DateTime[19300:19800], MAC004267.KWHperHH[19300:19800])\nax[2].plot(MAC004267.DateTime[19300:19800], MAC004267.ZeroKWHperHH[19300:19800])\nax[2].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[2].grid()\n\n# zoom in to a different part of the series...\nax[3].plot(MAC004267.DateTime[25000:25500], MAC004267.KWHperHH[25000:25500])\nax[3].plot(MAC004267.DateTime[25000:25500], MAC004267.ZeroKWHperHH[25000:25500])\nax[3].set(xlabel='time (s)', ylabel='KWH/hh')\nplt.tick_params(rotation=45)\nax[3].grid()\n\nfig.savefig(\"MAC004233.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:27.379238Z","iopub.execute_input":"2023-09-13T22:04:27.379952Z","iopub.status.idle":"2023-09-13T22:04:28.846710Z","shell.execute_reply.started":"2023-09-13T22:04:27.379907Z","shell.execute_reply":"2023-09-13T22:04:28.845457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation\n\nThe zeros for MAC004233 seem legit - leaving them in\n","metadata":{}},{"cell_type":"code","source":"# visualize and handle outliers\nd = df_interpol.copy()\n\n# minumum and maximum timestamp for each house\nprint(d.groupby('LCLid').max().sort_values('DateTime'))\nprint(d.groupby('LCLid').min().sort_values('DateTime'))\nprint(d.groupby('LCLid').count().sort_values('DateTime'))\n\nprint(d.groupby('LCLid').agg(['min', 'max', 'count']))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:28.848087Z","iopub.execute_input":"2023-09-13T22:04:28.848467Z","iopub.status.idle":"2023-09-13T22:04:29.289488Z","shell.execute_reply.started":"2023-09-13T22:04:28.848431Z","shell.execute_reply":"2023-09-13T22:04:29.288158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# which house has the highest peak load?\n\n# which house has the highest total aggregate load?\n\n# how variable / predictable is the timing of the peak load\n\n# how accurate is the next 24 hours forecast profile overall?\n\n# how accurate is the peak load forecast in next 24 hours?\n\n# normalize and standardize\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:29.291241Z","iopub.execute_input":"2023-09-13T22:04:29.291929Z","iopub.status.idle":"2023-09-13T22:04:29.297085Z","shell.execute_reply.started":"2023-09-13T22:04:29.291885Z","shell.execute_reply":"2023-09-13T22:04:29.296030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract one smartmeter for plotting\nsample = d.query(\"LCLid == 'MAC004233'\")\nsample","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:29.298710Z","iopub.execute_input":"2023-09-13T22:04:29.299128Z","iopub.status.idle":"2023-09-13T22:04:29.352493Z","shell.execute_reply.started":"2023-09-13T22:04:29.299096Z","shell.execute_reply":"2023-09-13T22:04:29.351601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize load profile for one household meter\nfig, ax = plt.subplots()\nax.plot(sample.iloc[100:4500,1], sample.iloc[100:4500,2])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Load from one Household, June-September 2012')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Load from one Household, June-September 2012.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:29.353989Z","iopub.execute_input":"2023-09-13T22:04:29.354322Z","iopub.status.idle":"2023-09-13T22:04:29.822900Z","shell.execute_reply.started":"2023-09-13T22:04:29.354285Z","shell.execute_reply":"2023-09-13T22:04:29.821614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set index for the sample\nsample.set_index('DateTime')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:29.824224Z","iopub.execute_input":"2023-09-13T22:04:29.824606Z","iopub.status.idle":"2023-09-13T22:04:29.841964Z","shell.execute_reply.started":"2023-09-13T22:04:29.824571Z","shell.execute_reply":"2023-09-13T22:04:29.840612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA: Visualize daily average load for each meter and all meters...","metadata":{}},{"cell_type":"code","source":"# calculate average daily load profile for all meters...\n# work with a copy of dataset...\nMeterData = df_interpol.copy()\n\navgLoadProfile = pd.DataFrame(MeterData.groupby([MeterData['DateTime'].dt.hour, MeterData['DateTime'].dt.minute]).KWHperHH.mean())\navgLoadProfile = avgLoadProfile.reset_index(names=['hour', 'minute'])\navgLoadProfile['labels'] = pd.to_datetime(avgLoadProfile['hour'].astype(str) + ':' + avgLoadProfile['minute'].astype(str), format='%H:%M').dt.time\n\n# print(avgLoadProfile.info())\n# print(avgLoadProfile)\n\nfig, ax = plt.subplots(figsize=(10,7))\n\nax.set_xticks(avgLoadProfile.index, avgLoadProfile.labels)\n\nax.set(xlabel='time (HH:MI)', ylabel='KWH/hh',\n       title='Average Household 24 hour load profile')\n\n# calculate average daily load for each meter...\navgLoadProfileEachMeter = pd.DataFrame(MeterData.groupby(['LCLid', MeterData['DateTime'].dt.hour, MeterData['DateTime'].dt.minute]).agg({'KWHperHH': 'mean'}))\navgLoadProfileEachMeter = avgLoadProfileEachMeter.reset_index(names=['LCLid', 'hour', 'minute'])\n# print(avgLoadProfileEachMeter.info())\n# print(avgLoadProfileEachMeter)\n\n# plot every meter\nfor meter in avgLoadProfileEachMeter.LCLid.unique():\n    # print(meter)\n    ax.plot(avgLoadProfileEachMeter.loc[avgLoadProfileEachMeter['LCLid'] == meter].index % 48, \n            avgLoadProfileEachMeter.loc[avgLoadProfileEachMeter['LCLid'] == meter].KWHperHH,\n           color='grey')\n\n# plot the average\nax.plot(avgLoadProfile.index, avgLoadProfile.KWHperHH, linewidth=5)\n\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Avg 24hr Load Profile every meter.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:29.843904Z","iopub.execute_input":"2023-09-13T22:04:29.845102Z","iopub.status.idle":"2023-09-13T22:04:31.296012Z","shell.execute_reply.started":"2023-09-13T22:04:29.844934Z","shell.execute_reply":"2023-09-13T22:04:31.294801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the sum of all loads for each timestamp using `groupby()` and `agg()`\naggLoad = d.groupby('DateTime')['KWHperHH'].agg('sum')\naggLoad = pd.DataFrame(aggLoad)\naggLoad = aggLoad.reset_index()\naggLoad.columns = ['DateTime', 'AggregateLoad']\n\nprint(aggLoad)\nprint(aggLoad.describe())\nprint(aggLoad.info())","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:31.297267Z","iopub.execute_input":"2023-09-13T22:04:31.297629Z","iopub.status.idle":"2023-09-13T22:04:31.358404Z","shell.execute_reply.started":"2023-09-13T22:04:31.297595Z","shell.execute_reply":"2023-09-13T22:04:31.357170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad = aggLoad.sort_values(by=['DateTime'])\naggLoad = aggLoad.set_index('DateTime')\naggLoad.index.rename('DateTimeIndex', inplace=True)\naggLoad.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:31.359814Z","iopub.execute_input":"2023-09-13T22:04:31.360230Z","iopub.status.idle":"2023-09-13T22:04:31.375943Z","shell.execute_reply.started":"2023-09-13T22:04:31.360190Z","shell.execute_reply":"2023-09-13T22:04:31.374859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad['DateTime'] = aggLoad.index\naggLoad.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:31.376972Z","iopub.execute_input":"2023-09-13T22:04:31.377587Z","iopub.status.idle":"2023-09-13T22:04:31.390893Z","shell.execute_reply.started":"2023-09-13T22:04:31.377551Z","shell.execute_reply":"2023-09-13T22:04:31.389768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inspect and fix records with zero load\n# start with the aggregated records with zero load\nAggZeros = aggLoad.query(\"AggregateLoad == 0\")\nAggZeros\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:31.400221Z","iopub.execute_input":"2023-09-13T22:04:31.400601Z","iopub.status.idle":"2023-09-13T22:04:31.414548Z","shell.execute_reply.started":"2023-09-13T22:04:31.400569Z","shell.execute_reply":"2023-09-13T22:04:31.413522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observation: Some of the timestamps are not exactly on the half-hour\nQuestion: How many of the timestamps are not exactly on the half-hour?","metadata":{}},{"cell_type":"code","source":"# inspect and fix records not exactly on the half-hour\noffRecs = aggLoad.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\n# aggLoad[\"DateTime\"].dt.hour > 30\nprint('Records not exactly on the half-hour: ', offRecs)\nprint(offRecs.info())\n\n# delete records not exactly on the half-hour\naggLoad = aggLoad.drop(offRecs.index)\n\noffRecs = aggLoad.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\nprint('Records not exactly on the half-hour: ', offRecs)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:31.416171Z","iopub.execute_input":"2023-09-13T22:04:31.416617Z","iopub.status.idle":"2023-09-13T22:04:31.464590Z","shell.execute_reply.started":"2023-09-13T22:04:31.416579Z","shell.execute_reply":"2023-09-13T22:04:31.463343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for missing records in the aggregate load time series\n# create reference time series\nminTimestamp = aggLoad.index.min()\nmaxTimestamp = aggLoad.index.max()\n\nprint('minTimestamp: ', minTimestamp)\nprint('maxTimestamp: ', maxTimestamp)\n\ndate_range = pd.date_range(minTimestamp, maxTimestamp, freq='30Min')\nreference_df = pd.DataFrame(np.random.randint(1, 20, (date_range.shape[0], 1)))\nreference_df.index = date_range  # set index\n\nprint('reference index length: ', reference_df.shape)\nprint('aggLoad index length: ', aggLoad.shape)\n\nprint('reference_df: ', reference_df)\nprint('aggLoad: ', aggLoad)\n\nprint('reference index: ', reference_df.index)\nprint('aggLoad index: ', aggLoad.index)\n\n# check for missing datetimeindex values based on reference index (with all values)\nmissing_dates = reference_df.index[~reference_df.index.isin(aggLoad.index)]\n\nprint('missing_dates: ', missing_dates)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:31.465748Z","iopub.execute_input":"2023-09-13T22:04:31.466039Z","iopub.status.idle":"2023-09-13T22:04:31.489200Z","shell.execute_reply.started":"2023-09-13T22:04:31.466014Z","shell.execute_reply":"2023-09-13T22:04:31.488405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the regularity of the observations (time between observations)\n# print(pd.infer_freq(train_data.DateTime))\naggLoad.index.to_series().diff().value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:31.490877Z","iopub.execute_input":"2023-09-13T22:04:31.491214Z","iopub.status.idle":"2023-09-13T22:04:31.501337Z","shell.execute_reply.started":"2023-09-13T22:04:31.491184Z","shell.execute_reply":"2023-09-13T22:04:31.500442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate moving average and stddev\nwindow_size = int(len(aggLoad.AggregateLoad) / 10)\nprint(window_size)\n\naggLoadMovingStdev = aggLoad.AggregateLoad.rolling(window_size).std()\naggLoadMovingStdev.columns = ['MovingStdev']\n# aggLoadMovingStdev.columns.values[0] = 'MovingStdev'\n\naggLoadMovingAvg = aggLoad.AggregateLoad.rolling(window_size).mean()\naggLoadMovingAvg.columns = ['MovingAvg']\n\nprint('aggLoadMovingStdev:\\n', aggLoadMovingStdev)\nprint(aggLoadMovingStdev.info())\nprint('aggLoadMovingAvg:\\n', aggLoadMovingAvg)\nprint(aggLoadMovingAvg.info())\n\n# aggLoad['MovingStdev'] = aggLoad.AggregateLoad.rolling(window_size).std()\n# aggLoad['MovingAvg'] = aggLoad.AggregateLoad.rolling(window_size).mean()\n\n# print('aggLoad.MovingStdev:\\n', aggLoad.MovingStdev)\n# print('aggLoad.MovingAvg:\\n', aggLoad.MovingAvg)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:31.502323Z","iopub.execute_input":"2023-09-13T22:04:31.502735Z","iopub.status.idle":"2023-09-13T22:04:31.532592Z","shell.execute_reply.started":"2023-09-13T22:04:31.502696Z","shell.execute_reply":"2023-09-13T22:04:31.531739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(aggLoad)\n\nfig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime, aggLoad.AggregateLoad)\n# ax.plot(aggLoad.DateTime, aggLoad.MovingAvg, linewidth=3)\n# ax.plot(aggLoad.DateTime, aggLoad.MovingStdev, linewidth=3)\nax.plot(aggLoad.DateTime, aggLoadMovingAvg, linewidth=3)\nax.plot(aggLoad.DateTime, aggLoadMovingStdev, linewidth=3)\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load 2012-2014')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:31.533499Z","iopub.execute_input":"2023-09-13T22:04:31.533822Z","iopub.status.idle":"2023-09-13T22:04:32.391285Z","shell.execute_reply.started":"2023-09-13T22:04:31.533794Z","shell.execute_reply":"2023-09-13T22:04:32.389896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggLoad.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:32.392643Z","iopub.execute_input":"2023-09-13T22:04:32.392987Z","iopub.status.idle":"2023-09-13T22:04:32.404540Z","shell.execute_reply.started":"2023-09-13T22:04:32.392958Z","shell.execute_reply":"2023-09-13T22:04:32.403407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime[10000:15000], aggLoad.AggregateLoad[10000:15000])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load June-August 2012')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"Aggregate Household load June-August 2012.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:32.406462Z","iopub.execute_input":"2023-09-13T22:04:32.406902Z","iopub.status.idle":"2023-09-13T22:04:33.192525Z","shell.execute_reply.started":"2023-09-13T22:04:32.406861Z","shell.execute_reply":"2023-09-13T22:04:33.191161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime[12000:13000], aggLoad.AggregateLoad[12000:13000])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:33.193921Z","iopub.execute_input":"2023-09-13T22:04:33.194319Z","iopub.status.idle":"2023-09-13T22:04:33.777634Z","shell.execute_reply.started":"2023-09-13T22:04:33.194282Z","shell.execute_reply":"2023-09-13T22:04:33.776489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nax.plot(aggLoad.DateTime[12500:12600], aggLoad.AggregateLoad[12500:12600])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load ~two days')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:33.778768Z","iopub.execute_input":"2023-09-13T22:04:33.779327Z","iopub.status.idle":"2023-09-13T22:04:34.348760Z","shell.execute_reply.started":"2023-09-13T22:04:33.779295Z","shell.execute_reply":"2023-09-13T22:04:34.347919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(aggLoad.DateTime[12500:12550], aggLoad.AggregateLoad[12500:12550])\n\nax.set(xlabel='time (s)', ylabel='KWH/hh',\n       title='Aggregate Household load (one day)')\nplt.tick_params(rotation=45)\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:34.350038Z","iopub.execute_input":"2023-09-13T22:04:34.350349Z","iopub.status.idle":"2023-09-13T22:04:34.728061Z","shell.execute_reply.started":"2023-09-13T22:04:34.350321Z","shell.execute_reply":"2023-09-13T22:04:34.726801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_plot(testY, test_predict):\n      len_prediction=[x for x in range(len(testY))]\n      plt.figure(figsize=(20,5))\n      plt.plot(len_prediction, testY, marker='.', label=\"actual\")\n      plt.plot(len_prediction, test_predict, 'r', label=\"prediction\")\n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:34.729344Z","iopub.execute_input":"2023-09-13T22:04:34.729724Z","iopub.status.idle":"2023-09-13T22:04:34.739212Z","shell.execute_reply.started":"2023-09-13T22:04:34.729689Z","shell.execute_reply":"2023-09-13T22:04:34.737851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use a naive persistence model as baseline to compare more sophisticated models\nUse a 1 week persistence\n\nGeorgios Tziolis, Chrysovalantis Spanias, Maria Theodoride, Spyros Theocharides, Javier Lopez-Lorente, Andreas Livera, George Makrides, George E. Georghiou,\n\nShort-term electric net load forecasting for solar-integrated distribution systems based on Bayesian neural networks and statistical post-processing,\n\nEnergy,\nVolume 271,\n2023,\n127018,\nISSN 0360-5442,\n\nhttps://doi.org/10.1016/j.energy.2023.127018.","metadata":{}},{"cell_type":"code","source":"# Naive 1 week persistence model\nNaiveForecast = aggLoad.AggregateLoad.copy()\n\nOneWeekNPeriods = 48 * 7\n\nNaiveForecast[:OneWeekNPeriods] = np.nan\n\nfor i in range(OneWeekNPeriods, len(aggLoad.AggregateLoad)):\n    NaiveForecast[i] = aggLoad.AggregateLoad[i - OneWeekNPeriods]\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:34.740539Z","iopub.execute_input":"2023-09-13T22:04:34.740915Z","iopub.status.idle":"2023-09-13T22:04:36.216165Z","shell.execute_reply.started":"2023-09-13T22:04:34.740876Z","shell.execute_reply":"2023-09-13T22:04:36.215051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize naive forecast\nprediction_plot(aggLoad.AggregateLoad, NaiveForecast)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:36.217589Z","iopub.execute_input":"2023-09-13T22:04:36.217933Z","iopub.status.idle":"2023-09-13T22:04:36.882931Z","shell.execute_reply.started":"2023-09-13T22:04:36.217903Z","shell.execute_reply":"2023-09-13T22:04:36.881311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate error for naive model\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\nprint('Naive Root Mean Squared Error(RMSE): %.2f; Naive Mean Absolute Error(MAE) : %.2f; Naive Mean Absolute Percantage Error(MAPE) : %.2f '\n      % (np.sqrt(mean_squared_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])),\n         mean_absolute_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:]),\n         mean_absolute_percentage_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:36.884443Z","iopub.execute_input":"2023-09-13T22:04:36.884779Z","iopub.status.idle":"2023-09-13T22:04:37.105516Z","shell.execute_reply.started":"2023-09-13T22:04:36.884749Z","shell.execute_reply":"2023-09-13T22:04:37.103787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ADF Test function\nimport statsmodels.tsa.stattools as smt\ndef adf_test(series):\n result = smt.adfuller(series.dropna())\n print('ADF Statistic: %f' % result[0])\n print('p-value: %f' % result[1])\n return result","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:37.109008Z","iopub.execute_input":"2023-09-13T22:04:37.109410Z","iopub.status.idle":"2023-09-13T22:04:37.116379Z","shell.execute_reply.started":"2023-09-13T22:04:37.109375Z","shell.execute_reply":"2023-09-13T22:04:37.115015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adf_test(aggLoad.AggregateLoad)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:37.118010Z","iopub.execute_input":"2023-09-13T22:04:37.118329Z","iopub.status.idle":"2023-09-13T22:04:41.184012Z","shell.execute_reply.started":"2023-09-13T22:04:37.118301Z","shell.execute_reply":"2023-09-13T22:04:41.182842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.tsa.seasonal as sts\n\ncomponents = sts.seasonal_decompose(aggLoad.AggregateLoad, period=48) # 48 = one day\ncomponents.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:41.186108Z","iopub.execute_input":"2023-09-13T22:04:41.187034Z","iopub.status.idle":"2023-09-13T22:04:42.900139Z","shell.execute_reply.started":"2023-09-13T22:04:41.186983Z","shell.execute_reply":"2023-09-13T22:04:42.899037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf\nplot_acf(aggLoad.AggregateLoad, lags = 96) \n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:42.901664Z","iopub.execute_input":"2023-09-13T22:04:42.902555Z","iopub.status.idle":"2023-09-13T22:04:43.930600Z","shell.execute_reply.started":"2023-09-13T22:04:42.902507Z","shell.execute_reply":"2023-09-13T22:04:43.929455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install pmdarima","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:43.932051Z","iopub.execute_input":"2023-09-13T22:04:43.932448Z","iopub.status.idle":"2023-09-13T22:04:57.228113Z","shell.execute_reply.started":"2023-09-13T22:04:43.932415Z","shell.execute_reply":"2023-09-13T22:04:57.226680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"find best parameters for ARIMA\nimport pmdarima as pm\nmodel = pm.auto_arima(aggLoad.AggregateLoad, start_p=1, start_q=1,\n                      test='adf',       \nuse adftest to find optimal 'd'\n                      max_p=3, max_q=3, \nmaximum p=3 and q=3\n                      m=17532,              \nperiodicity of 48 months as the data timeline is in h\n                      d=None,           \nlet the model determine 'd'\n                      seasonal=True,   # Seasonality\n                      start_P=0, \n                      D=1, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=True)\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-09-01T20:45:20.266736Z","iopub.execute_input":"2023-09-01T20:45:20.267337Z"}}},{"cell_type":"code","source":"# print(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:57.230267Z","iopub.execute_input":"2023-09-13T22:04:57.230808Z","iopub.status.idle":"2023-09-13T22:04:57.236860Z","shell.execute_reply.started":"2023-09-13T22:04:57.230758Z","shell.execute_reply":"2023-09-13T22:04:57.235621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the time series data into train, test, and validation datasets\ntrain_size = int(len(aggLoad) * 0.7)  # 70% for training\ntest_size = int(len(aggLoad) * 0.2)   # 20% for testing\nval_size = len(aggLoad) - train_size - test_size  # Remaining for validation\n\ntrain_data = aggLoad[:train_size]\ntest_data = aggLoad[train_size:train_size+test_size]\nval_data = aggLoad[train_size+test_size:]\n\nprint('train_data.head()', train_data.head())\nprint('test_data.head()', test_data.head())\nprint('val_data.head()', val_data.head())\nprint(train_data.info())","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:57.238654Z","iopub.execute_input":"2023-09-13T22:04:57.238975Z","iopub.status.idle":"2023-09-13T22:04:57.275220Z","shell.execute_reply.started":"2023-09-13T22:04:57.238949Z","shell.execute_reply":"2023-09-13T22:04:57.274287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create an ARIMA algorithm baseline to assess other models against ","metadata":{}},{"cell_type":"markdown","source":"# Create a Deep Learning time series forecasting model using Keras","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\ndef convert2matrix(data_arr, look_back):\n   X, Y =[], []\n   for i in range(len(data_arr)-look_back):\n       d=i+look_back  \n       X.append(data_arr[i:d,])\n       Y.append(data_arr[d,])\n   return np.array(X), np.array(Y)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:04:57.276951Z","iopub.execute_input":"2023-09-13T22:04:57.277701Z","iopub.status.idle":"2023-09-13T22:05:06.589992Z","shell.execute_reply.started":"2023-09-13T22:04:57.277654Z","shell.execute_reply":"2023-09-13T22:05:06.588776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RNN\n# work with a copy of the dataset\ndf1 = aggLoad.copy()\n# print(df1.head())\ndf1 = df1.drop(columns=['DateTime'])\nprint(df1.head())\n\n# prepare the data\ntrain,test = df1.values[0:train_size,:], df1.values[train_size:train_size+test_size,:]\nlook_back = 96 # create window size\ntest = np.append(test,np.repeat(test[-1,], look_back))\ntrain = np.append(train,np.repeat(train[-1,],look_back))\ntrainX,trainY =convert2matrix(train,look_back)\ntestX,testY =convert2matrix(test,look_back)\n# reshape input to be [samples, window size, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n\n\nprint('trainX:\\n', trainX.shape, trainX.dtype)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:06.591264Z","iopub.execute_input":"2023-09-13T22:05:06.592159Z","iopub.status.idle":"2023-09-13T22:05:06.644563Z","shell.execute_reply.started":"2023-09-13T22:05:06.592122Z","shell.execute_reply":"2023-09-13T22:05:06.643262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the RNN model architecture\nfrom keras.models import Sequential\nfrom keras.layers import Dense, SimpleRNN\nfrom keras.callbacks import EarlyStopping\ndef model_rnn(look_back):\n  model=Sequential()\n  model.add(SimpleRNN(units=8, input_shape=(1,look_back), activation=\"relu\"))\n  model.add(Dense(4, activation='relu'))\n  model.add(Dense(1))\n  model.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:06.645939Z","iopub.execute_input":"2023-09-13T22:05:06.646293Z","iopub.status.idle":"2023-09-13T22:05:06.653607Z","shell.execute_reply.started":"2023-09-13T22:05:06.646263Z","shell.execute_reply":"2023-09-13T22:05:06.652243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the RNN model\nmodel=model_rnn(look_back)\n\nhistory=model.fit(trainX,trainY, epochs=100, batch_size=30, verbose=1, validation_data=(testX,testY),callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:06.655164Z","iopub.execute_input":"2023-09-13T22:05:06.655555Z","iopub.status.idle":"2023-09-13T22:05:40.018786Z","shell.execute_reply.started":"2023-09-13T22:05:06.655522Z","shell.execute_reply":"2023-09-13T22:05:40.017751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for plotting the train and test loss curves\ndef model_loss(history):\n    plt.figure(figsize=(8,4))\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Test Loss')\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epochs')\n    plt.legend(loc='upper right')\n    plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:40.020196Z","iopub.execute_input":"2023-09-13T22:05:40.020559Z","iopub.status.idle":"2023-09-13T22:05:40.027173Z","shell.execute_reply.started":"2023-09-13T22:05:40.020528Z","shell.execute_reply":"2023-09-13T22:05:40.026164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict on the train and test datasets\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\ntrain_predict = model.predict(trainX)\ntest_predict = model.predict(testX)\nprint('Train Root Mean Squared Error(RMSE): %.2f; Train Mean Absolute Error(MAE) : %.2f '\n      % (np.sqrt(mean_squared_error(trainY, train_predict)), mean_absolute_error(trainY, train_predict[:,0])))\nprint('Test Root Mean Squared Error(RMSE): %.2f; Test Mean Absolute Error(MAE) : %.2f ' \n      % (np.sqrt(mean_squared_error(testY, test_predict[:,0])), mean_absolute_error(testY, test_predict[:,0])))\nmodel_loss(history)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:40.028838Z","iopub.execute_input":"2023-09-13T22:05:40.029139Z","iopub.status.idle":"2023-09-13T22:05:42.131693Z","shell.execute_reply.started":"2023-09-13T22:05:40.029112Z","shell.execute_reply":"2023-09-13T22:05:42.130656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot actuals and predictions for the whole test set\n# print('testY:\\n', testY.shape, testY)\n# print('test_predict:\\n', test_predict.shape, test_predict)\nprediction_plot(testY, test_predict)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:42.133207Z","iopub.execute_input":"2023-09-13T22:05:42.133578Z","iopub.status.idle":"2023-09-13T22:05:42.681486Z","shell.execute_reply.started":"2023-09-13T22:05:42.133546Z","shell.execute_reply":"2023-09-13T22:05:42.680631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot actuals and RNN predictions for the first day of the test set\nprediction_plot(testY[0:48], test_predict[0:48])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:42.682716Z","iopub.execute_input":"2023-09-13T22:05:42.683221Z","iopub.status.idle":"2023-09-13T22:05:43.036307Z","shell.execute_reply.started":"2023-09-13T22:05:42.683182Z","shell.execute_reply":"2023-09-13T22:05:43.035170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTM\n# work with a copy of the dataset\ndf1 = aggLoad.copy()\n# print(df1.head())\ndf1 = df1.drop(columns=['DateTime'])\nprint(df1.head())\n\n# prepare the data\ntrain,test = df1.values[0:train_size,:], df1.values[train_size:train_size+test_size,:]\nlook_back = 48 # create window size\ntest = np.append(test,np.repeat(test[-1,], look_back))\ntrain = np.append(train,np.repeat(train[-1,],look_back))\ntrainX,trainY =convert2matrix(train,look_back)\ntestX,testY =convert2matrix(test,look_back)\n# reshape input to be [samples, window size, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n\n\nprint('trainX:\\n', trainX.shape, trainX.dtype)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:43.037678Z","iopub.execute_input":"2023-09-13T22:05:43.038012Z","iopub.status.idle":"2023-09-13T22:05:43.089647Z","shell.execute_reply.started":"2023-09-13T22:05:43.037982Z","shell.execute_reply":"2023-09-13T22:05:43.088427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTM\nimport keras\nfrom keras.layers import LSTM\n\n# Create the LSTM layer\nlstm_layer = LSTM(units=128, input_shape=(1,look_back))\n\n# Create the model\nlstm_model = keras.Sequential()\nlstm_model.add(lstm_layer)\nlstm_model.add(keras.layers.Dense(8))\nlstm_model.add(keras.layers.Dropout(0.2))\nlstm_model.add(keras.layers.Dense(1))\n\n# Compile the model\nlstm_model.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:43.091267Z","iopub.execute_input":"2023-09-13T22:05:43.091638Z","iopub.status.idle":"2023-09-13T22:05:43.442617Z","shell.execute_reply.started":"2023-09-13T22:05:43.091606Z","shell.execute_reply":"2023-09-13T22:05:43.441390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nprint('Fitting LSTM model...\\n')\nhistory = lstm_model.fit(trainX,trainY, \n               epochs=100, batch_size=30, verbose=1, \n               validation_data=(testX,testY),\n               callbacks=[EarlyStopping(monitor='val_loss', patience=10)],\n               shuffle=False)\n\n# Make a prediction\nprint('Predicting train and test data using LSTM model...\\n')\n\nlstm_train_predict = lstm_model.predict(trainX)\nlstm_test_predict = lstm_model.predict(testX)\nprint('Train Root Mean Squared Error(RMSE): %.2f; Train Mean Absolute Error(MAE) : %.2f '\n      % (np.sqrt(mean_squared_error(trainY, lstm_train_predict)), mean_absolute_error(trainY, lstm_train_predict[:,0])))\nprint('Test Root Mean Squared Error(RMSE): %.2f; Test Mean Absolute Error(MAE) : %.2f ' \n      % (np.sqrt(mean_squared_error(testY, lstm_test_predict[:,0])), mean_absolute_error(testY, lstm_test_predict[:,0])))\n\n# generate loss curves...\nmodel_loss(history)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:05:43.443896Z","iopub.execute_input":"2023-09-13T22:05:43.444224Z","iopub.status.idle":"2023-09-13T22:09:17.171237Z","shell.execute_reply.started":"2023-09-13T22:05:43.444194Z","shell.execute_reply":"2023-09-13T22:09:17.170436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN-LSTM","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:09:17.172513Z","iopub.execute_input":"2023-09-13T22:09:17.173485Z","iopub.status.idle":"2023-09-13T22:09:17.177177Z","shell.execute_reply.started":"2023-09-13T22:09:17.173451Z","shell.execute_reply":"2023-09-13T22:09:17.176434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary of errors for naive and RNN\n","metadata":{}},{"cell_type":"code","source":"print('Naive Root Mean Squared Error(RMSE): %.2f; Naive Mean Absolute Error(MAE) : %.2f; Naive Mean Absolute Percantage Error(MAPE) : %.2f '\n      % (np.sqrt(mean_squared_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])),\n         mean_absolute_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:]),\n         mean_absolute_percentage_error(aggLoad.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])))\nprint('RNN Train Root Mean Squared Error(RMSE): %.2f; Train Mean Absolute Error(MAE) : %.2f '\n      % (np.sqrt(mean_squared_error(trainY, train_predict)), mean_absolute_error(trainY, train_predict[:,0])))\nprint('RNN Test Root Mean Squared Error(RMSE): %.2f; Test Mean Absolute Error(MAE) : %.2f ' \n      % (np.sqrt(mean_squared_error(testY, test_predict[:,0])), mean_absolute_error(testY, test_predict[:,0])))\n\n# to-do: create nice graphic for this","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:09:17.178716Z","iopub.execute_input":"2023-09-13T22:09:17.179031Z","iopub.status.idle":"2023-09-13T22:09:17.201537Z","shell.execute_reply.started":"2023-09-13T22:09:17.179003Z","shell.execute_reply":"2023-09-13T22:09:17.200328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot of naive, RNN and actuals","metadata":{}},{"cell_type":"code","source":"      len_prediction=[x for x in range(len(testY))]\n      plt.figure(figsize=(20,5))\n      plt.plot(len_prediction, testY, marker='.', label=\"actual\")\n      plt.plot(len_prediction, test_predict, 'r', label=\"RNN prediction\")\n      plt.plot(len_prediction, NaiveForecast[train_size:train_size+test_size], 'g', label=\"Naive prediction\")\n        \n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:09:17.202909Z","iopub.execute_input":"2023-09-13T22:09:17.204148Z","iopub.status.idle":"2023-09-13T22:09:17.818559Z","shell.execute_reply.started":"2023-09-13T22:09:17.204102Z","shell.execute_reply":"2023-09-13T22:09:17.817440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"      len_prediction=[x for x in range(len(testY[0:48]))]\n      plt.figure(figsize=(20,5))\n      plt.plot(len_prediction, testY[0:48], marker='.', label=\"actual\")\n      plt.plot(len_prediction, test_predict[0:48], 'r', label=\"RNN prediction\")\n      plt.plot(len_prediction, NaiveForecast[train_size:train_size+48], 'g', label=\"Naive prediction\")\n        \n      plt.tight_layout()\n      sns.despine(top=True)\n      plt.subplots_adjust(left=0.07)\n      plt.ylabel('KWH per half hour', size=15)\n      plt.xlabel('Time step', size=15)\n      plt.legend(fontsize=15)\n      plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:09:17.820018Z","iopub.execute_input":"2023-09-13T22:09:17.820416Z","iopub.status.idle":"2023-09-13T22:09:18.196908Z","shell.execute_reply.started":"2023-09-13T22:09:17.820381Z","shell.execute_reply":"2023-09-13T22:09:18.196061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use AutoGluon AutoML with London dataset","metadata":{}},{"cell_type":"code","source":"# install AutoGluon AutoML\n!pip install autogluon\nfrom autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:09:18.197930Z","iopub.execute_input":"2023-09-13T22:09:18.198628Z","iopub.status.idle":"2023-09-13T22:12:43.864928Z","shell.execute_reply.started":"2023-09-13T22:09:18.198593Z","shell.execute_reply":"2023-09-13T22:12:43.863595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AutoGluon specific data preparation\n# work with a copy of the split datasets...\"ag_\" prefix stands for AutoGluon\nag_train_data = train_data.copy()\nag_test_data = test_data.copy()\nag_val_data = val_data.copy()\n\n# AutoGluon requires an ItemID Column, so adding one...\nag_train_data['item_id'] = 'LoadSum'\nag_train_data = ag_train_data.astype({\"item_id\": str})\nag_test_data['item_id'] = 'LoadSum'\nag_test_data = ag_test_data.astype({\"item_id\": str})\nag_val_data['item_id'] = 'LoadSum'\nag_val_data = ag_val_data.astype({\"item_id\": str})","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:12:43.866751Z","iopub.execute_input":"2023-09-13T22:12:43.867119Z","iopub.status.idle":"2023-09-13T22:12:43.888744Z","shell.execute_reply.started":"2023-09-13T22:12:43.867079Z","shell.execute_reply":"2023-09-13T22:12:43.887483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take a quick look at the split datasets\nprint('ag_train_data\\n', ag_train_data)\nprint('ag_test_data\\n', ag_test_data)\nprint('ag_val_data\\n', ag_val_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:12:43.890614Z","iopub.execute_input":"2023-09-13T22:12:43.891065Z","iopub.status.idle":"2023-09-13T22:12:43.911100Z","shell.execute_reply.started":"2023-09-13T22:12:43.891023Z","shell.execute_reply":"2023-09-13T22:12:43.909904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load training data in to required AutoGluon proprietary data frame\nprint(ag_train_data.info())\nag_train_data_tsdf = TimeSeriesDataFrame.from_data_frame(\n    ag_train_data,\n    id_column=\"item_id\",\n    timestamp_column=\"DateTime\"\n)\nag_train_data_tsdf","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:12:43.912590Z","iopub.execute_input":"2023-09-13T22:12:43.912939Z","iopub.status.idle":"2023-09-13T22:12:43.994185Z","shell.execute_reply.started":"2023-09-13T22:12:43.912906Z","shell.execute_reply":"2023-09-13T22:12:43.992293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load test data in to required AutoGluon proprietary data frame, \"_tsdf\" suffix = time series data frame\nag_test_data_tsdf = TimeSeriesDataFrame.from_data_frame(\n    ag_test_data,\n    id_column=\"item_id\",\n    timestamp_column=\"DateTime\"\n)\nag_test_data_tsdf","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:12:43.996055Z","iopub.execute_input":"2023-09-13T22:12:43.996468Z","iopub.status.idle":"2023-09-13T22:12:44.037657Z","shell.execute_reply.started":"2023-09-13T22:12:43.996434Z","shell.execute_reply":"2023-09-13T22:12:44.036400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# at \"high_quality\" level, training takes about 45 minutes...\n# training takes about 15 minutes for DeepAR\n# training takes about 21 minutes for TemporalFusionTransformer\n# training takes about 4 minutes for PatchTST\n# training takes about 4 minutes for PatchTST","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:12:44.039217Z","iopub.execute_input":"2023-09-13T22:12:44.039576Z","iopub.status.idle":"2023-09-13T22:12:44.045241Z","shell.execute_reply.started":"2023-09-13T22:12:44.039545Z","shell.execute_reply":"2023-09-13T22:12:44.044104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ag_predictor = TimeSeriesPredictor(\n    prediction_length=48,\n    path=\"autogluon-london-half-hourly\",\n    target=\"AggregateLoad\",\n    eval_metric=\"MASE\",\n)\n\nag_predictor.fit(\n    ag_train_data_tsdf,\n    presets=\"medium_quality\",\n    time_limit=6000,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T22:12:44.046934Z","iopub.execute_input":"2023-09-13T22:12:44.047255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The test score is computed using the last\n# prediction_length=48 timesteps of each time series in test_data\nag_predictor.leaderboard(ag_test_data_tsdf, silent=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate predictions\nag_predictions = ag_predictor.predict(ag_train_data_tsdf)\nag_predictions.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot prediction results, history and actual test data values\nplt.figure(figsize=(20, 3))\n\nitem_id = \"LoadSum\"\ny_past = ag_train_data_tsdf.loc[item_id][\"AggregateLoad\"]\ny_pred = ag_predictions.loc[item_id]\ny_test = ag_test_data_tsdf.loc[item_id][\"AggregateLoad\"]\n\nplt.plot(y_past[-100:], label=\"Past time series values\")\nplt.plot(y_pred[\"mean\"], label=\"Mean forecast\")\nplt.plot(y_test[:48], label=\"Future time series values\")\n\nplt.fill_between(\n    y_pred.index, y_pred[\"0.1\"], y_pred[\"0.9\"], color=\"red\", alpha=0.1, label=f\"10%-90% confidence interval\"\n)\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}